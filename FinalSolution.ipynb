{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from stop_words import get_stop_words\n",
    "import Stemmer\n",
    "import pymorphy2\n",
    "from segtok import segmenter\n",
    "import re\n",
    "from functools import partial\n",
    "import pickle\n",
    "import xgboost as xgb \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/comments_vrn.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193539, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    111199\n",
       "1.0     82340\n",
       "Name: is_gum, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_gum.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_gum</th>\n",
       "      <th>hour</th>\n",
       "      <th>likes</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170328895</td>\n",
       "      <td>–ê –µ—â–µ —Å–µ–≥–æ–¥–Ω—è —É –Ω–∞—Å –≤ –°–æ–≤–µ—Ç—Å–∫–æ–º —Ä–∞–π–æ–Ω–µ –Ω–∞—à–ª—ã –º...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170328895</td>\n",
       "      <td>[id231306085|–ê–ª–∏—Å–∞], –Ω–µ —Å–ª—ã—à–∞–ª–∞ —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170328895</td>\n",
       "      <td>–ê–ª–∏—Å–∞, —Ö–æ—Ä–æ—à–æ –±—ã ,—É –Ω–∞—Å –Ω–∏ –æ—Ç –∫–æ–≥–æ —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     from_id                                               text  is_gum  hour  \\\n",
       "0  170328895  –ê –µ—â–µ —Å–µ–≥–æ–¥–Ω—è —É –Ω–∞—Å –≤ –°–æ–≤–µ—Ç—Å–∫–æ–º —Ä–∞–π–æ–Ω–µ –Ω–∞—à–ª—ã –º...     1.0    13   \n",
       "1  170328895  [id231306085|–ê–ª–∏—Å–∞], –Ω–µ —Å–ª—ã—à–∞–ª–∞ —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü...     1.0    13   \n",
       "2  170328895  –ê–ª–∏—Å–∞, —Ö–æ—Ä–æ—à–æ –±—ã ,—É –Ω–∞—Å –Ω–∏ –æ—Ç –∫–æ–≥–æ —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä...     1.0    13   \n",
       "\n",
       "   likes  sex  \n",
       "0      9    1  \n",
       "1      0    1  \n",
       "2      0    1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[id255650758|–ê–ª–µ–∫—Å–∞–Ω–¥—Ä], –∞ —Ç—ã –≤ –æ–∫–Ω–æ—Ç–Ω–µ —Å–º–æ—Ç—Ä–∏, –≥–ª–∞–∑–∞ –∑–∞–∫—Ä–æ–π',\n",
       "       '[id120194982|–ì–Ω—è–∑], –ù–∏ –¥–∞–π –ë–æ–≥ –∫–æ–Ω–µ—á–Ω–æ! –õ—É—á—à–µ –≤—Å–µ–≥–æ –≤—Å–µ—Ö –Ω–∞—Å —Ä–∞—Å—Å—É–¥–∏—Ç –≤—Ä–µ–º—è –≤ —ç—Ç–æ–º –≤–æ–ø—Ä–æ—Å–µ –¥—É–º–∞—é —Å–∫–æ—Ä–æ —Å—Ç–∞–Ω–µ—Ç —è—Å–Ω–æ –∫–∞–∫–æ–µ –º–Ω–µ–Ω–∏–µ –±—ã–ª–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∞ –∫–∞–∫–æ–µ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ–º!',\n",
       "       '–ù–æ, –º–Ω–æ–≥–∏–µ –≤—Å–ø–æ–º–Ω—è—Ç...',\n",
       "       '[id13899021|–°–≤–µ—Ç–ª–∞–Ω–∞], –±–ª–∞–≥–æ–¥–∞—Ä—é –í–∞—Å üòå \\n–°–ª—ã—à–∞–ª —á—Ç–æ —É –Ω–∞—Å –ø–µ—Ä–µ–≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–ª–∞–Ω–∞ –ø–æ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤—É –Ω–∞ 30%\\n–ù–∏–∫—Ç–æ –Ω–µ –≤ –∫—É—Ä—Å–µ?',\n",
       "       '–ê —Ö–æ—Ç—å –∏ –Ω–µ—Ç, –≤ –∞—Ä–º–∏–∏ –≤—Å–µ–º—É –Ω–∞—É—á–∞—Ç!',\n",
       "       '[id286100158|–ê–ª–µ–Ω–∫–∞], –æ–æ, —á—ë—Ç —Ç—ã –Ω–∞ –Ω–æ—á—å –≥–ª—è–¥—è –∞–º–±–∞—Å–∞–¥–¥–æ—Ä —Å–µ–±–µ –∑–∞–≤–∞—Ä–∏–ª–∞? –±–µ—Å—Å–æ–Ω–Ω–∏—Ü—É —Ä–∞–∑–≥–æ–Ω—è–µ—à—å –¥–æ –Ω–µ–º—ã—Å–ª–∏–º—ã—Ö –ø—Ä–µ–¥–µ–ª–æ–≤?',\n",
       "       '[id275785718|–î–º–∏—Ç—Ä–∏–π], —è –Ω–µ –æ–ø—Ä–∞–≤–¥—ã–≤–∞—é –ï–ª—å—à–∏–Ω–∞. –ò—Ö –Ω–∞–¥–æ –±—ã–ª–æ –≤–º–µ—Å—Ç–µ —Å —ç—Ç–∏–º–∏ —Å–≤–µ—Å—Ç–∏',\n",
       "       '–ñ–∏–≤—ã–µ –µ—Å—Ç—å?',\n",
       "       '[id109059312|–ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω], –≤—ã—Ö–æ–¥–∏—Ç —è —Å—Ç–∞—Ä, —Ä–∞–∑ –∏ —Ç–∞–∫–æ–µ –ø–æ–º–Ω—é, –∏ –∫–∞—Ç–∞–ª—Å—è –Ω–∞ —ç—Ç–æ–º, —Ç–∞–∫ –µ—â–µ –∏ –Ω–∞ —Ç—Ä–∞–º–≤–∞–µ –Ω–∞ –∫–æ–ª–±–∞—Å–µ –∫–∞—Ç–∞–ª–∏—Å—å',\n",
       "       '[id103199386|–ê–ª–µ–Ω–∫–∞], )))'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.is_gum == False].text.sample(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ '[id237244411|–ê–Ω—Ç–æ–Ω], –∞ —á—Ç–æ —Ç–µ–±–µ —è—Å–Ω–æ? –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞—é —É–∂–µ —Ç–≤–æ–π –æ—Ç–≤–µ—Ç —Ç–∏–ø–∞, —á—Ç–æ —è —Ç—É–ø–∞—è. –•–∏-—Ö–∏.',\n",
       "       '[id13766429|–í–∞–¥–∏–º], –¥–∞–≤–∞–π—Ç–µ —Ö–∞–∞—Ö', '[id91316539|–†–æ–º–∞–Ω], –∑–∞ 299',\n",
       "       '–ù—É, —Å—É–¥—è –ø–æ —Ñ–æ—Ç–æ - –≤–æ–¥–∏—Ç–µ–ª—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∂–∏–≤! –ò–ª–∏ —Ç–∞–º –ø–∞—Å—Å–∞–∂–∏—Ä –±—ã–ª?',\n",
       "       '[id173075801|–ù–∏–∫–∏–Ω—è—à–∞], —Å–ø–∞—Å–∏–±–æ)',\n",
       "       '–ü–µ—á–∞–ª—å —Å —É—Ç—Ä–∞, –∫–æ–≥–¥–∞ –≤—Å—Ç–∞–ª –≤ 6...( —Å–ø–∞—Ç—å –æ—Ö–æ—Ç–∞...',\n",
       "       '–î–∞ —á—Ç–æ –∂ —Ç–∞–∫–æ–µ !!!???', '–•–µ—Ö, —Ç—É—Ä–∏—Å—Ç—ã –≤ –í–æ—Ä–æ–Ω–µ–∂–µ, —É–º–æ—Ä—ã....',\n",
       "       '–í–ø–µ—Ä–≤—ã–µ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –±–µ–∑ —à—É—Ç–Ω–∏–∫–æ–≤)', '–í –ì—Ä–µ—Ü–∏—é —Ö–æ—á–µ—Ç'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.is_gum == True].text.sample(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lenghts_word = np.array([len(m.split()) for m in data.text.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.219397640785578, 6.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenghts_word.mean(), np.median(lenghts_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134898, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = data[(lenghts_word < 60) & (lenghts_word > 3)]\n",
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46% of comments contain links\n"
     ]
    }
   ],
   "source": [
    "links = [m for m in data.text.values if 'http' in m or 'www' in m or '.ru' in m or '.com' in m] \n",
    "print('{:.2f}% of comments contain links'.format(len(links) / len(data) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "without_link = [False if 'http' in c or 'www' in c or '.ru' in c or '.com' in c else True\n",
    "                for c in comments.text.values] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = comments[without_link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134325, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Droping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=1000, ngram_range=(3, 3), analyzer='char')\n",
    "X = vectorizer.fit_transform([' '.join(t.split()[:4]) for t in comments.text.values])\n",
    "y = comments.is_gum.values\n",
    "# y = comments.sex.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = IsolationForest(200, contamination=0.01, n_jobs=-1)\n",
    "forest.fit(X)\n",
    "X_pred = forest.predict(X)\n",
    "comments['len'] = [len(t) for t in comments.text.values]\n",
    "comments['outlier'] = X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['–ø–æ—á–∏—Ç–∞–π—Ç–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –ù—é—Ä–Ω–±–µ—Ä–≥—Å–∫–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞....–ø—Ä–æ—Å–≤–µ—Ç–∏—Ç–µ—Å—å....',\n",
       "       '[id4000062|–ù–∞—Ç–∞–ª—å—è], —Ç–µ–ª–æ —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –±—ã–ª–æ —Ç–∞–º, –≥–¥–µ –µ–≥–æ –∏ –Ω–∞—à–ª–∏ 1 —á–∏—Å–ª–∞. –•–æ—Ç—è –≤–µ—Ä—Å–∏—é –ø—Ä–æ —Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç—Ä—É–ø–∞ –≤ –¥—Ä—É–≥–æ–º –º–µ—Å—Ç–µ –ø–æ–∫–∞ —Ç–æ–∂–µ –≤ —Ä–∞–±–æ—Ç–µ',\n",
       "       '[id14204536|–ö—Ä–∏—Å—Ç–∏–Ω–∞], –Ω–∞ —Ä–∞–±–æ—Ç–µ –æ—Å—Ç–∞–≤–∏–ª....–Ω–∞–ø–æ–º–Ω–∏—Ç–µ –∑–∞–≤—Ç—Ä–∞, —Ä–∞—Å–ø–∏—à—É —á—Ç–æ –∏ –∫–∞–∫',\n",
       "       '[id140491201|–ú–∏—Ö–∞–∏–ª], –ø–æ—Å–æ–≤–µ—Ç—É–π—Ç–µ –µ–º—É —Å–∏–ª—å–Ω–æ –Ω–µ –≥–æ—Ä—è—á–∏—Ç—å—Å—è....—Å–ø—Ä–æ–≤–æ—Ü–∏—Ä–æ–≤–∞—Ç—å –º–æ–∂–Ω–æ –∑–∞–ø—Ä–æ—Å—Ç–æ....–∏ –¥–µ–ª–æ –º–æ–∂–µ—Ç –∑–∞–≥–ª–æ—Ö–Ω—É—Ç—å',\n",
       "       '[id84212618|–í–∏–∫—Ç–æ—Ä], –∫—Ç–æ —Ä–µ–ø–æ—Å—Ç–∏—Ç-—Ç–µ–º –±–æ–ª–µ–µüòñ',\n",
       "       '[id191579258|–ò—Ä–∏–Ω–∞], —Ñ–æ—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∫—Ä–∞—Å–∏–≤—ã–µ, –º—ã –Ω–∞–∫–∏–Ω—É–ª–∏—Å—å –ª–∞–π–∫–∞—Ç—å –∏ —Ä–∞–¥–æ–≤–∞—Ç—å—Å—è)))))',\n",
       "       '[id50990265|–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞], –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –º–æ—Ä–æ–∂–µ–Ω–æ–µ —Ö–æ—Ä–æ—à–æ –∑–∞—à–ª–æ? üçßüçßüçß',\n",
       "       '[id50990265|–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞], –∫–æ—Ç–æ—Ä—ã–π –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø–æ–∑–≤–æ–ª–∏—Ç—å?üòè',\n",
       "       '[id11420305|–í–∞—Å–∏–ª–∏–π], –Ω–∞–≤–µ—Ä–Ω–æ–µ –ø–æ—Ç–æ–º—É —á—Ç–æ –¥–æ –ª–µ—Ç–∞ –µ—â–µ —Ä–∞–Ω–æ–≤–∞—Ç–æüòè',\n",
       "       '[id1417542|–Ø—Ä–æ—Å–ª–∞–≤], —ç—Ç–æ—Ç –º–∞–≥–∞–∑–∏–Ω –Ω–∞—Å–∫–æ–ª—å–∫–æ —è –∑–Ω–∞—é, –º–∏–Ω–∏–º—É–º –ª–µ—Ç 5 —Å—É—â–µ—Å—Ç–≤—É–µ—Ç))))) –∞ —Å–∞–π—Ç-–≤–∏–∑–∏—Ç–∫–∞ —Ç–µ–±–µ –ø–æ–Ω—è—Ç–∏–µ –∑–Ω–∞–∫–æ–º–æ?'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[comments.outlier == -1].head(10).text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_id</th>\n",
       "      <th>is_gum</th>\n",
       "      <th>hour</th>\n",
       "      <th>likes</th>\n",
       "      <th>sex</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outlier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>9.706319e+07</td>\n",
       "      <td>0.436756</td>\n",
       "      <td>11.840030</td>\n",
       "      <td>0.488839</td>\n",
       "      <td>1.656250</td>\n",
       "      <td>105.696429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.080808e+07</td>\n",
       "      <td>0.427978</td>\n",
       "      <td>12.645115</td>\n",
       "      <td>1.242350</td>\n",
       "      <td>1.677691</td>\n",
       "      <td>83.924282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              from_id    is_gum       hour     likes       sex         len\n",
       "outlier                                                                   \n",
       "-1       9.706319e+07  0.436756  11.840030  0.488839  1.656250  105.696429\n",
       " 1       9.080808e+07  0.427978  12.645115  1.242350  1.677691   83.924282"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.groupby('outlier').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_list = comments.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('meta_data/emoji.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "emojis = [line[0] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_with_emoji(comment):\n",
    "    for em in emojis:\n",
    "        if em in comment:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def with_emoji(comments):\n",
    "    return [is_with_emoji(c) for c in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_emoji(comment, repetition=True):\n",
    "    ems = []\n",
    "    for em in emojis:\n",
    "        if not repetition:\n",
    "            if em in comment:\n",
    "                ems.append(em)\n",
    "        else:\n",
    "            founded = re.findall(em, comment)\n",
    "            if len(founded) > 0:\n",
    "                ems.extend(founded)\n",
    "    return ems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If not done before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134325"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 35min 58s, sys: 804 ms, total: 1h 35min 59s\n",
      "Wall time: 1h 37min 14s\n"
     ]
    }
   ],
   "source": [
    "# %time emoji_from_comments_rep = list(map(get_emoji, comments_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('meta_data/emoji_from_comments_vrn_final.pkl', 'wb') as f:\n",
    "#     pickle.dump(emoji_from_comments_rep, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Else load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134325, 134325)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('meta_data/emoji_from_comments_vrn_final.pkl', 'rb') as f:\n",
    "    emoji_from_comments_rep = pickle.load(f)\n",
    "emoji_from_comments_no_rep = list(map(lambda com: get_emoji(com, False), comments_list))\n",
    "len(comments_list), len(emoji_from_comments_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_emoji_proportion(comments, emoji_from_coms=None, repetition=True):\n",
    "    emoji_proportion = [] \n",
    "    func = lambda com: get_emoji(com, repetition)\n",
    "    if not emoji_from_coms:\n",
    "        emoji_from_coms = list(map(func, comments))\n",
    "    \n",
    "    for i in range(len(comments)):\n",
    "        com = re.sub(' *', '', comments[i])\n",
    "        emoji_proportion.append(len(emoji_from_coms[i]) / len(com))\n",
    "    return np.array(emoji_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em_proportion_rep = get_emoji_proportion(comments_list, emoji_from_comments_rep)\n",
    "em_proportion_no_rep = get_emoji_proportion(comments_list, emoji_from_comments_no_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['–° –¥–Ω–µ–º —Ä–æ–∂–¥–µ–Ω–∏—è, –õ–µ–≥–µ–Ω–¥–∞‚ù§‚ù§‚ù§', '–±–æ–ª—å–Ω–æ –í—ã –º–Ω–µ –Ω—É–∂–Ω—ãüòÇüòÇüòÇ',\n",
       "       '–∫—Ç–æ —ç—Ç–æ —Å–ª—É—à–∞–µ—Ç? üòÄüòÄ', '–≠—Ç–æ —Ä–∞–∑–≤–µ —Ç–∞–∫ –≤–∞–∂–Ω–æ?üòÄüòÄüòÄ',\n",
       "       '–Ω–∞ –ª–æ–≥–æ—Ç–∏–ø Pepsi –ø–æ—Ö–æ–∂–µüòãüòãüòã', '–¢–∞–∫ —ç—Ç–æ –∂–µ –ø—Ä–æ–≤–æ–¥ üòÄüòÄ',\n",
       "       '–î–∞ –Ω–µ –∑–∞ —á—Ç–æüòÑüòÑ', '–ê \"–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ\" - —Å–ª–∏—Ç–Ω–æ üòÑüòÑüòÑ',\n",
       "       '–ï—Å—Ç—å‚úãüèª–ó–æ–∂–Ω–∏–∫–∏ –Ω–µ –±—É—Ö–∞—é—Ç üòÑ', '–Ø –±—ã —Å–æ–±–∞—á–µ–∫ –Ω–∞–∫–æ—Ä–º–∏–ª–∞ ü§óü§óü§ó'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((em_proportion_rep > 0.12).sum())\n",
    "comments_list[em_proportion_rep > 0.12][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['–¶–æ–π –∂–∏–≤üíã\\n–° –¥–Ω–µ–º —Ä–æ–∂–¥–µ–Ω–∏—è üòî', '–Ω–µ –ª—é–±–ª—é –º–æ—Ä–µ üòÑ', '–î–∞ –Ω–µ –∑–∞ —á—Ç–æüòÑüòÑ',\n",
       "       '–ï—Å—Ç—å‚úãüèª–ó–æ–∂–Ω–∏–∫–∏ –Ω–µ –±—É—Ö–∞—é—Ç üòÑ',\n",
       "       '–ó–∞—á–µ–µ—ÇüòÇüëçüèª –ê –∫–∞–∫ –æ–Ω —Ç—É–¥–∞ –∑–∞–±—Ä–∞–ª—Å—è? –Ø —Ç–æ–∂–µ —Ö–æ—á—É',\n",
       "       '–ö–ª–∞—Å—Å–Ω—ã–π –º—É–∂–∏–∫, –∫–ª–∞—Å—Å–Ω—ã–π –õ–µ–Ω–∏–Ω–≥—Ä–∞–¥ üòçüëçüèª',\n",
       "       '–í—Å–µ –¥–µ–Ω—å–≥–∏ –Ω–∞ –∫–∞—á–∞–ª–∫—É —É—à–ª–∏ üòÄüòÜ', '–¢–∞–∫ –æ–Ω–æ –∏ –µ—Å—Ç—å üòÑ',\n",
       "       '–°–ø–∞—Å–∏–±–æ –∑–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é üòáüëçüèª', '–ü–æ–π–¥—É –∫–æ—Ç–∞ –ø–æ—Ü–µ–ª—É—é üòÑ‚ù§'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((em_proportion_no_rep > 0.08).sum())\n",
    "comments_list[em_proportion_no_rep > 0.08][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of alphabetical symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_abc_proportion(comments):\n",
    "    abc_proportion = []     \n",
    "    for i in range(len(comments)):\n",
    "        com = re.sub(' *', '', comments[i])\n",
    "        abc = re.findall('[–∞-—è—ëa-z]', com, flags=re.IGNORECASE)\n",
    "        abc_proportion.append(len(abc) / len(com))\n",
    "    return np.array(abc_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abc_proportion = get_abc_proportion(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1018"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abc_proportion < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['–≠—Ç–æ –∫–∞–∫ —Ç–∞–∫—ä ???????????',\n",
       "       '[id191122455|–ö–∞—Ç–µ—Ä–∏–Ω–∞], —á—Ç–æ —è...–¥–∞ —Ç–∞–∫)))‚ò∫‚ò∫‚ò∫‚ò∫',\n",
       "       \".‚àßÔºø‚àß \\n( ÔΩ•œâÔΩ•ÔΩ°)„Å§‚îÅ‚òÜ„Éª*„ÄÇ \\n‚äÇ\\u3000 „Éé \\u3000\\u3000\\u3000„Éª„Çú+. \\n„Åó„ÉºÔº™\\u3000\\u3000\\u3000¬∞„ÄÇ+ *¬¥¬®) \\n\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000.¬∑ ¬¥¬∏.¬∑*¬¥¬®) ¬∏.¬∑*¬®) \\n\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000(¬∏.¬∑¬¥ (¬∏.¬∑'* –≤–∂—É—Ö,–º–∞–≥–∏—è –±–∞—è–Ω–∞\",\n",
       "       '[id195857273|Alexis], –≥–æ–¥—É –≤ 2003',\n",
       "       '[id137387704|–Æ–ª—è], –∞ —á–µ–≥–æ —Ç–∞–∫ —Ö–º—É—Ä–æ?))))üíê',\n",
       "       '[id302984120|Ê∞∏ÊÅíÁöÑ], –∞, –≤–æ—Ç —Ç—ã –≥–¥–µ.',\n",
       "       '[id140593667|–Æ–ª—è], –æ —Ç–æ–º, —á—Ç–æ —É–∂–µ 0:22',\n",
       "       '[id20683885|–û–ª—å–≥–∞], —è –≤ —à–æ–∫–µüò±üò±üò±üò±',\n",
       "       '[id166215931|–ú–∏–ª–µ–Ω–∞], –æ–∫–æ–ª–æ 1,2 –º–ª–Ω.',\n",
       "       '[id215978004|Mac], –ø–æ –í–æ—Ä–æ–Ω–µ–∂—É 12-25 —Ç. —Ä. –∑–øüòå'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_list[abc_proportion < 0.5][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments['emojis'] = [' '.join(e) for e in emoji_from_comments_rep]\n",
    "comments['em_proportion_rep'] = em_proportion_rep\n",
    "comments['em_proportion_no_rep'] = em_proportion_no_rep\n",
    "comments['abc_proportion'] = abc_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_gum</th>\n",
       "      <th>hour</th>\n",
       "      <th>likes</th>\n",
       "      <th>sex</th>\n",
       "      <th>len</th>\n",
       "      <th>outlier</th>\n",
       "      <th>emojis</th>\n",
       "      <th>em_proportion_rep</th>\n",
       "      <th>em_proportion_no_rep</th>\n",
       "      <th>abc_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170328895</td>\n",
       "      <td>–ê –µ—â–µ —Å–µ–≥–æ–¥–Ω—è —É –Ω–∞—Å –≤ –°–æ–≤–µ—Ç—Å–∫–æ–º —Ä–∞–π–æ–Ω–µ –Ω–∞—à–ª—ã –º...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170328895</td>\n",
       "      <td>[id231306085|–ê–ª–∏—Å–∞], –Ω–µ —Å–ª—ã—à–∞–ª–∞ —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170328895</td>\n",
       "      <td>–ê–ª–∏—Å–∞, —Ö–æ—Ä–æ—à–æ –±—ã ,—É –Ω–∞—Å –Ω–∏ –æ—Ç –∫–æ–≥–æ —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.920792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     from_id                                               text  is_gum  hour  \\\n",
       "0  170328895  –ê –µ—â–µ —Å–µ–≥–æ–¥–Ω—è —É –Ω–∞—Å –≤ –°–æ–≤–µ—Ç—Å–∫–æ–º —Ä–∞–π–æ–Ω–µ –Ω–∞—à–ª—ã –º...     1.0    13   \n",
       "1  170328895  [id231306085|–ê–ª–∏—Å–∞], –Ω–µ —Å–ª—ã—à–∞–ª–∞ —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü...     1.0    13   \n",
       "2  170328895  –ê–ª–∏—Å–∞, —Ö–æ—Ä–æ—à–æ –±—ã ,—É –Ω–∞—Å –Ω–∏ –æ—Ç –∫–æ–≥–æ —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä...     1.0    13   \n",
       "\n",
       "   likes  sex  len  outlier emojis  em_proportion_rep  em_proportion_no_rep  \\\n",
       "0      9    1  133        1                       0.0                   0.0   \n",
       "1      0    1   62        1                       0.0                   0.0   \n",
       "2      0    1  123        1                       0.0                   0.0   \n",
       "\n",
       "   abc_proportion  \n",
       "0        0.955752  \n",
       "1        0.727273  \n",
       "2        0.920792  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If message repeats more than one time - drop (spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 different spam comments\n"
     ]
    }
   ],
   "source": [
    "print('{} different spam comments'.format((comments.text.value_counts() > 1).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "989 total count of spam comments\n"
     ]
    }
   ],
   "source": [
    "print('{} total count of spam comments'\n",
    "      .format(comments.text.value_counts()[comments.text.value_counts() > 1].values.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_comments = comments.text.value_counts()[comments.text.value_counts() > 1].keys()\n",
    "comments = comments[comments.text.apply(lambda t: t not in spam_comments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_to_del = comments[(comments.em_proportion_rep > 0.12).values | (comments.abc_proportion < 0.5).values | \n",
    "                        (comments.text.value_counts() != 1).values |\n",
    "                        (comments.em_proportion_no_rep > 0.08).values].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1578,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_del.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments.drop(index_to_del, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131758, 12)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_list = comments.text.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_list = []\n",
    "for comment in comments.text.values:\n",
    "    c = comment.split()\n",
    "    if c[0].startswith('[id'):\n",
    "        c[0] = '–∏–º—è'\n",
    "    c_ = []\n",
    "    for w in c:\n",
    "        if w.startswith('id'):\n",
    "            c_.append('–∏–º—è')\n",
    "        else:\n",
    "            c_.append(w)\n",
    "    comments_list.append(' '.join(c))\n",
    "comments_list = np.array(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ '–ê –µ—â–µ —Å–µ–≥–æ–¥–Ω—è —É –Ω–∞—Å –≤ –°–æ–≤–µ—Ç—Å–∫–æ–º —Ä–∞–π–æ–Ω–µ –Ω–∞—à–ª—ã –º—É–∂—á–∏–Ω—É —Ä–∞—Å—á–ª–µ–Ω–µ–Ω–æ–≥–æ ,—Ç–∞–∫ —á—Ç–æ –Ω–µ —Ñ–∞–∫—Ç —á—Ç–æ —Ç–æ–ª—å–∫–æ –Ω–∞ –∂–µ–Ω—â–∏–Ω –Ω–∞–ø–∞–¥–∞–µ—Ç)–ü—Ä–∏–¥–æ–Ω—Å–∫–æ–π –≥—Ä–µ–º–∏—Ç)))',\n",
       "       '–∏–º—è –Ω–µ —Å–ª—ã—à–∞–ª–∞ —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ,–≤—Å–µ –±–æ—è—Ç—Å—è )',\n",
       "       '–ê–ª–∏—Å–∞, —Ö–æ—Ä–æ—à–æ –±—ã ,—É –Ω–∞—Å –Ω–∏ –æ—Ç –∫–æ–≥–æ —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç .–ù–æ –ü—Ä–∏–¥–æ–Ω—Å–∫–æ–π —ç—Ç–æ –°–æ–≤–µ—Ç—Å–∫–∏–π —Ä–∞–π–æ–Ω ,—É –Ω–∞—Å –Ω–µ –æ–¥–∏–Ω –º–∞–Ω—å—è–∫ —á—Ç–æ –ª–∏?)))'], \n",
       "      dtype='<U515')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments.text = comments_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clearing comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = comments.is_gum.values\n",
    "adj_proportion = []\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_comments(comments, with_stemmer=False, with_lemmer=True, to_lower=True, without_names=False,\n",
    "                without_stop_words=False, min_word_len=None, with_emoji=False):\n",
    "    global adj_proportion\n",
    "    global errors \n",
    "    adj_proportion = []\n",
    "    errors = []\n",
    "    clear_comments = []\n",
    "    stop_words = set(get_stop_words('ru'))\n",
    "    stemmer = Stemmer.Stemmer('russian')\n",
    "    lemmer = pymorphy2.MorphAnalyzer()\n",
    "    \n",
    "    names_del = 0\n",
    "    i = -1\n",
    "    for comment in comments:\n",
    "        comment_ = comment\n",
    "        i += 1\n",
    "        if to_lower:\n",
    "            comment = comment.lower()\n",
    "        comment = re.sub('[^–∞-—è–ê-–Ø—ë–Åa-zA-Z\\-]', ' ', comment)\n",
    "        comment = comment.split()\n",
    "        if without_stop_words:\n",
    "            comment = [c for c in comment if c not in stop_words]\n",
    "        if with_stemmer:\n",
    "            comment = stemmer.stemWords(comment)\n",
    "            if without_names:\n",
    "                with open('meta_data/names_from_sent.txt', 'r') as f:\n",
    "                    names = f.readlines()\n",
    "                    names = set([name.strip() for name in names])\n",
    "                before = len(comment)\n",
    "                comment = [c for c in comment if c not in names]\n",
    "                aft = len(comment)\n",
    "                names_del += before - aft\n",
    "        elif with_lemmer:\n",
    "            parsed = [lemmer.parse(c)[0] for c in comment]\n",
    "            comment = [p.normal_form for p in parsed]\n",
    "            adj = sum([1 for p in parsed if 'ADJ' in str(p.tag)])\n",
    "            if len(comment) == 0:\n",
    "                errors.append(comment_)\n",
    "                adj_proportion.append(0)\n",
    "            else:\n",
    "                adj_proportion.append(adj / len(comment))\n",
    "            if without_names:\n",
    "                with open('meta_data/names.txt', 'r') as f:\n",
    "                    names = f.readlines()\n",
    "                    names = set([name.strip() for name in names])\n",
    "                    before = len(comment)\n",
    "                    comment = [c for c in comment if c not in names]\n",
    "                    aft = len(comment)\n",
    "                    names_del += before - aft\n",
    "        if min_word_len is not None:\n",
    "            comment = [c for c in comment if len(c) >= min_word_len]\n",
    "        if with_emoji:\n",
    "            comment.extend(emoji_from_comments_rep[i])\n",
    "        clear_comments.append(' '.join(comment))\n",
    "    print('names del: {}'.format(names_del))\n",
    "    return clear_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.333333333333332"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "550 / 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names del: 8877\n",
      "CPU times: user 11min 56s, sys: 8.1 s, total: 12min 4s\n",
      "Wall time: 12min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clear_coms = clear_comments(comments_list, min_word_len=3, with_emoji=True, with_stemmer=False,\n",
    "                            with_lemmer=True, without_names=True, without_stop_words=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments['clear_text'] = clear_coms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_gum</th>\n",
       "      <th>hour</th>\n",
       "      <th>likes</th>\n",
       "      <th>sex</th>\n",
       "      <th>len</th>\n",
       "      <th>outlier</th>\n",
       "      <th>emojis</th>\n",
       "      <th>em_proportion_rep</th>\n",
       "      <th>em_proportion_no_rep</th>\n",
       "      <th>abc_proportion</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170328895</td>\n",
       "      <td>–ê –µ—â–µ —Å–µ–≥–æ–¥–Ω—è —É –Ω–∞—Å –≤ –°–æ–≤–µ—Ç—Å–∫–æ–º —Ä–∞–π–æ–Ω–µ –Ω–∞—à–ª—ã –º...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>–µ—â—ë —Å–µ–≥–æ–¥–Ω—è —Å–æ–≤–µ—Ç—Å–∫–∏–π —Ä–∞–π–æ–Ω –Ω–∞—à–ª—ã–π –º—É–∂—á–∏–Ω–∞ —Ä–∞—Å...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170328895</td>\n",
       "      <td>–∏–º—è –Ω–µ —Å–ª—ã—à–∞–ª–∞ —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ,–≤—Å–µ –±–æ—è—Ç—Å—è )</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>–∏–º—è —Å–ª—ã—à–∞—Ç—å —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤–µ—Å—å –±–æ—è—Ç—å—Å—è</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     from_id                                               text  is_gum  hour  \\\n",
       "0  170328895  –ê –µ—â–µ —Å–µ–≥–æ–¥–Ω—è —É –Ω–∞—Å –≤ –°–æ–≤–µ—Ç—Å–∫–æ–º —Ä–∞–π–æ–Ω–µ –Ω–∞—à–ª—ã –º...     1.0    13   \n",
       "1  170328895      –∏–º—è –Ω–µ —Å–ª—ã—à–∞–ª–∞ —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ,–≤—Å–µ –±–æ—è—Ç—Å—è )     1.0    13   \n",
       "\n",
       "   likes  sex  len  outlier emojis  em_proportion_rep  em_proportion_no_rep  \\\n",
       "0      9    1  133        1                       0.0                   0.0   \n",
       "1      0    1   62        1                       0.0                   0.0   \n",
       "\n",
       "   abc_proportion                                         clear_text  \n",
       "0        0.955752  –µ—â—ë —Å–µ–≥–æ–¥–Ω—è —Å–æ–≤–µ—Ç—Å–∫–∏–π —Ä–∞–π–æ–Ω –Ω–∞—à–ª—ã–π –º—É–∂—á–∏–Ω–∞ —Ä–∞—Å...  \n",
       "1        0.727273          –∏–º—è —Å–ª—ã—à–∞—Ç—å —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤–µ—Å—å –±–æ—è—Ç—å—Å—è  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–∏–º—è –Ω–∞–ø–∏—Å–∞—Ç—å',\n",
       " '–∏–º—è —Ç–∞–º —Ç–æ–∂–µ –æ—Ç–∫—Ä—ã—Ç—ã–π –ª–∏—á–∫–∞',\n",
       " '–∏–º—è —Ç–∞–∫ —Ä–µ–∞–ª—å–Ω–æ —á—Ç–æ –±–æ–ª—å—à–æ–π üòÇ',\n",
       " '–∏–º—è –¥–∞–∂–µ –µ—Å–ª–∏ —á–µ–ª–æ–≤–µ–∫ –≤—ã–ø–∏–≤–∞—Ç—å –≤–µ—Å—å —Ä–æ–≤–Ω–æ –æ–Ω–∏ —á–µ–ª–æ–≤–µ–∫ –æ–Ω–∏ –∂–∞–ª–∫–æ',\n",
       " '—Å–º–µ—à–Ω–æ–π –∫–æ–Ω–µ—á–Ω–æ –∂–µ–Ω—â–∏–Ω–∞']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_coms[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.2, 0.0, 0.08333333333333333, 0.25]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_proportion[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.73 s, sys: 68 ms, total: 7.8 s\n",
      "Wall time: 7.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = CountVectorizer(max_features=10000, min_df=100, ngram_range=(1, 2), analyzer='word')\n",
    "word_features = vectorizer.fit_transform(clear_coms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['–º—É–∂', '–∏–º—è –æ—Ç–∫—É–¥–∞', '–≤—Å—Ç—Ä–µ—Ç–∏—Ç—å', '–≤–æ—Å–ø–∏—Ç–∞–Ω–∏–µ', '–º–∞–ª–µ–Ω—å–∫–∞—è',\n",
       "       '–∂–∏—Ç–µ–ª—å', '–ª–æ—Ö', '–≤–µ—Å—å —Ç–∞–∫', '–¥–æ—Å—Ç–æ–π–Ω—ã–π', '–º–æ–∑–≥', '–∑–∞–∫—Ä—ã—Ç—ã–π',\n",
       "       '–∏–º—è –≤–∏–¥–µ—Ç—å', '–Ω–∞–¥–µ—è—Ç—å—Å—è', '–∑–∞—á–µ–º', '–∏–º—è —É–∂–µ', '–≤–≥—É', '–¥–µ—Ç—Å–∫–∏–π',\n",
       "       '–Ω–æ–≥–∞', '–∏–Ω—Ñ', '–∏–¥–∏–æ—Ç'], \n",
       "      dtype='<U18')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectorizer.get_feature_names())[np.random.randint(0, 1000, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = lm.LogisticRegression(penalty='l1', C=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56067934537104835"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(lr, word_features, comments.is_gum, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the first letter of sentence upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_stat(comments):\n",
    "    big_letter = []\n",
    "    sents_count = []\n",
    "    for comment in comments:\n",
    "        sents = list(segmenter.split_single(re.sub('(\\)+|\\.+)', '\\n', comment)))\n",
    "        count = sum([1 for sent in sents if sent and (sent[0].isupper() or '–∏–º—è' in sent\n",
    "                                                      or (len(sent) > 1 and sent[0] == '\"' and sent[1].isupper()))])\n",
    "        total = sum([1 for sent in sents if sent.strip() != ''\n",
    "                     and re.match('.*[a-z–∞-—è—ë].*', sent.strip(), flags=re.IGNORECASE)])\n",
    "        # print(count, total)\n",
    "        if total:\n",
    "            big_letter.append(count // total)\n",
    "        else:\n",
    "            big_letter.append(1)\n",
    "        if total > 3:\n",
    "            total = 4\n",
    "        if total < 1:\n",
    "            total = 1\n",
    "        sents_count.append(total)\n",
    "    return np.array(big_letter), np.array(sents_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.4 s, sys: 0 ns, total: 5.4 s\n",
      "Wall time: 5.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "big_letter, sents_count = sentence_stat(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    75753\n",
       "2    33895\n",
       "3    12450\n",
       "4     9660\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(sents_count).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.559730\n",
       "2    0.264190\n",
       "3    0.100222\n",
       "4    0.075858\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(sents_count[y.astype(bool)]).value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.586322\n",
       "2    0.252060\n",
       "3    0.090203\n",
       "4    0.071414\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(sents_count[~y.astype(bool)]).value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    93185\n",
       "0    38573\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(big_letter).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation count in comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def punctuation_counts(comments, pattern='\\(+', partion=False):\n",
    "    if partion:\n",
    "        return [sum(len(p) for p in re.findall(pattern, c)) / len(c) for c in comments]\n",
    "    else:\n",
    "        return [1 if len(re.findall(pattern, c)) > 0 else 0 for c in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "commas = punctuation_counts(comments_list, pattern='[\\.]{2,}', partion=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    113044\n",
       "1     18714\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(commas).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_word_length(comments):\n",
    "    lengths = []\n",
    "    for comment in comments:\n",
    "        comment = comment.lower()\n",
    "        comment = re.sub('[^–∞-—è—ë\\-]', ' ', comment).split()\n",
    "        ls = [len(w) for w in comment]\n",
    "        if len(ls):\n",
    "            lengths.append(sum(ls) / len(ls))\n",
    "        else:\n",
    "            lengths.append(1)\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_length = mean_word_length(comments_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caps WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def caps_words(comments, partion=False):\n",
    "    caps = []\n",
    "    for comment in comments:\n",
    "        count = len(re.findall('[–ê-–Ø–ÅA-Z\\-]{4,}', comment))\n",
    "        total = len(comment.split())\n",
    "        if partion and total != 0:\n",
    "            caps.append(count / total * 100)\n",
    "        else:\n",
    "            caps.append(1 if count > 0 else 0)\n",
    "    return caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caps = caps_words(comments_list, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    128178\n",
       "1      3580\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(caps).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eng_words(comments, partion=False):\n",
    "    engs = []\n",
    "    for comment in comments:\n",
    "        count = len([w for w in re.findall('[a-z\\-]{3,}', comment, flags=re.IGNORECASE) if w != '–∏–º—è'])\n",
    "        total = len(comment.split())\n",
    "        if partion and total != 0:\n",
    "            engs.append(count / total * 100)\n",
    "        else:\n",
    "            engs.append(1 if count > 0 else 0)\n",
    "    return engs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engs = eng_words(comments_list, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    129737\n",
       "1      2021\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(engs).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_words(comments):\n",
    "    return [len(com.split()) if len(com.split()) < 25 else 25 for com in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_count = total_words(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25    15464\n",
       "4     14525\n",
       "5     13609\n",
       "6     12380\n",
       "7     10582\n",
       "8      9198\n",
       "9      7848\n",
       "10     6821\n",
       "11     5759\n",
       "12     5133\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(words_count).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_chars(comments):\n",
    "    return [len(com) if len(com) < 100 else 100 for com in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars_count = total_chars(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    30216\n",
       "28      2174\n",
       "30      2155\n",
       "26      2138\n",
       "27      2127\n",
       "31      2121\n",
       "29      2091\n",
       "33      2074\n",
       "25      2070\n",
       "32      2064\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(chars_count).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All comments features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_comments_features(coms):\n",
    "    features = pd.DataFrame()\n",
    "    features['with_emoji'] = with_emoji(coms)\n",
    "    big_letter, sents_count = sentence_stat(coms)\n",
    "    features['big_letter'] = big_letter\n",
    "    features['sents_count'] = sents_count\n",
    "    features['punct_)'] = punctuation_counts(coms, pattern='\\)+')\n",
    "    features['punct_('] = punctuation_counts(coms, pattern='\\(+')\n",
    "    features['punct_?'] = punctuation_counts(coms, pattern='\\?+')\n",
    "    features['punct_!'] = punctuation_counts(coms, pattern='\\!+')\n",
    "    features['punct_..'] = punctuation_counts(coms, pattern='[\\.]{2,}')\n",
    "    features['punct_1-9'] = punctuation_counts(coms, pattern='[0-9]{1,}')\n",
    "    features['punct_\"'] = punctuation_counts(coms, pattern='\".+\"')\n",
    "    features['eng_words'] = eng_words(coms, True)\n",
    "    features['mean_word_len'] = mean_word_length(coms)\n",
    "    features['caps'] = caps_words(coms)\n",
    "    features['em_proportion_rep'] = comments['em_proportion_rep'].values\n",
    "    features['em_proportion_no_rep'] = comments['em_proportion_no_rep'].values\n",
    "    # features['adj_proportion'] = adj_proportion\n",
    "    features['abc_proportion'] = comments['abc_proportion'].values\n",
    "    features['words_count'] = total_words(coms)\n",
    "    features['chars_count'] = total_chars(coms)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comment_features = get_comments_features(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comment_features_list = comment_features.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>with_emoji</th>\n",
       "      <th>big_letter</th>\n",
       "      <th>sents_count</th>\n",
       "      <th>punct_)</th>\n",
       "      <th>punct_(</th>\n",
       "      <th>punct_?</th>\n",
       "      <th>punct_!</th>\n",
       "      <th>punct_..</th>\n",
       "      <th>punct_1-9</th>\n",
       "      <th>punct_\"</th>\n",
       "      <th>eng_words</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>caps</th>\n",
       "      <th>em_proportion_rep</th>\n",
       "      <th>em_proportion_no_rep</th>\n",
       "      <th>abc_proportion</th>\n",
       "      <th>words_count</th>\n",
       "      <th>chars_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "      <td>131758.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.107348</td>\n",
       "      <td>0.707244</td>\n",
       "      <td>1.666183</td>\n",
       "      <td>0.230627</td>\n",
       "      <td>0.042396</td>\n",
       "      <td>0.202652</td>\n",
       "      <td>0.125776</td>\n",
       "      <td>0.142033</td>\n",
       "      <td>0.119439</td>\n",
       "      <td>0.053113</td>\n",
       "      <td>0.297779</td>\n",
       "      <td>4.662089</td>\n",
       "      <td>0.027171</td>\n",
       "      <td>0.003154</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.834683</td>\n",
       "      <td>11.547155</td>\n",
       "      <td>59.567396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.309557</td>\n",
       "      <td>0.455029</td>\n",
       "      <td>0.922643</td>\n",
       "      <td>0.421236</td>\n",
       "      <td>0.201491</td>\n",
       "      <td>0.401977</td>\n",
       "      <td>0.331598</td>\n",
       "      <td>0.349085</td>\n",
       "      <td>0.324305</td>\n",
       "      <td>0.224259</td>\n",
       "      <td>3.316524</td>\n",
       "      <td>0.970924</td>\n",
       "      <td>0.162582</td>\n",
       "      <td>0.011219</td>\n",
       "      <td>0.009081</td>\n",
       "      <td>0.120017</td>\n",
       "      <td>6.913353</td>\n",
       "      <td>29.130016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          with_emoji     big_letter    sents_count        punct_)  \\\n",
       "count  131758.000000  131758.000000  131758.000000  131758.000000   \n",
       "mean        0.107348       0.707244       1.666183       0.230627   \n",
       "std         0.309557       0.455029       0.922643       0.421236   \n",
       "min         0.000000       0.000000       1.000000       0.000000   \n",
       "25%         0.000000       0.000000       1.000000       0.000000   \n",
       "50%         0.000000       1.000000       1.000000       0.000000   \n",
       "75%         0.000000       1.000000       2.000000       0.000000   \n",
       "max         1.000000       1.000000       4.000000       1.000000   \n",
       "\n",
       "             punct_(        punct_?        punct_!       punct_..  \\\n",
       "count  131758.000000  131758.000000  131758.000000  131758.000000   \n",
       "mean        0.042396       0.202652       0.125776       0.142033   \n",
       "std         0.201491       0.401977       0.331598       0.349085   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "           punct_1-9        punct_\"      eng_words  mean_word_len  \\\n",
       "count  131758.000000  131758.000000  131758.000000  131758.000000   \n",
       "mean        0.119439       0.053113       0.297779       4.662089   \n",
       "std         0.324305       0.224259       3.316524       0.970924   \n",
       "min         0.000000       0.000000       0.000000       1.000000   \n",
       "25%         0.000000       0.000000       0.000000       4.000000   \n",
       "50%         0.000000       0.000000       0.000000       4.600000   \n",
       "75%         0.000000       0.000000       0.000000       5.200000   \n",
       "max         1.000000       1.000000     110.000000      37.000000   \n",
       "\n",
       "                caps  em_proportion_rep  em_proportion_no_rep  abc_proportion  \\\n",
       "count  131758.000000      131758.000000         131758.000000   131758.000000   \n",
       "mean        0.027171           0.003154              0.002672        0.834683   \n",
       "std         0.162582           0.011219              0.009081        0.120017   \n",
       "min         0.000000           0.000000              0.000000        0.500000   \n",
       "25%         0.000000           0.000000              0.000000        0.746667   \n",
       "50%         0.000000           0.000000              0.000000        0.861702   \n",
       "75%         0.000000           0.000000              0.000000        0.937500   \n",
       "max         1.000000           0.120000              0.080000        1.000000   \n",
       "\n",
       "         words_count    chars_count  \n",
       "count  131758.000000  131758.000000  \n",
       "mean       11.547155      59.567396  \n",
       "std         6.913353      29.130016  \n",
       "min         4.000000       7.000000  \n",
       "25%         6.000000      33.000000  \n",
       "50%         9.000000      54.000000  \n",
       "75%        16.000000      94.000000  \n",
       "max        25.000000     100.000000  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = comment_features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131758, 18)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = ensemble.RandomForestClassifier(100, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.524537386691 0.006830531033\n"
     ]
    }
   ],
   "source": [
    "baseline_scores = cross_val_score(rf, X, y, cv=5)\n",
    "print(baseline_scores.mean(), baseline_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.549560696258 0.0187862997332\n"
     ]
    }
   ],
   "source": [
    "baseline_scores = cross_val_score(gb, X, y, cv=5)\n",
    "print(baseline_scores.mean(), baseline_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, f_regression, mutual_info_regression, RFE,\\\n",
    "     SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(0.5)\n",
    "sel.fit(X, y)\n",
    "X_ = sel.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131758, 5)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.569005339723 0.00625938827059\n"
     ]
    }
   ],
   "source": [
    "baseline_scores = cross_val_score(lr, X_, y, cv=5)\n",
    "print(baseline_scores.mean(), baseline_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.fit(X_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sents_count', 0.10086455),\n",
       " ('eng_words', 0.099423632),\n",
       " ('mean_word_len', 0.34438041),\n",
       " ('words_count', 0.21757925),\n",
       " ('chars_count', 0.23775215)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(comment_features.columns.values[sel.get_support()], gb.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = pd.concat((comments.reset_index(drop=True), comment_features.reset_index(drop=True)),\n",
    "                     axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cross validation method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_df_balanced(df, by_col):\n",
    "    \"\"\"Make df balanced by binary columns named - by_col. Using oversampling\"\"\"\n",
    "    big_class = 0\n",
    "    small_class = 1\n",
    "    if df[by_col].value_counts()[0] < df[by_col].value_counts()[1]:\n",
    "        big_class = 1\n",
    "        small_class = 0\n",
    "    \n",
    "    delta = df[by_col].value_counts()[big_class] - df[by_col].value_counts()[small_class]\n",
    "    only_ing = df[df[by_col] == small_class]\n",
    "    to_add_indexes = np.random.randint(0, len(only_ing) - 1, delta)\n",
    "    df = pd.concat((df, only_ing.iloc[to_add_indexes]))\n",
    "\n",
    "    # shuffle after adding\n",
    "    df = df.iloc[np.random.permutation(df.shape[0])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_predict_to_n_user(comments, models, n=10, use_cache=True, debug=True, debug_score=True,\n",
    "                          with_additional=True, predict_proba=False, return_prediction=False):\n",
    "    unique_ids = None\n",
    "    if use_cache:\n",
    "        with open('unique_ids_{}.pkl'.format(n), 'rb') as f:\n",
    "            unique_ids = pickle.load(f)\n",
    "    else:\n",
    "        unique_ids = comments.from_id.value_counts()[comments.from_id.value_counts() >= n].index.values\n",
    "        additional_ids = comments.from_id.value_counts()[comments.from_id.value_counts() < n].index.values\n",
    "#         with open('unique_ids_{}.pkl'.format(n), 'wb') as f:\n",
    "#             pickle.dump(unique_ids, f)\n",
    "    \n",
    "    if debug:\n",
    "        print('{} - uniq peoples'.format(len(unique_ids)))\n",
    "        print('{} - additional peoples'.format(len(additional_ids)))\n",
    "    \n",
    "    train_idxs = unique_ids[:int(len(unique_ids) * 0.8)]\n",
    "    test_idxs = unique_ids[int(len(unique_ids) * 0.8):]\n",
    "\n",
    "    train_comments = comments[[i in train_idxs for i in comments.from_id]]\n",
    "    additional_comments = comments[[i in additional_ids for i in comments.from_id]]\n",
    "    train_comments = pd.concat((train_comments.reset_index(drop=True), additional_comments.reset_index(drop=True)))\n",
    "\n",
    "    test_comments = comments[[i in test_idxs for i in comments.from_id]]\n",
    "\n",
    "    if debug:\n",
    "        print('Before sampling:')\n",
    "        print(train_comments.is_gum.value_counts())\n",
    "        print('Additional comments:')\n",
    "        print(additional_comments.shape[0])\n",
    "    \n",
    "    train_comments = make_df_balanced(train_comments, 'is_gum')\n",
    "    \n",
    "    X_train, X_test = train_comments, test_comments\n",
    "    y_train, y_test = train_comments.is_gum.values, test_comments.is_gum.values\n",
    "    \n",
    "    # models\n",
    "    prediction_df = pd.DataFrame()\n",
    "    if debug_score:\n",
    "        print('Accuracy for comment:')\n",
    "    \n",
    "    cols = []\n",
    "    for model in models:\n",
    "        cols.append(model.name)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        if predict_proba:\n",
    "            prediction = model.predict_proba(X_test)\n",
    "            if prediction.shape[1] > 1:\n",
    "                prediction = prediction[:, 1]\n",
    "            else:\n",
    "                prediction = prediction.ravel()\n",
    "        else:\n",
    "            prediction = model.predict(X_test)\n",
    "        prediction_df[model.name] = prediction\n",
    "        \n",
    "        if debug_score:\n",
    "            print('Model: ', model.name)\n",
    "            if predict_proba:\n",
    "                print(accuracy_score(y_test, prediction > 0.5))\n",
    "            else:\n",
    "                print(accuracy_score(y_test, prediction))\n",
    "                \n",
    "    if predict_proba:\n",
    "        prediction_df['prediction'] = prediction_df.mean(axis=1)\n",
    "    else:\n",
    "        prediction_df['prediction'] = prediction_df.median(axis=1)\n",
    "        \n",
    "    if debug_score:\n",
    "        if predict_proba:\n",
    "            print('Mean of models:', accuracy_score(y_test, (prediction_df['prediction'].values > 0.5).astype(int)))\n",
    "        else:\n",
    "            print('Median of models:', accuracy_score(y_test, prediction_df['prediction'].values.astype(int)))\n",
    "    # print(test_comments.shape, prediction_df.shape)\n",
    "    test_comments = pd.concat((test_comments.reset_index(drop=True), prediction_df.reset_index(drop=True)), axis=1)\n",
    "    # print(test_comments.shape)\n",
    "    # test_comments['prediction'] = prediction\n",
    "    # y_true = test_comments.groupby('from_id').agg(np.median)['is_gum'].values\n",
    "    # return test_comments\n",
    "    if predict_proba:\n",
    "        grouped_median_test = test_comments.groupby('from_id').agg(np.mean)\n",
    "    else:\n",
    "        grouped_median_test = test_comments.groupby('from_id').agg(np.median)\n",
    "    # return test_comments.groupby('from_id')[cols].agg(np.median)\n",
    "    y_true = grouped_median_test['is_gum'].values\n",
    "    # print(y_true[:3])\n",
    "    if debug_score:\n",
    "        print('Accuracy for user:')\n",
    "\n",
    "    for model in models:\n",
    "        y_pred = grouped_median_test[model.name].values\n",
    "        # print(y_pred[:3])\n",
    "        # y_pred = np.floor(test_comments.groupby('from_id').agg(np.median)['prediction'].values)\n",
    "        if debug_score:\n",
    "            print('Model: ', model.name)\n",
    "            if predict_proba:\n",
    "                print(accuracy_score(y_true, (y_pred > 0.5).astype(int)))\n",
    "            else:\n",
    "                print(accuracy_score(y_true, y_pred.astype(int)))\n",
    "\n",
    "    if predict_proba:\n",
    "        y_pred_proba = grouped_median_test[cols].mean(axis=1).values\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    else:\n",
    "        y_pred = np.floor(grouped_median_test[cols].median(axis=1).values).astype(int)\n",
    "    med_of_models_score = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    if predict_proba:\n",
    "        y_pred = (grouped_median_test['prediction'].values > 0.5).astype(int)\n",
    "    else:\n",
    "        y_pred = np.floor(grouped_median_test['prediction'].values).astype(int)\n",
    "    med_of_av_models_score = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    if debug_score:\n",
    "        print('Median of models averaged per user:')\n",
    "        print(med_of_models_score)\n",
    "    \n",
    "    if debug_score:\n",
    "        print('Median of averaged model per user:')\n",
    "        print(med_of_av_models_score)\n",
    "    \n",
    "    if return_prediction: # for debug\n",
    "        return med_of_models_score, med_of_av_models_score, prediction_df, y_test\n",
    "    else:\n",
    "        return med_of_models_score, med_of_av_models_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, name='-'):\n",
    "        self.name = name\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        raise NotImplemented()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        raise NotImplemented()\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LrModelCount(Model):\n",
    "    def __init__(self, name='-', max_features=1000, analyzer='word', ngram_range=(1, 1), penalty='l2', C=1):\n",
    "        super().__init__(name)\n",
    "        self.vectorizer = CountVectorizer(max_features=max_features, analyzer=analyzer, ngram_range=ngram_range)\n",
    "        self.model = lm.LogisticRegression(penalty=penalty, C=C)\n",
    "        self._fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = self.vectorizer.fit_transform(X.text.values)\n",
    "        self.model.fit(X, y)\n",
    "        self._fitted = True\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = self.vectorizer.transform(X.text.values)\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = self.vectorizer.transform(X.text.values)\n",
    "        return self.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LrModelCountClear(Model):\n",
    "    def __init__(self, name='-', max_features=1000):\n",
    "        super().__init__(name)\n",
    "        self.vectorizer = CountVectorizer(max_features=max_features)\n",
    "        self.model = lm.LogisticRegression()\n",
    "        self._fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = self.vectorizer.fit_transform(X.clear_text.values)\n",
    "        self.model.fit(X, y)\n",
    "        self._fitted = True\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = self.vectorizer.transform(X.clear_text.values)\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = self.vectorizer.transform(X.clear_text.values)\n",
    "        return self.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LrModelTfidf(Model):\n",
    "    def __init__(self, name='-', max_features=1000, penalty='l2', C=1):\n",
    "        super().__init__(name)\n",
    "        self.vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "        self.model = lm.LogisticRegression(penalty=penalty, C=C)\n",
    "        self._fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = self.vectorizer.fit_transform(X.text.values)\n",
    "        self.model.fit(X, y)\n",
    "        self._fitted = True\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = self.vectorizer.transform(X.text.values)\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = self.vectorizer.transform(X.text.values)\n",
    "        return self.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeaturesModelXGB(Model):\n",
    "    def __init__(self, name='-', n_estimators=100, var_threshold=None, chi2_count=None):\n",
    "        super().__init__(name)\n",
    "        self.model = xgb.XGBClassifier(n_estimators=n_estimators)\n",
    "        if chi2_count is not None:\n",
    "            self.selector = SelectKBest(chi2, chi2_count)\n",
    "        elif var_threshold is not None:\n",
    "            self.selector = VarianceThreshold(var_threshold)\n",
    "        else:\n",
    "            raise Exception('var_threshold or chi2_count should be specified!')\n",
    "        self._fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = X[comment_features_list].values\n",
    "        X = self.selector.fit_transform(X, y)\n",
    "        self.model.fit(X, y)\n",
    "        self._fitted = True\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = X[comment_features_list].values\n",
    "        X = self.selector.transform(X)\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = X[comment_features_list].values\n",
    "        X = self.selector.transform(X)\n",
    "        return self.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "import keras.preprocessing.text\n",
    "np.random.seed(7)\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MlpModel(Model):\n",
    "    def __init__(self, name='-', max_features=1000, neurons=500, clear=False):\n",
    "        super().__init__(name)\n",
    "        self.clear = clear\n",
    "        self.vectorizer = CountVectorizer(max_features=max_features)\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(neurons, input_shape=(max_features,)))\n",
    "        self.model.add(Activation(PReLU()))\n",
    "        self.model.add(Dropout(0.3))\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.add(Activation('sigmoid'))\n",
    "\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        self._fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        text = X.text.values\n",
    "        if self.clear:\n",
    "            text = X.clear_text.values\n",
    "        X = self.vectorizer.fit_transform(text)\n",
    "        self.model.fit(X.toarray(), y,\n",
    "                    nb_epoch=3, batch_size=512,\n",
    "                    verbose=0) # , validation_split=0.1)\n",
    "        self._fitted = True\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "\n",
    "        text = X.text.values\n",
    "        if self.clear:\n",
    "            text = X.clear_text.values\n",
    "            \n",
    "        X = self.vectorizer.transform(text)\n",
    "        return self.model.predict_classes(X.toarray(), batch_size=512, verbose=0).ravel()\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "            \n",
    "        text = X.text.values\n",
    "        if self.clear:\n",
    "            text = X.clear_text.values\n",
    "            \n",
    "        X = self.vectorizer.transform(text)\n",
    "        return self.model.predict(X.toarray(), batch_size=512, verbose=0) #.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LstmModel(Model):\n",
    "    def __init__(self, name='-', nb_words=10000, embedding_vector_length=64, char_level=False, max_len=40,\n",
    "                 nb_epoch=3, clear=False):\n",
    "        super().__init__(name)\n",
    "        self.nb_words = nb_words\n",
    "        self.embedding_vector_length = embedding_vector_length\n",
    "        self.char_level = char_level\n",
    "        self.max_len = max_len\n",
    "        self.nb_epoch = nb_epoch\n",
    "        self.clear = clear\n",
    "        \n",
    "        self.vectorizer = keras.preprocessing.text.Tokenizer(nb_words=nb_words, lower=True, split=\" \",\n",
    "                                                             char_level=char_level)\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Embedding(nb_words, embedding_vector_length))\n",
    "        self.model.add(Dropout(0.4))\n",
    "        self.model.add(LSTM(64, return_sequences=True, dropout_W=0.3, dropout_U=0.3))\n",
    "        self.model.add(Dropout(0.3))\n",
    "        self.model.add(LSTM(64, return_sequences=False, dropout_W=0.2, dropout_U=0.2))\n",
    "        self.model.add(Dropout(0.3))\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        self._fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        text = X.text.values\n",
    "        if self.clear:\n",
    "            text = X.clear_text.values\n",
    "            \n",
    "        self.vectorizer.fit_on_texts(text) # clear_coms\n",
    "        X = self.vectorizer.texts_to_sequences(text)\n",
    "        X = sequence.pad_sequences(X, maxlen=self.max_len, padding='pre')\n",
    "        \n",
    "        self.model.fit(X, y, nb_epoch=self.nb_epoch, batch_size=512, verbose=0)\n",
    "        self._fitted = True\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "            \n",
    "        text = X.text.values\n",
    "        if self.clear:\n",
    "            text = X.clear_text.values\n",
    "            \n",
    "        X = self.vectorizer.texts_to_sequences(text)\n",
    "        X = sequence.pad_sequences(X, maxlen=self.max_len, padding='pre')\n",
    "        return self.model.predict_classes(X, batch_size=512, verbose=0).ravel()\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        \n",
    "        text = X.text.values\n",
    "        if self.clear:\n",
    "            text = X.clear_text.values\n",
    "            \n",
    "        X = self.vectorizer.texts_to_sequences(text)\n",
    "        X = sequence.pad_sequences(X, maxlen=self.max_len, padding='pre')\n",
    "        return self.model.predict(X, batch_size=512, verbose=0) #.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429 - uniq peoples\n",
      "4624 - additional peoples\n",
      "Before sampling:\n",
      "0.0    73488\n",
      "1.0    54723\n",
      "Name: is_gum, dtype: int64\n",
      "Additional comments:\n",
      "13244\n",
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.539047082041\n",
      "Model:  lstm_word_big\n",
      "0.531435015506\n",
      "Model:  lstm_word_clear\n",
      "0.527488018043\n",
      "Model:  lstm_char\n",
      "0.517056667606\n",
      "Model:  mlp\n",
      "0.533972371018\n",
      "Model:  mlp_big\n",
      "0.542712151114\n",
      "Model:  mlp_clear\n",
      "0.545249506625\n",
      "Model:  mlp_big_clear\n",
      "0.529179588385\n",
      "Model:  lr_count_2k_word_1\n",
      "0.543276007894\n",
      "Model:  lr_count_2k_word_12\n",
      "0.554271215111\n",
      "Model:  lr_count_2k_word_13\n",
      "0.550606146039\n",
      "Model:  lr_count_2k_char_33\n",
      "0.549478432478\n",
      "Model:  lr_count_2k_char_23\n",
      "0.558782069354\n",
      "Model:  lr_count_5k_word_12\n",
      "0.547786862137\n",
      "Model:  lr_count_5k_word_13\n",
      "0.538765153651\n",
      "Model:  lr_count_10k_word_13\n",
      "0.547504933747\n",
      "Model:  lr_count_5k_char_33\n",
      "0.554835071892\n",
      "Model:  lr_count_5k_char_23\n",
      "0.547786862137\n",
      "Model:  lr_clear_count_1k\n",
      "0.541020580772\n",
      "Model:  lr_clear_count_2k\n",
      "0.538483225261\n",
      "Model:  lr_clear_count_3k\n",
      "0.543839864674\n",
      "Model:  xgb_300_0\n",
      "0.534536227798\n",
      "Model:  xgb_200_0\n",
      "0.531435015506\n",
      "Model:  xgb_150_0.3\n",
      "0.540738652382\n",
      "Model:  xgb_100_0.5\n",
      "0.53707358331\n",
      "Model:  xgb_75_0.7\n",
      "0.533408514237\n",
      "Model:  lr_tfidf_1k\n",
      "0.550888074429\n",
      "Model:  lr_tfidf_2k\n",
      "0.544121793065\n",
      "Model:  lr_tfidf_3k\n",
      "0.538201296871\n",
      "Model:  lr_tfidf_5k\n",
      "0.543276007894\n",
      "Mean of models: 0.566394135889\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.618881118881\n",
      "Model:  lstm_word_big\n",
      "0.625874125874\n",
      "Model:  lstm_word_clear\n",
      "0.573426573427\n",
      "Model:  lstm_char\n",
      "0.562937062937\n",
      "Model:  mlp\n",
      "0.615384615385\n",
      "Model:  mlp_big\n",
      "0.618881118881\n",
      "Model:  mlp_clear\n",
      "0.587412587413\n",
      "Model:  mlp_big_clear\n",
      "0.615384615385\n",
      "Model:  lr_count_2k_word_1\n",
      "0.660839160839\n",
      "Model:  lr_count_2k_word_12\n",
      "0.65034965035\n",
      "Model:  lr_count_2k_word_13\n",
      "0.65034965035\n",
      "Model:  lr_count_2k_char_33\n",
      "0.63986013986\n",
      "Model:  lr_count_2k_char_23\n",
      "0.688811188811\n",
      "Model:  lr_count_5k_word_12\n",
      "0.622377622378\n",
      "Model:  lr_count_5k_word_13\n",
      "0.601398601399\n",
      "Model:  lr_count_10k_word_13\n",
      "0.604895104895\n",
      "Model:  lr_count_5k_char_33\n",
      "0.643356643357\n",
      "Model:  lr_count_5k_char_23\n",
      "0.632867132867\n",
      "Model:  lr_clear_count_1k\n",
      "0.576923076923\n",
      "Model:  lr_clear_count_2k\n",
      "0.56993006993\n",
      "Model:  lr_clear_count_3k\n",
      "0.604895104895\n",
      "Model:  xgb_300_0\n",
      "0.576923076923\n",
      "Model:  xgb_200_0\n",
      "0.576923076923\n",
      "Model:  xgb_150_0.3\n",
      "0.604895104895\n",
      "Model:  xgb_100_0.5\n",
      "0.587412587413\n",
      "Model:  xgb_75_0.7\n",
      "0.594405594406\n",
      "Model:  lr_tfidf_1k\n",
      "0.611888111888\n",
      "Model:  lr_tfidf_2k\n",
      "0.643356643357\n",
      "Model:  lr_tfidf_3k\n",
      "0.636363636364\n",
      "Model:  lr_tfidf_5k\n",
      "0.625874125874\n",
      "Median of models averaged per user:\n",
      "0.664335664336\n",
      "Median of averaged model per user:\n",
      "0.664335664336\n",
      "CPU times: user 8h 13min 17s, sys: 48min 20s, total: 9h 1min 37s\n",
      "Wall time: 2h 38min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(0)\n",
    "s1, s2, pr, y_t = fit_predict_to_n_user(comments,\n",
    "        [\n",
    "            LstmModel('lstm_word', nb_words=5000, nb_epoch=4),\n",
    "            LstmModel('lstm_word_big', nb_words=10000, nb_epoch=5),\n",
    "            LstmModel('lstm_word_clear', nb_words=5000, nb_epoch=4, clear=True),\n",
    "            LstmModel('lstm_char', nb_epoch=5, nb_words=100, char_level=True, max_len=100),\n",
    "            \n",
    "            MlpModel('mlp', neurons=400),\n",
    "            MlpModel('mlp_big', max_features=3000, neurons=700),\n",
    "            MlpModel('mlp_clear', neurons=400, clear=True),\n",
    "            MlpModel('mlp_big_clear', max_features=2000, neurons=600, clear=True),\n",
    "\n",
    "            LrModelCount('lr_count_2k_word_1', 2000),\n",
    "            LrModelCount('lr_count_2k_word_12', 2000, ngram_range=(1, 2)),\n",
    "            LrModelCount('lr_count_2k_word_13', 2000, ngram_range=(1, 3)),\n",
    "\n",
    "            LrModelCount('lr_count_2k_char_33', 2000, 'char', (3, 3)),\n",
    "            LrModelCount('lr_count_2k_char_23', 2000, 'char', (2, 3)),\n",
    "\n",
    "            LrModelCount('lr_count_5k_word_12', 5000, ngram_range=(1, 2)),\n",
    "            LrModelCount('lr_count_5k_word_13', 5000, ngram_range=(1, 3)),\n",
    "            \n",
    "            LrModelCount('lr_count_10k_word_13', 10000, ngram_range=(1, 3)),\n",
    "            \n",
    "            LrModelCount('lr_count_5k_char_33', 5000, 'char', (3, 3)),\n",
    "            LrModelCount('lr_count_5k_char_23', 5000, 'char', (2, 3)),\n",
    "\n",
    "\n",
    "            LrModelCountClear('lr_clear_count_1k', 1000),\n",
    "            LrModelCountClear('lr_clear_count_2k', 2000),\n",
    "            LrModelCountClear('lr_clear_count_3k', 3000),\n",
    "\n",
    "            FeaturesModelXGB('xgb_300_0', n_estimators=300, var_threshold=0.0),\n",
    "            FeaturesModelXGB('xgb_200_0', n_estimators=200, var_threshold=0.0),\n",
    "            FeaturesModelXGB('xgb_150_0.3', n_estimators=150, var_threshold=0.3),\n",
    "            FeaturesModelXGB('xgb_100_0.5', n_estimators=100, var_threshold=0.5),\n",
    "            FeaturesModelXGB('xgb_75_0.7', n_estimators=75, var_threshold=0.7),\n",
    "            \n",
    "            LrModelTfidf('lr_tfidf_1k', 1000),\n",
    "            LrModelTfidf('lr_tfidf_2k', 2000),\n",
    "            LrModelTfidf('lr_tfidf_3k', 3000),\n",
    "            LrModelTfidf('lr_tfidf_5k', 5000),\n",
    "        ], 11, False, with_additional=True, debug=True, predict_proba=True, return_prediction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lstm_word</th>\n",
       "      <th>lstm_word_big</th>\n",
       "      <th>lstm_word_clear</th>\n",
       "      <th>lstm_char</th>\n",
       "      <th>mlp</th>\n",
       "      <th>mlp_big</th>\n",
       "      <th>mlp_clear</th>\n",
       "      <th>mlp_big_clear</th>\n",
       "      <th>lr_count_2k_word_1</th>\n",
       "      <th>lr_count_2k_word_12</th>\n",
       "      <th>...</th>\n",
       "      <th>xgb_300_0</th>\n",
       "      <th>xgb_200_0</th>\n",
       "      <th>xgb_150_0.3</th>\n",
       "      <th>xgb_100_0.5</th>\n",
       "      <th>xgb_75_0.7</th>\n",
       "      <th>lr_tfidf_1k</th>\n",
       "      <th>lr_tfidf_2k</th>\n",
       "      <th>lr_tfidf_3k</th>\n",
       "      <th>lr_tfidf_5k</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "      <td>3547.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.494524</td>\n",
       "      <td>0.479183</td>\n",
       "      <td>0.479653</td>\n",
       "      <td>0.494375</td>\n",
       "      <td>0.500112</td>\n",
       "      <td>0.484483</td>\n",
       "      <td>0.482043</td>\n",
       "      <td>0.487802</td>\n",
       "      <td>0.501548</td>\n",
       "      <td>0.499140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497313</td>\n",
       "      <td>0.497783</td>\n",
       "      <td>0.496815</td>\n",
       "      <td>0.497104</td>\n",
       "      <td>0.497136</td>\n",
       "      <td>0.500486</td>\n",
       "      <td>0.500778</td>\n",
       "      <td>0.500119</td>\n",
       "      <td>0.497918</td>\n",
       "      <td>0.496510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.114672</td>\n",
       "      <td>0.157980</td>\n",
       "      <td>0.108216</td>\n",
       "      <td>0.057088</td>\n",
       "      <td>0.111211</td>\n",
       "      <td>0.168537</td>\n",
       "      <td>0.107304</td>\n",
       "      <td>0.143095</td>\n",
       "      <td>0.109158</td>\n",
       "      <td>0.109086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062143</td>\n",
       "      <td>0.057566</td>\n",
       "      <td>0.037256</td>\n",
       "      <td>0.034077</td>\n",
       "      <td>0.032231</td>\n",
       "      <td>0.086301</td>\n",
       "      <td>0.100598</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.116778</td>\n",
       "      <td>0.075273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.105407</td>\n",
       "      <td>0.023086</td>\n",
       "      <td>0.076239</td>\n",
       "      <td>0.132589</td>\n",
       "      <td>0.057707</td>\n",
       "      <td>0.022394</td>\n",
       "      <td>0.073027</td>\n",
       "      <td>0.042001</td>\n",
       "      <td>0.066863</td>\n",
       "      <td>0.082034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175013</td>\n",
       "      <td>0.187309</td>\n",
       "      <td>0.317216</td>\n",
       "      <td>0.335991</td>\n",
       "      <td>0.352048</td>\n",
       "      <td>0.190727</td>\n",
       "      <td>0.174869</td>\n",
       "      <td>0.165873</td>\n",
       "      <td>0.140537</td>\n",
       "      <td>0.208697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.423163</td>\n",
       "      <td>0.382424</td>\n",
       "      <td>0.413417</td>\n",
       "      <td>0.476266</td>\n",
       "      <td>0.435940</td>\n",
       "      <td>0.375887</td>\n",
       "      <td>0.421662</td>\n",
       "      <td>0.401399</td>\n",
       "      <td>0.443878</td>\n",
       "      <td>0.438658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456726</td>\n",
       "      <td>0.459890</td>\n",
       "      <td>0.475556</td>\n",
       "      <td>0.476443</td>\n",
       "      <td>0.477311</td>\n",
       "      <td>0.441617</td>\n",
       "      <td>0.433975</td>\n",
       "      <td>0.426486</td>\n",
       "      <td>0.416937</td>\n",
       "      <td>0.450115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.499839</td>\n",
       "      <td>0.483596</td>\n",
       "      <td>0.483637</td>\n",
       "      <td>0.495477</td>\n",
       "      <td>0.500240</td>\n",
       "      <td>0.481818</td>\n",
       "      <td>0.481765</td>\n",
       "      <td>0.492121</td>\n",
       "      <td>0.499653</td>\n",
       "      <td>0.494559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497934</td>\n",
       "      <td>0.499032</td>\n",
       "      <td>0.493646</td>\n",
       "      <td>0.494543</td>\n",
       "      <td>0.496264</td>\n",
       "      <td>0.502596</td>\n",
       "      <td>0.503248</td>\n",
       "      <td>0.501762</td>\n",
       "      <td>0.500559</td>\n",
       "      <td>0.496599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.564370</td>\n",
       "      <td>0.576147</td>\n",
       "      <td>0.546913</td>\n",
       "      <td>0.516328</td>\n",
       "      <td>0.563930</td>\n",
       "      <td>0.590431</td>\n",
       "      <td>0.541576</td>\n",
       "      <td>0.573458</td>\n",
       "      <td>0.556635</td>\n",
       "      <td>0.555431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537620</td>\n",
       "      <td>0.536039</td>\n",
       "      <td>0.517807</td>\n",
       "      <td>0.517729</td>\n",
       "      <td>0.516583</td>\n",
       "      <td>0.557469</td>\n",
       "      <td>0.566922</td>\n",
       "      <td>0.572704</td>\n",
       "      <td>0.576888</td>\n",
       "      <td>0.543353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.862354</td>\n",
       "      <td>0.932236</td>\n",
       "      <td>0.877540</td>\n",
       "      <td>0.669623</td>\n",
       "      <td>0.940165</td>\n",
       "      <td>0.991717</td>\n",
       "      <td>0.947259</td>\n",
       "      <td>0.974586</td>\n",
       "      <td>0.964229</td>\n",
       "      <td>0.964423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799207</td>\n",
       "      <td>0.762947</td>\n",
       "      <td>0.727886</td>\n",
       "      <td>0.695030</td>\n",
       "      <td>0.661049</td>\n",
       "      <td>0.840245</td>\n",
       "      <td>0.841259</td>\n",
       "      <td>0.870749</td>\n",
       "      <td>0.878528</td>\n",
       "      <td>0.829986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lstm_word  lstm_word_big  lstm_word_clear    lstm_char          mlp  \\\n",
       "count  3547.000000    3547.000000      3547.000000  3547.000000  3547.000000   \n",
       "mean      0.494524       0.479183         0.479653     0.494375     0.500112   \n",
       "std       0.114672       0.157980         0.108216     0.057088     0.111211   \n",
       "min       0.105407       0.023086         0.076239     0.132589     0.057707   \n",
       "25%       0.423163       0.382424         0.413417     0.476266     0.435940   \n",
       "50%       0.499839       0.483596         0.483637     0.495477     0.500240   \n",
       "75%       0.564370       0.576147         0.546913     0.516328     0.563930   \n",
       "max       0.862354       0.932236         0.877540     0.669623     0.940165   \n",
       "\n",
       "           mlp_big    mlp_clear  mlp_big_clear  lr_count_2k_word_1  \\\n",
       "count  3547.000000  3547.000000    3547.000000         3547.000000   \n",
       "mean      0.484483     0.482043       0.487802            0.501548   \n",
       "std       0.168537     0.107304       0.143095            0.109158   \n",
       "min       0.022394     0.073027       0.042001            0.066863   \n",
       "25%       0.375887     0.421662       0.401399            0.443878   \n",
       "50%       0.481818     0.481765       0.492121            0.499653   \n",
       "75%       0.590431     0.541576       0.573458            0.556635   \n",
       "max       0.991717     0.947259       0.974586            0.964229   \n",
       "\n",
       "       lr_count_2k_word_12     ...         xgb_300_0    xgb_200_0  \\\n",
       "count          3547.000000     ...       3547.000000  3547.000000   \n",
       "mean              0.499140     ...          0.497313     0.497783   \n",
       "std               0.109086     ...          0.062143     0.057566   \n",
       "min               0.082034     ...          0.175013     0.187309   \n",
       "25%               0.438658     ...          0.456726     0.459890   \n",
       "50%               0.494559     ...          0.497934     0.499032   \n",
       "75%               0.555431     ...          0.537620     0.536039   \n",
       "max               0.964423     ...          0.799207     0.762947   \n",
       "\n",
       "       xgb_150_0.3  xgb_100_0.5   xgb_75_0.7  lr_tfidf_1k  lr_tfidf_2k  \\\n",
       "count  3547.000000  3547.000000  3547.000000  3547.000000  3547.000000   \n",
       "mean      0.496815     0.497104     0.497136     0.500486     0.500778   \n",
       "std       0.037256     0.034077     0.032231     0.086301     0.100598   \n",
       "min       0.317216     0.335991     0.352048     0.190727     0.174869   \n",
       "25%       0.475556     0.476443     0.477311     0.441617     0.433975   \n",
       "50%       0.493646     0.494543     0.496264     0.502596     0.503248   \n",
       "75%       0.517807     0.517729     0.516583     0.557469     0.566922   \n",
       "max       0.727886     0.695030     0.661049     0.840245     0.841259   \n",
       "\n",
       "       lr_tfidf_3k  lr_tfidf_5k   prediction  \n",
       "count  3547.000000  3547.000000  3547.000000  \n",
       "mean      0.500119     0.497918     0.496510  \n",
       "std       0.108821     0.116778     0.075273  \n",
       "min       0.165873     0.140537     0.208697  \n",
       "25%       0.426486     0.416937     0.450115  \n",
       "50%       0.501762     0.500559     0.496599  \n",
       "75%       0.572704     0.576888     0.543353  \n",
       "max       0.870749     0.878528     0.829986  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fec4146eef0>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAosAAAKaCAYAAABWYBMpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncRzHcRynkP8Pw5qnLsi8dagAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fec36ee21d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(pr.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve, f1_score, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3547, 31)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndUkqxFCXpEL+H4c4YxyZrgUVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fec22b20b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pr.prediction.values, bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56639413588948406"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_t, pr.prediction.values > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6374974442854221"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_t, pr.prediction.values > 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fpr, tpr = roc_curve(y_t, pr.drop('prediction', axis=1).values)\n",
    "fpr, tpr, _ = roc_curve(y_t, pr.prediction.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fec227a98d0>]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRDxOQS4i4nH/DwqKjA0Iq03wAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fec21704358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58141052631578949"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fec2276b160>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAD4CAYAAAA94VfoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fec222540b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_t, (pr.prediction.values > 0.5).astype(int))\n",
    "cm =  cm / cm.sum() #[np.newaxis]\n",
    "sns.heatmap(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection model with l1 lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = lm.LogisticRegression('l1', C=0.3)\n",
    "lr.fit(pr.drop('prediction', axis=1).values, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lstm_word', 0.0),\n",
       " ('lstm_word_big', 0.0),\n",
       " ('lstm_word_clear', 0.0),\n",
       " ('lstm_char', 0.0),\n",
       " ('mlp', 0.0),\n",
       " ('mlp_clear', 0.0),\n",
       " ('mlp_big_clear', 0.0),\n",
       " ('lr_count_2k_word_1', 0.0),\n",
       " ('lr_count_2k_word_13', 0.0),\n",
       " ('lr_count_2k_char_33', 0.0),\n",
       " ('lr_count_5k_word_13', 0.0),\n",
       " ('lr_count_10k_word_13', 0.0),\n",
       " ('lr_count_5k_char_23', 0.0),\n",
       " ('lr_clear_count_1k', 0.0),\n",
       " ('lr_clear_count_2k', 0.0),\n",
       " ('lr_clear_count_3k', 0.0),\n",
       " ('xgb_200_0', 0.0),\n",
       " ('xgb_150_0.3', 0.0),\n",
       " ('xgb_100_0.5', 0.0),\n",
       " ('xgb_75_0.7', 0.0),\n",
       " ('lr_tfidf_1k', 0.0),\n",
       " ('lr_tfidf_2k', 0.0),\n",
       " ('lr_tfidf_3k', 0.0),\n",
       " ('mlp_big', 0.079578809730879926),\n",
       " ('lr_tfidf_5k', 0.10877022807245063),\n",
       " ('xgb_300_0', 0.18565235883895151),\n",
       " ('lr_count_5k_word_12', 0.22940280716904571),\n",
       " ('lr_count_5k_char_33', 0.27444551864820244),\n",
       " ('lr_count_2k_word_12', 0.62057739526434041),\n",
       " ('lr_count_2k_char_23', 1.4703878156466577)]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(pr.columns[:-1], lr.coef_.ravel())), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best = list(filter(lambda x: x[1] != 0.0, zip(pr.columns[:-1], lr.coef_.ravel())))\n",
    "best_model_names = [x[0] for x in best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58519362041467304"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_t, pr[best_model_names].mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using best models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the best models based on single comment score, user score and coef before model in ridge regression on prediction from all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429 - uniq peoples\n",
      "4624 - additional peoples\n",
      "Before sampling:\n",
      "0.0    73488\n",
      "1.0    54723\n",
      "Name: is_gum, dtype: int64\n",
      "Additional comments:\n",
      "13244\n",
      "Accuracy for comment:\n",
      "Model:  lr_tfidf_5k\n",
      "0.540174795602\n",
      "Model:  lr_tfidf_2k\n",
      "0.542148294333\n",
      "Model:  lr_count_5k_word_12\n",
      "0.545813363406\n",
      "Model:  lr_count_5k_char_33\n",
      "0.546095291796\n",
      "Model:  lr_count_2k_char_23\n",
      "0.558782069354\n",
      "Model:  lr_count_2k_word_1\n",
      "0.535382012969\n",
      "Model:  lr_count_2k_word_12\n",
      "0.5517338596\n",
      "Median of models: 0.544685649845\n",
      "Accuracy for user:\n",
      "Model:  lr_tfidf_5k\n",
      "0.611888111888\n",
      "Model:  lr_tfidf_2k\n",
      "0.608391608392\n",
      "Model:  lr_count_5k_word_12\n",
      "0.618881118881\n",
      "Model:  lr_count_5k_char_33\n",
      "0.643356643357\n",
      "Model:  lr_count_2k_char_23\n",
      "0.615384615385\n",
      "Model:  lr_count_2k_word_1\n",
      "0.604895104895\n",
      "Model:  lr_count_2k_word_12\n",
      "0.65034965035\n",
      "Median of models averaged per user:\n",
      "0.643356643357\n",
      "Median of averaged model per user:\n",
      "0.629370629371\n",
      "CPU times: user 3min 15s, sys: 2.48 s, total: 3min 18s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(0)\n",
    "fit_predict_to_n_user(comments,\n",
    "        [\n",
    "            LrModelTfidf('lr_tfidf_2k', 2000),\n",
    "            \n",
    "            LrModelCount('lr_count_5k_word_12', 5000, ngram_range=(1, 2)),\n",
    "            LrModelCount('lr_count_5k_char_33', 5000, 'char', (3, 3)),\n",
    "            \n",
    "            LrModelCount('lr_count_2k_char_23', 2000, 'char', (2, 3)), # best\n",
    "            \n",
    "            LrModelCount('lr_count_2k_word_1', 2000), # best\n",
    "            LrModelCount('lr_count_2k_word_12', 2000, ngram_range=(1, 2)),\n",
    "        ], 11, False, with_additional=True, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy for single user - 0.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429 - uniq peoples\n",
      "4624 - additional peoples\n",
      "Before sampling:\n",
      "0.0    73488\n",
      "1.0    54723\n",
      "Name: is_gum, dtype: int64\n",
      "Additional comments:\n",
      "13244\n",
      "Accuracy for comment:\n",
      "Model:  lr_tfidf_2k\n",
      "0.53763744009\n",
      "Model:  lr_count_5k_word_12\n",
      "0.553707358331\n",
      "Model:  lr_count_5k_char_33\n",
      "0.558782069354\n",
      "Model:  lr_count_2k_char_23\n",
      "0.561037496476\n",
      "Model:  lr_count_2k_word_1\n",
      "0.543839864674\n",
      "Model:  lr_count_2k_word_12\n",
      "0.551451931209\n",
      "Mean of models: 0.563010995207\n",
      "Accuracy for user:\n",
      "Model:  lr_tfidf_2k\n",
      "0.625874125874\n",
      "Model:  lr_count_5k_word_12\n",
      "0.65034965035\n",
      "Model:  lr_count_5k_char_33\n",
      "0.664335664336\n",
      "Model:  lr_count_2k_char_23\n",
      "0.667832167832\n",
      "Model:  lr_count_2k_word_1\n",
      "0.65034965035\n",
      "Model:  lr_count_2k_word_12\n",
      "0.65034965035\n",
      "Median of models averaged per user:\n",
      "0.674825174825\n",
      "Median of averaged model per user:\n",
      "0.674825174825\n",
      "CPU times: user 1min 55s, sys: 916 ms, total: 1min 56s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(0)\n",
    "fit_predict_to_n_user(comments,\n",
    "        [\n",
    "            LrModelTfidf('lr_tfidf_2k', 2000, penalty='l2', C=0.05),\n",
    "            \n",
    "            LrModelCount('lr_count_5k_word_12', 5000, ngram_range=(1, 2), penalty='l2', C=0.05),\n",
    "            LrModelCount('lr_count_5k_char_33', 5000, 'char', (3, 3), penalty='l2', C=0.05),\n",
    "            \n",
    "            LrModelCount('lr_count_2k_char_23', 2000, 'char', (2, 3), penalty='l2', C=0.05), # best\n",
    "            \n",
    "            LrModelCount('lr_count_2k_word_1', 2000, penalty='l2', C=0.05), # best\n",
    "            LrModelCount('lr_count_2k_word_12', 2000, ngram_range=(1, 2), penalty='l2', C=0.05),\n",
    "        ], 11, False, with_additional=True, debug=True, predict_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429 - uniq peoples\n",
      "4624 - additional peoples\n",
      "Before sampling:\n",
      "0.0    73488\n",
      "1.0    54723\n",
      "Name: is_gum, dtype: int64\n",
      "Additional comments:\n",
      "13244\n",
      "Accuracy for comment:\n",
      "Model:  lr_tfidf_2k\n",
      "0.544403721455\n",
      "Model:  lr_count_5k_word_12\n",
      "0.548350718917\n",
      "Model:  lr_count_5k_char_33\n",
      "0.554553143502\n",
      "Model:  lr_count_2k_char_23\n",
      "0.561319424866\n",
      "Model:  lr_count_2k_word_1\n",
      "0.543276007894\n",
      "Model:  lr_count_2k_word_12\n",
      "0.554271215111\n",
      "Mean of models: 0.563856780378\n",
      "Accuracy for user:\n",
      "Model:  lr_tfidf_2k\n",
      "0.63986013986\n",
      "Model:  lr_count_5k_word_12\n",
      "0.664335664336\n",
      "Model:  lr_count_5k_char_33\n",
      "0.65034965035\n",
      "Model:  lr_count_2k_char_23\n",
      "0.660839160839\n",
      "Model:  lr_count_2k_word_1\n",
      "0.653846153846\n",
      "Model:  lr_count_2k_word_12\n",
      "0.65034965035\n",
      "Median of models averaged per user:\n",
      "0.674825174825\n",
      "Median of averaged model per user:\n",
      "0.674825174825\n",
      "CPU times: user 4min 34s, sys: 468 ms, total: 4min 35s\n",
      "Wall time: 4min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(0)\n",
    "fit_predict_to_n_user(comments,\n",
    "        [\n",
    "            LrModelTfidf('lr_tfidf_2k', 2000, penalty='l1', C=0.5),\n",
    "            \n",
    "            LrModelCount('lr_count_5k_word_12', 5000, ngram_range=(1, 2), penalty='l1', C=0.5),\n",
    "            LrModelCount('lr_count_5k_char_33', 5000, 'char', (3, 3), penalty='l1', C=0.5),\n",
    "            \n",
    "            LrModelCount('lr_count_2k_char_23', 2000, 'char', (2, 3), penalty='l1', C=0.5), # best\n",
    "            \n",
    "            LrModelCount('lr_count_2k_word_1', 2000, penalty='l1', C=0.5), # best\n",
    "            LrModelCount('lr_count_2k_word_12', 2000, ngram_range=(1, 2), penalty='l1', C=0.5),\n",
    "        ], 11, False, with_additional=True, debug=True, predict_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting for one user in a wild"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AverageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AverageModel():\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        self._fitted = False\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for m in self.models:\n",
    "            m.fit(X, y)\n",
    "        self._fitted = True\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        \n",
    "        predictions = np.hstack([np.expand_dims(m.predict(X), -1) for m in self.models])\n",
    "        predictions = (np.median(predictions, axis=1) > 0.5).astype(int)\n",
    "        return predictions\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        \n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            prediction = model.predict_proba(X)\n",
    "            if prediction.shape[1] > 1:\n",
    "                prediction = prediction[:, 1]\n",
    "            else:\n",
    "                prediction = prediction.ravel()\n",
    "            predictions.append(prediction)\n",
    "                \n",
    "        predictions = np.hstack([np.expand_dims(p, -1) for p in predictions])\n",
    "        predictions = np.mean(predictions, axis=1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "av_model = AverageModel([\n",
    "            LrModelTfidf('lr_tfidf_2k', 2000, penalty='l1', C=0.5),\n",
    "            \n",
    "            LrModelCount('lr_count_5k_word_12', 5000, ngram_range=(1, 2), penalty='l1', C=0.5),\n",
    "            LrModelCount('lr_count_5k_char_33', 5000, 'char', (3, 3), penalty='l1', C=0.5),\n",
    "            \n",
    "            LrModelCount('lr_count_2k_char_23', 2000, 'char', (2, 3), penalty='l1', C=0.5), # best\n",
    "            \n",
    "            LrModelCount('lr_count_2k_word_1', 2000, penalty='l1', C=0.5), # best\n",
    "            LrModelCount('lr_count_2k_word_12', 2000, ngram_range=(1, 2), penalty='l1', C=0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_ids = comments.from_id.value_counts()[comments.from_id.value_counts() >= 11].index.values\n",
    "additional_ids = comments.from_id.value_counts()[comments.from_id.value_counts() < 11].index.values\n",
    "\n",
    "train_idxs = unique_ids[:int(len(unique_ids) * 0.8)]\n",
    "test_idxs = unique_ids[int(len(unique_ids) * 0.8):]\n",
    "\n",
    "train_comments = comments[[i in train_idxs for i in comments.from_id]]\n",
    "additional_comments = comments[[i in additional_ids for i in comments.from_id]]\n",
    "train_comments = pd.concat((train_comments.reset_index(drop=True), additional_comments.reset_index(drop=True)))\n",
    "\n",
    "test_comments = comments[[i in test_idxs for i in comments.from_id]]\n",
    "\n",
    "train_comments = make_df_balanced(train_comments, 'is_gum')\n",
    "\n",
    "X_train, X_test = train_comments, test_comments\n",
    "y_train, y_test = train_comments.is_gum.values, test_comments.is_gum.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "av_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr = av_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55624471384268392"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr = av_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56075556808570626"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pr > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_coms = ['–≠–π —Ç—ã –∞ –Ω—É –±—ã—Ä–æ –æ—Ç–æ—à–µ–ª –æ—Ç –º–æ–µ–π –º–∞—à–∏–Ω—ã!!!',\n",
    "           '–í—á–µ—Ä–∞ –Ω–∞ –≤–æ–≥—Ä–µ—Å–µ —Ç–∞–∫—É—é –∞–≤–∞—Ä–∏—é –≤–∏–¥–µ–ª',\n",
    "           '–°–ª—ã—à–∞–ª–∏, –ø—Ä–æ–µ–∑–¥ –¥–æ 17—Ä –ø–æ–¥–æ—Ä–æ–∂–∞–ª?)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_coms_df = pd.DataFrame(my_coms, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.52118789,  0.39955414,  0.30648223])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_model.predict_proba(my_coms_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.52385131,  0.43406523,  0.31261936])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_model.predict_proba(my_coms_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELI5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_model = LrModelCount('lr_count_5k_word_12', 5000, ngram_range=(1, 2), penalty='l2', C=0.05)\n",
    "lr_model_char = LrModelCount('lr_count_5k_char_23', 5000, 'char', (2, 3), penalty='l2', C=0.05)\n",
    "lr_model_tfidf = LrModelTfidf('lr_tfidf_5k', 5000, penalty='l2', C=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_model.fit(X_train, y_train)\n",
    "lr_model_char.fit(X_train, y_train)\n",
    "lr_model_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4BLaR1MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3e434cda20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lr_model_tfidf.model.coef_.ravel(), bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10142533])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_tfidf.model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1.0\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 81.21%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.987\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≤–∞—â—â–µ\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.29%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.764\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –º—É–∂—á–∏–Ω—ã\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.67%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.738\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Å–æ–≥–ª–∞—Å–Ω–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.71%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.735\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≤–∏–∫–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.96%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.718\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –∫–æ—à–º–∞—Ä\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.45%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.685\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ñ–∏–≥–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.25%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.632\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ö–æ—Ç–µ–ª–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.36%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.625\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ö–∏\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.67%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.604\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≤—Ä–∞—á–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.590\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –ø–æ–Ω—è–ª–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.42%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.556\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –º—É–∂\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.61%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.544\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –¥—É–º–∞–ª–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.67%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.541\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≤–∞–∏\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.74%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.536\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≤–∏–¥–µ–ª–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.80%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.533\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        xd\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.15%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.511\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –¥–æ–±—Ä–æ–≥–æ —É—Ç—Ä–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.18%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.509\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –Ω–∞—Ö—Ä–µ–Ω–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.25%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.505\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –ø–æ—Ç–æ–º—É —á—Ç–æ\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.27%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.504\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≤—Ä–∞—á\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.32%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.500\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –º—É–∂—á–∏–Ω\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.32%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 2443 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.74%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 2518 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.74%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.416\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ç–æ–µ—Å—Ç—å\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.74%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.416\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –∑–∞—Ä–ø–ª–∞—Ç–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.72%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.417\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –ø—Ä–æ—Å—Ç\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.50%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.429\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ç–ø\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.47%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.432\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –¥–∞–ª–µ–µ\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.47%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.432\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≥—Ä–∞–¥\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.44%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.433\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –ø–æ–≤—Ç–æ—Ä—é—Å—å\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.25%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.444\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –º–∞—Ä—à—Ä—É—Ç\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.07%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.455\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –ø–ø—Ü\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.03%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.458\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –ø–æ–ª—é–±–æ–º—É\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.99%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.460\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ç–∏–ø–∏—á–Ω—ã–π\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.95%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.462\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ä–∞–¥–æ–≤–∞—Ç—å—Å—è\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.82%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.470\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –Ω–µ—Ç—É\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.82%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.470\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≤–æ—Ç —Ç–µ–±–µ\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.72%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.476\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –∫—Ä—ã–º\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.63%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.482\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ç–≤\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.08%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.515\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≥–æ—Å–ø–æ–¥–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.80%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.532\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ç–∞–∫–∂–µ\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.64%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.672\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –º—Å–∫\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.079\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≥–≥\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(lr_model.model, vec=lr_model.vectorizer, top=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1.0\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.446\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ^^\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.53%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.653\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>üòä\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.585\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        .)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.485\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –æ)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.87%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.471\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>=\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.98%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.463\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –º)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.04%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.459\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –∞)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.10%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.455\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –Ω–æ—Ç\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.25%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.444\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ?)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.37%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.435\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –º—É–∂\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.58%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.421\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Å)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.59%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.420\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        !))\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.66%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.415\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>–∂<span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0 0 0.1em\" title=\"A space symbol\">&emsp;</span>\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.70%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.412\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ä!\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.70%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.412\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>)<span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0 0 0.1em\" title=\"A space symbol\">&emsp;</span>\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.72%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.410\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>—Ö–∏\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.88%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.399\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Å—Å–Ω\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.386\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —è–∫–∏\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.20%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.377\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –∏)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.25%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.373\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –ª—É–π\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.25%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 2530 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.39%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 2431 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.364\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ü–∏–æ\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.35%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.366\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        -–≤\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.34%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.367\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ,–∞<span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0 0 0.1em\" title=\"A space symbol\">&emsp;</span>\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.13%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.382\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –Ω–∑\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.96%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.393\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>(\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.95%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.394\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —à–µ–≤\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.90%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.397\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –º—É—Å\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.87%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.400\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ?))\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.84%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.402\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        üòä<span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0 0 0.1em\" title=\"A space symbol\">&emsp;</span>\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.78%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.406\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>.<span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0 0 0.1em\" title=\"A space symbol\">&emsp;</span>\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.74%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.409\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ??<span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0 0 0.1em\" title=\"A space symbol\">&emsp;</span>\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.65%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.415\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        :<span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0.1em\" title=\"A space symbol\">&emsp;</span>&quot;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.61%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.418\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>:-\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.55%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.422\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        :d\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.52%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.425\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.22%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.446\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –∞—â–µ\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.41%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.506\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>:)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.561\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>üëç\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.63%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.646\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>üòÉ\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.707\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>))\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(lr_model_char.model, vec=lr_model_char.vectorizer, top=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1.0\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.02%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.932\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Å–æ–≥–ª–∞—Å–Ω–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 81.57%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.830\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≤–∏–¥–µ–ª–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 81.88%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.810\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –ø–æ–Ω—è–ª–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.746\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≤–∞—â—â–µ\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.72%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.695\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –º—É–∂—á–∏–Ω—ã\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.76%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.693\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –æ—á–µ–Ω—å\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.92%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.683\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –∫–æ—à–º–∞—Ä\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.17%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.668\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ñ–∏–≥–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.31%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.660\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ö–æ—Ç–µ–ª–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.76%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.633\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –Ω–∏–±—É–¥—å\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.56%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.586\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –º–Ω–µ\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.60%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.583\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –Ω—É\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.65%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.581\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –¥—É–º–∞–ª–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.81%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.571\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ç—ã\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.94%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.564\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –∂–∏–≤–æ—Ç–Ω—ã—Ö\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.12%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.554\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –º—É–∂\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.15%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.552\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ö–∏\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.58%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.527\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –±–ª–∏–Ω\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.59%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.527\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≤—ã\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.60%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.526\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –æ_–æ\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.60%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 2435 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.22%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 2526 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.22%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.438\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –ª—é–±–æ–π\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.98%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.451\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Å–æ–≥–ª–∞—Å–µ–Ω\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.455\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –ø–µ—Ä–µ–¥\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.85%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.458\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        club33041211\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.73%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.464\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —â–∞—Å\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.58%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.472\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ä—É–±–ª–µ–π\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.482\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≥–æ—Å–ø–æ–¥–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.35%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.485\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –±–æ–ª–µ–µ\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.34%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.485\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –º—Å–∫\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.27%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.489\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ç–≤\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.46%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.534\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –Ω–µ—Ç—É\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.34%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.541\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –º–µ—Å—Ç–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.30%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.543\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —É—Ö–∞—Ö–∞—Ö–∞\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.11%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.554\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —á—Ç–æ–±—ã\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.99%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.561\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≤–∏–¥–µ–ª\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.77%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.574\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ç–∞–∫–∂–µ\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.13%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.611\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≤—Å—ë\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.61%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.642\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        —Ç–∏–ø–∏—á–Ω—ã–π\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.35%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.657\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –µ—â—ë\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.933\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        –≥–≥\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(lr_model_tfidf.model, vec=lr_model_tfidf.vectorizer, top=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "i = 333\n",
    "print(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=0.0\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.671</b>, score <b>-0.714</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.639\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.53%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.075\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 79.41%); opacity: 0.88\" title=\"-0.182\">–¥–∞</span><span style=\"opacity: 0.80\"> –∏ </span><span style=\"background-color: hsl(0, 100.00%, 77.45%); opacity: 0.89\" title=\"-0.207\">–≤–æ–æ–±—â–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.32%); opacity: 0.84\" title=\"-0.091\">–Ω–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.89%); opacity: 0.86\" title=\"0.152\">–Ω–∞–¥–æ–µ–ª–æ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.67%); opacity: 0.86\" title=\"0.131\">—ç—Ç—É</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.78%); opacity: 0.87\" title=\"0.153\">—Ç–µ–º—É</span><span style=\"opacity: 0.80\"> –ø–µ—Ä–µ—Ç–∏—Ä–∞—Ç—å?! </span><span style=\"background-color: hsl(120, 100.00%, 88.92%); opacity: 0.83\" title=\"0.075\">–±–æ–ª—å—à–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.37%); opacity: 0.84\" title=\"-0.101\">–¥—Ä—É–≥–∏—Ö</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.470\">–Ω–µ—Ç—É</span><span style=\"opacity: 0.80\">?! </span><span style=\"background-color: hsl(0, 100.00%, 82.78%); opacity: 0.86\" title=\"-0.141\">–ø–æ</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(0, 100.00%, 82.62%); opacity: 0.86\" title=\"-0.143\">–º–æ–µ–º—É</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 67.45%); opacity: 0.95\" title=\"0.350\">—É–∂–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.54%); opacity: 0.89\" title=\"0.219\">–Ω–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.77%); opacity: 0.81\" title=\"-0.026\">–ø–µ—Ä–≤—ã–π</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.88%); opacity: 0.85\" title=\"0.117\">–≥–æ–¥</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.13%); opacity: 0.81\" title=\"-0.017\">–ª–µ—Ç–∞—é—Ç</span><span style=\"opacity: 0.80\">,–∞ </span><span style=\"background-color: hsl(120, 100.00%, 90.02%); opacity: 0.83\" title=\"0.065\">–≤—ã</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.75%); opacity: 0.82\" title=\"0.058\">–≤—Å–µ</span><span style=\"opacity: 0.80\"> —É—Å–ø–æ–∫–æ–∏—Ç—å—Å—è </span><span style=\"background-color: hsl(0, 100.00%, 91.38%); opacity: 0.82\" title=\"-0.052\">–Ω–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.73%); opacity: 0.81\" title=\"-0.019\">–º–æ–∂–µ—Ç–µ</span><span style=\"opacity: 0.80\">! –ø–æ—Å—Ç–∞–≤—å—Ç–µ </span><span style=\"background-color: hsl(0, 100.00%, 98.41%); opacity: 0.80\" title=\"-0.005\">—Å–µ–±–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.51%); opacity: 0.81\" title=\"-0.035\">–æ–∫–Ω–∞</span><span style=\"opacity: 0.80\"> –∏ –∂–∏–≤–∏—Ç–µ </span><span style=\"background-color: hsl(120, 100.00%, 94.59%); opacity: 0.81\" title=\"0.027\">—Å–ø–æ–∫–æ–π–Ω–æ</span><span style=\"opacity: 0.80\">!! –≥–æ—Ä–¥–∏—Ç—å—Å—è </span><span style=\"background-color: hsl(0, 100.00%, 90.02%); opacity: 0.83\" title=\"-0.065\">–¥–æ–ª–∂–Ω—ã</span><span style=\"opacity: 0.80\"> ,–∞ </span><span style=\"background-color: hsl(0, 100.00%, 92.57%); opacity: 0.82\" title=\"-0.042\">–Ω–µ</span><span style=\"opacity: 0.80\"> –æ–±—Å–µ—Ä–∞—Ç—å !</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_prediction(lr_model.model, X_train.text.iloc[i], vec=lr_model.vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=0.0\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.670</b>, score <b>-0.709</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.618\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.78%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.091\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 78.29%); opacity: 0.88\" title=\"-0.063\">–¥</span><span style=\"background-color: hsl(0, 100.00%, 76.45%); opacity: 0.89\" title=\"-0.071\">–∞</span><span style=\"background-color: hsl(0, 100.00%, 94.42%); opacity: 0.81\" title=\"-0.009\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.09%); opacity: 0.80\" title=\"-0.002\">–∏</span><span style=\"background-color: hsl(120, 100.00%, 82.16%); opacity: 0.86\" title=\"0.048\"> </span><span style=\"background-color: hsl(0, 100.00%, 67.35%); opacity: 0.95\" title=\"-0.114\">–≤</span><span style=\"background-color: hsl(0, 100.00%, 94.44%); opacity: 0.81\" title=\"-0.009\">–æ</span><span style=\"background-color: hsl(0, 100.00%, 90.52%); opacity: 0.83\" title=\"-0.019\">–æ</span><span style=\"background-color: hsl(120, 100.00%, 80.89%); opacity: 0.87\" title=\"0.053\">–±</span><span style=\"background-color: hsl(0, 100.00%, 79.97%); opacity: 0.87\" title=\"-0.057\">—â</span><span style=\"background-color: hsl(0, 100.00%, 95.85%); opacity: 0.81\" title=\"-0.006\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 88.24%); opacity: 0.83\" title=\"0.026\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.34%); opacity: 0.87\" title=\"-0.055\">–Ω</span><span style=\"background-color: hsl(120, 100.00%, 86.49%); opacity: 0.84\" title=\"0.032\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 86.89%); opacity: 0.84\" title=\"0.031\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.78%); opacity: 0.81\" title=\"-0.006\">–Ω</span><span style=\"background-color: hsl(120, 100.00%, 90.63%); opacity: 0.83\" title=\"0.019\">–∞</span><span style=\"background-color: hsl(120, 100.00%, 92.97%); opacity: 0.82\" title=\"0.013\">–¥</span><span style=\"background-color: hsl(120, 100.00%, 87.40%); opacity: 0.84\" title=\"0.029\">–æ</span><span style=\"background-color: hsl(120, 100.00%, 91.43%); opacity: 0.82\" title=\"0.017\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 85.93%); opacity: 0.84\" title=\"0.034\">–ª</span><span style=\"background-color: hsl(0, 100.00%, 94.71%); opacity: 0.81\" title=\"-0.008\">–æ</span><span style=\"background-color: hsl(120, 100.00%, 89.86%); opacity: 0.83\" title=\"0.021\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.92%); opacity: 0.80\" title=\"0.002\">—ç</span><span style=\"background-color: hsl(120, 100.00%, 91.69%); opacity: 0.82\" title=\"0.016\">—Ç</span><span style=\"background-color: hsl(120, 100.00%, 75.92%); opacity: 0.90\" title=\"0.074\">—É</span><span style=\"background-color: hsl(120, 100.00%, 97.11%); opacity: 0.80\" title=\"0.004\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.00%); opacity: 0.80\" title=\"0.002\">—Ç</span><span style=\"background-color: hsl(120, 100.00%, 92.36%); opacity: 0.82\" title=\"0.014\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 80.40%); opacity: 0.87\" title=\"0.055\">–º</span><span style=\"background-color: hsl(120, 100.00%, 91.14%); opacity: 0.82\" title=\"0.018\">—É</span><span style=\"background-color: hsl(120, 100.00%, 87.44%); opacity: 0.84\" title=\"0.029\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.35%); opacity: 0.81\" title=\"0.005\">–ø</span><span style=\"background-color: hsl(0, 100.00%, 80.40%); opacity: 0.87\" title=\"-0.055\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 89.51%); opacity: 0.83\" title=\"0.022\">—Ä</span><span style=\"background-color: hsl(0, 100.00%, 95.44%); opacity: 0.81\" title=\"-0.007\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 90.19%); opacity: 0.83\" title=\"0.020\">—Ç</span><span style=\"background-color: hsl(0, 100.00%, 93.25%); opacity: 0.82\" title=\"-0.012\">–∏</span><span style=\"background-color: hsl(120, 100.00%, 90.19%); opacity: 0.83\" title=\"0.020\">—Ä</span><span style=\"background-color: hsl(120, 100.00%, 86.74%); opacity: 0.84\" title=\"0.031\">–∞</span><span style=\"background-color: hsl(120, 100.00%, 85.59%); opacity: 0.85\" title=\"0.035\">—Ç</span><span style=\"background-color: hsl(0, 100.00%, 70.06%); opacity: 0.93\" title=\"-0.100\">—å</span><span style=\"background-color: hsl(0, 100.00%, 75.63%); opacity: 0.90\" title=\"-0.075\">?</span><span style=\"background-color: hsl(0, 100.00%, 96.71%); opacity: 0.81\" title=\"-0.004\">!</span><span style=\"background-color: hsl(120, 100.00%, 74.46%); opacity: 0.91\" title=\"0.080\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.90%); opacity: 0.82\" title=\"-0.013\">–±</span><span style=\"background-color: hsl(120, 100.00%, 94.05%); opacity: 0.81\" title=\"0.010\">–æ</span><span style=\"background-color: hsl(0, 100.00%, 88.13%); opacity: 0.84\" title=\"-0.027\">–ª</span><span style=\"background-color: hsl(120, 100.00%, 78.07%); opacity: 0.88\" title=\"0.064\">—å</span><span style=\"background-color: hsl(120, 100.00%, 77.01%); opacity: 0.89\" title=\"0.069\">—à</span><span style=\"background-color: hsl(0, 100.00%, 91.95%); opacity: 0.82\" title=\"-0.015\">–µ</span><span style=\"background-color: hsl(0, 100.00%, 88.23%); opacity: 0.83\" title=\"-0.026\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.55%); opacity: 0.87\" title=\"-0.054\">–¥</span><span style=\"background-color: hsl(120, 100.00%, 82.44%); opacity: 0.86\" title=\"0.047\">—Ä</span><span style=\"background-color: hsl(0, 100.00%, 81.19%); opacity: 0.87\" title=\"-0.052\">—É</span><span style=\"background-color: hsl(0, 100.00%, 66.74%); opacity: 0.95\" title=\"-0.117\">–≥</span><span style=\"background-color: hsl(0, 100.00%, 78.16%); opacity: 0.88\" title=\"-0.064\">–∏</span><span style=\"background-color: hsl(120, 100.00%, 72.48%); opacity: 0.92\" title=\"0.089\">—Ö</span><span style=\"background-color: hsl(120, 100.00%, 87.08%); opacity: 0.84\" title=\"0.030\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.67%); opacity: 0.84\" title=\"-0.028\">–Ω</span><span style=\"background-color: hsl(120, 100.00%, 75.26%); opacity: 0.90\" title=\"0.076\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 70.34%); opacity: 0.93\" title=\"0.099\">—Ç</span><span style=\"background-color: hsl(120, 100.00%, 86.95%); opacity: 0.84\" title=\"0.031\">—É</span><span style=\"background-color: hsl(0, 100.00%, 68.72%); opacity: 0.94\" title=\"-0.107\">?</span><span style=\"background-color: hsl(0, 100.00%, 96.43%); opacity: 0.81\" title=\"-0.005\">!</span><span style=\"background-color: hsl(120, 100.00%, 70.17%); opacity: 0.93\" title=\"0.100\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.15%); opacity: 0.82\" title=\"-0.015\">–ø</span><span style=\"background-color: hsl(0, 100.00%, 65.92%); opacity: 0.96\" title=\"-0.121\">–æ</span><span style=\"background-color: hsl(120, 100.00%, 86.95%); opacity: 0.84\" title=\"0.031\">-</span><span style=\"background-color: hsl(120, 100.00%, 92.59%); opacity: 0.82\" title=\"0.014\">–º</span><span style=\"background-color: hsl(120, 100.00%, 95.32%); opacity: 0.81\" title=\"0.007\">–æ</span><span style=\"background-color: hsl(0, 100.00%, 84.00%); opacity: 0.85\" title=\"-0.041\">–µ</span><span style=\"background-color: hsl(0, 100.00%, 86.26%); opacity: 0.84\" title=\"-0.033\">–º</span><span style=\"background-color: hsl(0, 100.00%, 84.91%); opacity: 0.85\" title=\"-0.038\">—É</span><span style=\"background-color: hsl(0, 100.00%, 86.43%); opacity: 0.84\" title=\"-0.032\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.14%); opacity: 0.82\" title=\"-0.018\">—É</span><span style=\"background-color: hsl(120, 100.00%, 83.65%); opacity: 0.86\" title=\"0.042\">–∂</span><span style=\"background-color: hsl(120, 100.00%, 76.63%); opacity: 0.89\" title=\"0.071\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 81.71%); opacity: 0.87\" title=\"0.050\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.34%); opacity: 0.87\" title=\"-0.055\">–Ω</span><span style=\"background-color: hsl(120, 100.00%, 87.59%); opacity: 0.84\" title=\"0.029\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 84.06%); opacity: 0.85\" title=\"0.041\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.92%); opacity: 0.84\" title=\"-0.031\">–ø</span><span style=\"background-color: hsl(0, 100.00%, 74.71%); opacity: 0.90\" title=\"-0.079\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 77.61%); opacity: 0.89\" title=\"0.066\">—Ä</span><span style=\"background-color: hsl(120, 100.00%, 82.13%); opacity: 0.86\" title=\"0.048\">–≤</span><span style=\"background-color: hsl(0, 100.00%, 61.46%); opacity: 0.99\" title=\"-0.144\">—ã</span><span style=\"background-color: hsl(120, 100.00%, 90.05%); opacity: 0.83\" title=\"0.021\">–π</span><span style=\"background-color: hsl(0, 100.00%, 93.78%); opacity: 0.81\" title=\"-0.011\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.11%); opacity: 0.80\" title=\"-0.001\">–≥</span><span style=\"background-color: hsl(120, 100.00%, 85.90%); opacity: 0.85\" title=\"0.034\">–æ</span><span style=\"background-color: hsl(0, 100.00%, 85.87%); opacity: 0.85\" title=\"-0.034\">–¥</span><span style=\"background-color: hsl(120, 100.00%, 95.98%); opacity: 0.81\" title=\"0.006\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.97%); opacity: 0.84\" title=\"-0.031\">–ª</span><span style=\"background-color: hsl(120, 100.00%, 87.66%); opacity: 0.84\" title=\"0.028\">–µ</span><span style=\"background-color: hsl(0, 100.00%, 89.44%); opacity: 0.83\" title=\"-0.023\">—Ç</span><span style=\"background-color: hsl(0, 100.00%, 78.87%); opacity: 0.88\" title=\"-0.061\">–∞</span><span style=\"background-color: hsl(0, 100.00%, 88.24%); opacity: 0.83\" title=\"-0.026\">—é</span><span style=\"background-color: hsl(120, 100.00%, 96.48%); opacity: 0.81\" title=\"0.005\">—Ç</span><span style=\"background-color: hsl(120, 100.00%, 90.68%); opacity: 0.82\" title=\"0.019\">,</span><span style=\"background-color: hsl(120, 100.00%, 98.15%); opacity: 0.80\" title=\"0.002\">–∞</span><span style=\"background-color: hsl(120, 100.00%, 74.90%); opacity: 0.90\" title=\"0.078\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.55%); opacity: 0.87\" title=\"-0.050\">–≤</span><span style=\"background-color: hsl(120, 100.00%, 84.79%); opacity: 0.85\" title=\"0.038\">—ã</span><span style=\"background-color: hsl(120, 100.00%, 82.95%); opacity: 0.86\" title=\"0.045\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.88%); opacity: 0.83\" title=\"-0.024\">–≤</span><span style=\"background-color: hsl(120, 100.00%, 98.41%); opacity: 0.80\" title=\"0.002\">—Å</span><span style=\"background-color: hsl(0, 100.00%, 79.38%); opacity: 0.88\" title=\"-0.059\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 88.36%); opacity: 0.83\" title=\"0.026\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.32%); opacity: 0.82\" title=\"-0.014\">—É</span><span style=\"background-color: hsl(0, 100.00%, 97.72%); opacity: 0.80\" title=\"-0.003\">—Å</span><span style=\"background-color: hsl(120, 100.00%, 90.87%); opacity: 0.82\" title=\"0.018\">–ø</span><span style=\"background-color: hsl(0, 100.00%, 96.33%); opacity: 0.81\" title=\"-0.005\">–æ</span><span style=\"background-color: hsl(120, 100.00%, 84.92%); opacity: 0.85\" title=\"0.038\">–∫</span><span style=\"background-color: hsl(120, 100.00%, 83.52%); opacity: 0.86\" title=\"0.043\">–æ</span><span style=\"background-color: hsl(120, 100.00%, 85.99%); opacity: 0.84\" title=\"0.034\">–∏</span><span style=\"background-color: hsl(0, 100.00%, 95.29%); opacity: 0.81\" title=\"-0.007\">—Ç</span><span style=\"background-color: hsl(120, 100.00%, 87.12%); opacity: 0.84\" title=\"0.030\">—å</span><span style=\"background-color: hsl(120, 100.00%, 71.04%); opacity: 0.93\" title=\"0.096\">—Å</span><span style=\"background-color: hsl(120, 100.00%, 81.96%); opacity: 0.86\" title=\"0.049\">—è</span><span style=\"background-color: hsl(120, 100.00%, 94.50%); opacity: 0.81\" title=\"0.009\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.12%); opacity: 0.93\" title=\"-0.100\">–Ω</span><span style=\"background-color: hsl(120, 100.00%, 85.72%); opacity: 0.85\" title=\"0.035\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 81.23%); opacity: 0.87\" title=\"0.052\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.59%); opacity: 0.82\" title=\"0.014\">–º</span><span style=\"background-color: hsl(0, 100.00%, 73.02%); opacity: 0.91\" title=\"-0.087\">–æ</span><span style=\"background-color: hsl(0, 100.00%, 90.66%); opacity: 0.83\" title=\"-0.019\">–∂</span><span style=\"background-color: hsl(0, 100.00%, 84.19%); opacity: 0.85\" title=\"-0.040\">–µ</span><span style=\"background-color: hsl(0, 100.00%, 98.59%); opacity: 0.80\" title=\"-0.001\">—Ç</span><span style=\"background-color: hsl(0, 100.00%, 72.99%); opacity: 0.91\" title=\"-0.087\">–µ</span><span style=\"background-color: hsl(0, 100.00%, 92.93%); opacity: 0.82\" title=\"-0.013\">!</span><span style=\"background-color: hsl(0, 100.00%, 92.69%); opacity: 0.82\" title=\"-0.013\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.00%); opacity: 0.84\" title=\"-0.027\">–ø</span><span style=\"background-color: hsl(0, 100.00%, 84.51%); opacity: 0.85\" title=\"-0.039\">–æ</span><span style=\"background-color: hsl(120, 100.00%, 91.37%); opacity: 0.82\" title=\"0.017\">—Å</span><span style=\"background-color: hsl(0, 100.00%, 97.95%); opacity: 0.80\" title=\"-0.002\">—Ç</span><span style=\"background-color: hsl(120, 100.00%, 94.38%); opacity: 0.81\" title=\"0.009\">–∞</span><span style=\"background-color: hsl(0, 100.00%, 83.87%); opacity: 0.85\" title=\"-0.042\">–≤</span><span style=\"background-color: hsl(120, 100.00%, 83.74%); opacity: 0.86\" title=\"0.042\">—å</span><span style=\"background-color: hsl(120, 100.00%, 79.59%); opacity: 0.88\" title=\"0.058\">—Ç</span><span style=\"background-color: hsl(0, 100.00%, 94.04%); opacity: 0.81\" title=\"-0.010\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 82.86%); opacity: 0.86\" title=\"0.045\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.08%); opacity: 0.86\" title=\"0.044\">—Å</span><span style=\"background-color: hsl(120, 100.00%, 87.17%); opacity: 0.84\" title=\"0.030\">–µ</span><span style=\"background-color: hsl(0, 100.00%, 86.00%); opacity: 0.84\" title=\"-0.034\">–±</span><span style=\"background-color: hsl(0, 100.00%, 92.43%); opacity: 0.82\" title=\"-0.014\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 89.83%); opacity: 0.83\" title=\"0.021\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.36%); opacity: 0.94\" title=\"-0.109\">–æ</span><span style=\"background-color: hsl(120, 100.00%, 89.38%); opacity: 0.83\" title=\"0.023\">–∫</span><span style=\"background-color: hsl(120, 100.00%, 80.53%); opacity: 0.87\" title=\"0.054\">–Ω</span><span style=\"background-color: hsl(120, 100.00%, 97.68%); opacity: 0.80\" title=\"0.003\">–∞</span><span style=\"background-color: hsl(0, 100.00%, 97.02%); opacity: 0.80\" title=\"-0.004\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.94%); opacity: 0.86\" title=\"0.049\">–∏</span><span style=\"background-color: hsl(0, 100.00%, 92.94%); opacity: 0.82\" title=\"-0.013\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.25%); opacity: 0.94\" title=\"-0.109\">–∂</span><span style=\"background-color: hsl(120, 100.00%, 89.00%); opacity: 0.83\" title=\"0.024\">–∏</span><span style=\"background-color: hsl(0, 100.00%, 79.21%); opacity: 0.88\" title=\"-0.060\">–≤</span><span style=\"background-color: hsl(0, 100.00%, 80.45%); opacity: 0.87\" title=\"-0.055\">–∏</span><span style=\"background-color: hsl(0, 100.00%, 91.09%); opacity: 0.82\" title=\"-0.018\">—Ç</span><span style=\"background-color: hsl(120, 100.00%, 85.97%); opacity: 0.84\" title=\"0.034\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 79.22%); opacity: 0.88\" title=\"0.060\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.68%); opacity: 0.82\" title=\"-0.013\">—Å</span><span style=\"background-color: hsl(120, 100.00%, 86.75%); opacity: 0.84\" title=\"0.031\">–ø</span><span style=\"background-color: hsl(0, 100.00%, 96.33%); opacity: 0.81\" title=\"-0.005\">–æ</span><span style=\"background-color: hsl(120, 100.00%, 84.72%); opacity: 0.85\" title=\"0.038\">–∫</span><span style=\"background-color: hsl(120, 100.00%, 89.82%); opacity: 0.83\" title=\"0.022\">–æ</span><span style=\"background-color: hsl(120, 100.00%, 86.81%); opacity: 0.84\" title=\"0.031\">–π</span><span style=\"background-color: hsl(120, 100.00%, 81.05%); opacity: 0.87\" title=\"0.052\">–Ω</span><span style=\"background-color: hsl(120, 100.00%, 84.00%); opacity: 0.85\" title=\"0.041\">–æ</span><span style=\"background-color: hsl(120, 100.00%, 67.75%); opacity: 0.95\" title=\"0.112\">!</span><span style=\"background-color: hsl(120, 100.00%, 70.03%); opacity: 0.93\" title=\"0.101\">!</span><span style=\"background-color: hsl(120, 100.00%, 84.34%); opacity: 0.85\" title=\"0.040\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.48%); opacity: 0.86\" title=\"0.047\">–≥</span><span style=\"background-color: hsl(120, 100.00%, 81.25%); opacity: 0.87\" title=\"0.051\">–æ</span><span style=\"background-color: hsl(0, 100.00%, 89.31%); opacity: 0.83\" title=\"-0.023\">—Ä</span><span style=\"background-color: hsl(0, 100.00%, 98.80%); opacity: 0.80\" title=\"-0.001\">–¥</span><span style=\"background-color: hsl(120, 100.00%, 89.60%); opacity: 0.83\" title=\"0.022\">–∏</span><span style=\"background-color: hsl(0, 100.00%, 77.09%); opacity: 0.89\" title=\"-0.069\">—Ç</span><span style=\"background-color: hsl(120, 100.00%, 87.12%); opacity: 0.84\" title=\"0.030\">—å</span><span style=\"background-color: hsl(120, 100.00%, 71.04%); opacity: 0.93\" title=\"0.096\">—Å</span><span style=\"background-color: hsl(120, 100.00%, 72.93%); opacity: 0.91\" title=\"0.087\">—è</span><span style=\"background-color: hsl(0, 100.00%, 97.60%); opacity: 0.80\" title=\"-0.003\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.39%); opacity: 0.86\" title=\"-0.047\">–¥</span><span style=\"background-color: hsl(120, 100.00%, 65.40%); opacity: 0.96\" title=\"0.124\">–æ</span><span style=\"background-color: hsl(0, 100.00%, 77.12%); opacity: 0.89\" title=\"-0.068\">–ª</span><span style=\"background-color: hsl(0, 100.00%, 84.47%); opacity: 0.85\" title=\"-0.039\">–∂</span><span style=\"background-color: hsl(0, 100.00%, 87.32%); opacity: 0.84\" title=\"-0.029\">–Ω</span><span style=\"background-color: hsl(120, 100.00%, 86.84%); opacity: 0.84\" title=\"0.031\">—ã</span><span style=\"background-color: hsl(120, 100.00%, 79.99%); opacity: 0.87\" title=\"0.057\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.32%); opacity: 0.82\" title=\"-0.014\">,</span><span style=\"background-color: hsl(0, 100.00%, 88.00%); opacity: 0.84\" title=\"-0.027\">–∞</span><span style=\"background-color: hsl(120, 100.00%, 71.13%); opacity: 0.93\" title=\"0.095\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.94%); opacity: 0.90\" title=\"-0.074\">–Ω</span><span style=\"background-color: hsl(120, 100.00%, 86.54%); opacity: 0.84\" title=\"0.032\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 90.81%); opacity: 0.82\" title=\"0.019\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.62%); opacity: 0.87\" title=\"-0.054\">–æ</span><span style=\"background-color: hsl(120, 100.00%, 85.58%); opacity: 0.85\" title=\"0.035\">–±</span><span style=\"background-color: hsl(120, 100.00%, 97.64%); opacity: 0.80\" title=\"0.003\">—Å</span><span style=\"background-color: hsl(0, 100.00%, 95.33%); opacity: 0.81\" title=\"-0.007\">–µ</span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.006\">—Ä</span><span style=\"background-color: hsl(120, 100.00%, 73.10%); opacity: 0.91\" title=\"0.086\">–∞</span><span style=\"background-color: hsl(120, 100.00%, 91.70%); opacity: 0.82\" title=\"0.016\">—Ç</span><span style=\"background-color: hsl(120, 100.00%, 87.02%); opacity: 0.84\" title=\"0.030\">—å</span><span style=\"background-color: hsl(0, 100.00%, 79.60%); opacity: 0.88\" title=\"-0.058\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.152\">!</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_prediction(lr_model_char.model, X_train.text.iloc[i], vec=lr_model_char.vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=0.0\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.515</b>, score <b>-0.060</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.101\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.35%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.041\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 79.16%); opacity: 0.88\" title=\"-0.044\">–¥–∞</span><span style=\"opacity: 0.80\"> –∏ </span><span style=\"background-color: hsl(0, 100.00%, 80.69%); opacity: 0.87\" title=\"-0.039\">–≤–æ–æ–±—â–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.16%); opacity: 0.83\" title=\"-0.015\">–Ω–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.51%); opacity: 0.86\" title=\"0.034\">–Ω–∞–¥–æ–µ–ª–æ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.86%); opacity: 0.88\" title=\"0.042\">—ç—Ç—É</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.24%); opacity: 0.84\" title=\"0.024\">—Ç–µ–º—É</span><span style=\"opacity: 0.80\"> –ø–µ—Ä–µ—Ç–∏—Ä–∞—Ç—å?! </span><span style=\"background-color: hsl(120, 100.00%, 83.00%); opacity: 0.86\" title=\"0.033\">–±–æ–ª—å—à–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.68%); opacity: 0.85\" title=\"-0.028\">–¥—Ä—É–≥–∏—Ö</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.111\">–Ω–µ—Ç—É</span><span style=\"opacity: 0.80\">?! </span><span style=\"background-color: hsl(120, 100.00%, 83.42%); opacity: 0.86\" title=\"0.032\">–ø–æ</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(0, 100.00%, 89.49%); opacity: 0.83\" title=\"-0.017\">–º–æ–µ–º—É</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.36%); opacity: 0.89\" title=\"0.053\">—É–∂–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.16%); opacity: 0.83\" title=\"-0.015\">–Ω–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.22%); opacity: 0.84\" title=\"-0.022\">–ø–µ—Ä–≤—ã–π</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.67%); opacity: 0.89\" title=\"0.052\">–≥–æ–¥</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.48%); opacity: 0.82\" title=\"0.010\">–ª–µ—Ç–∞—é—Ç</span><span style=\"opacity: 0.80\">,–∞ </span><span style=\"background-color: hsl(0, 100.00%, 72.11%); opacity: 0.92\" title=\"-0.067\">–≤—ã</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.11%); opacity: 0.87\" title=\"-0.038\">–≤—Å–µ</span><span style=\"opacity: 0.80\"> —É—Å–ø–æ–∫–æ–∏—Ç—å—Å—è </span><span style=\"background-color: hsl(0, 100.00%, 90.16%); opacity: 0.83\" title=\"-0.015\">–Ω–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.00%); opacity: 0.84\" title=\"-0.022\">–º–æ–∂–µ—Ç–µ</span><span style=\"opacity: 0.80\">! –ø–æ—Å—Ç–∞–≤—å—Ç–µ </span><span style=\"background-color: hsl(0, 100.00%, 94.59%); opacity: 0.81\" title=\"-0.006\">—Å–µ–±–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.52%); opacity: 0.87\" title=\"-0.037\">–æ–∫–Ω–∞</span><span style=\"opacity: 0.80\"> –∏ </span><span style=\"background-color: hsl(0, 100.00%, 96.55%); opacity: 0.81\" title=\"-0.003\">–∂–∏–≤–∏—Ç–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.09%); opacity: 0.80\" title=\"0.003\">—Å–ø–æ–∫–æ–π–Ω–æ</span><span style=\"opacity: 0.80\">!! </span><span style=\"background-color: hsl(0, 100.00%, 82.27%); opacity: 0.86\" title=\"-0.035\">–≥–æ—Ä–¥–∏—Ç—å—Å—è</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.87%); opacity: 0.83\" title=\"-0.016\">–¥–æ–ª–∂–Ω—ã</span><span style=\"opacity: 0.80\"> ,–∞ </span><span style=\"background-color: hsl(0, 100.00%, 90.16%); opacity: 0.83\" title=\"-0.015\">–Ω–µ</span><span style=\"opacity: 0.80\"> –æ–±—Å–µ—Ä–∞—Ç—å !</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_prediction(lr_model_tfidf.model, X_train.text.iloc[i], vec=lr_model_tfidf.vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from eli5.lime import TextExplainer\n",
    "te = TextExplainer()\n",
    "\n",
    "def dummy_predict_proba(docs):\n",
    "    d = pd.DataFrame({'text': docs})\n",
    "    \n",
    "    predictions = []\n",
    "    for model in av_model.models:\n",
    "        prediction = model.predict_proba(d)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    pr = predictions[0]\n",
    "    for i in range(1, len(av_model.models)):\n",
    "        pr += predictions[1]\n",
    "    return pr / len(av_model.models)\n",
    "\n",
    "te.fit(X_train.text.iloc[i], dummy_predict_proba);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=0\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.585</b>, score <b>-0.343</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.303\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.18%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.040\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 79.21%); opacity: 0.88\" title=\"-0.162\">–¥–∞</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.80%); opacity: 0.84\" title=\"-0.085\">–∏</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.91%); opacity: 0.92\" title=\"-0.250\">–≤–æ–æ–±—â–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.35%); opacity: 0.88\" title=\"-0.172\">–Ω–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.61%); opacity: 0.85\" title=\"0.106\">–Ω–∞–¥–æ–µ–ª–æ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.93%); opacity: 0.88\" title=\"0.166\">—ç—Ç—É</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.23%); opacity: 0.85\" title=\"0.100\">—Ç–µ–º—É</span><span style=\"opacity: 0.80\"> –ø–µ—Ä–µ—Ç–∏—Ä–∞—Ç—å?! </span><span style=\"background-color: hsl(120, 100.00%, 81.60%); opacity: 0.87\" title=\"0.136\">–±–æ–ª—å—à–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.73%); opacity: 0.92\" title=\"-0.252\">–¥—Ä—É–≥–∏—Ö</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.414\">–Ω–µ—Ç—É</span><span style=\"opacity: 0.80\">?! </span><span style=\"background-color: hsl(0, 100.00%, 84.68%); opacity: 0.85\" title=\"-0.105\">–ø–æ</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(0, 100.00%, 96.35%); opacity: 0.81\" title=\"-0.014\">–º–æ–µ–º—É</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 63.10%); opacity: 0.98\" title=\"0.369\">—É–∂–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.84%); opacity: 0.84\" title=\"0.075\">–Ω–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.60%); opacity: 0.88\" title=\"-0.158\">–ø–µ—Ä–≤—ã–π</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.16%); opacity: 0.85\" title=\"0.110\">–≥–æ–¥</span><span style=\"opacity: 0.80\"> –ª–µ—Ç–∞—é—Ç,</span><span style=\"background-color: hsl(120, 100.00%, 90.20%); opacity: 0.83\" title=\"0.055\">–∞</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.84%); opacity: 0.81\" title=\"-0.016\">–≤—ã</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.39%); opacity: 0.80\" title=\"-0.004\">–≤—Å–µ</span><span style=\"opacity: 0.80\"> —É—Å–ø–æ–∫–æ–∏—Ç—å—Å—è </span><span style=\"background-color: hsl(0, 100.00%, 80.05%); opacity: 0.87\" title=\"-0.153\">–Ω–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.49%); opacity: 0.84\" title=\"-0.079\">–º–æ–∂–µ—Ç–µ</span><span style=\"opacity: 0.80\">! </span><span style=\"background-color: hsl(0, 100.00%, 94.04%); opacity: 0.81\" title=\"-0.027\">–ø–æ—Å—Ç–∞–≤—å—Ç–µ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.59%); opacity: 0.83\" title=\"-0.052\">—Å–µ–±–µ</span><span style=\"opacity: 0.80\"> –æ–∫–Ω–∞ </span><span style=\"background-color: hsl(120, 100.00%, 93.04%); opacity: 0.82\" title=\"0.034\">–∏</span><span style=\"opacity: 0.80\"> –∂–∏–≤–∏—Ç–µ </span><span style=\"background-color: hsl(120, 100.00%, 98.86%); opacity: 0.80\" title=\"0.003\">—Å–ø–æ–∫–æ–π–Ω–æ</span><span style=\"opacity: 0.80\">!! </span><span style=\"background-color: hsl(0, 100.00%, 92.04%); opacity: 0.82\" title=\"-0.041\">–≥–æ—Ä–¥–∏—Ç—å—Å—è</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.94%); opacity: 0.84\" title=\"-0.075\">–¥–æ–ª–∂–Ω—ã</span><span style=\"opacity: 0.80\"> ,</span><span style=\"background-color: hsl(120, 100.00%, 90.20%); opacity: 0.83\" title=\"0.055\">–∞</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.81%); opacity: 0.84\" title=\"-0.085\">–Ω–µ</span><span style=\"opacity: 0.80\"> –æ–±—Å–µ—Ä–∞—Ç—å !</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te.show_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For different n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.505617977528\n",
      "Model:  mlp\n",
      "0.512172284644\n",
      "Model:  lr_count_2k_word\n",
      "0.507490636704\n",
      "Model:  lr_count_2k_char\n",
      "0.526217228464\n",
      "Model:  lr_count_5k_word\n",
      "0.503745318352\n",
      "Model:  lr_count_5k_char\n",
      "0.50468164794\n",
      "Model:  lr_clear_count_1k\n",
      "0.5234082397\n",
      "Model:  xgb\n",
      "0.52808988764\n",
      "Model:  lr_tfidf_1k\n",
      "0.50936329588\n",
      "Model:  lr_tfidf_5k\n",
      "0.507490636704\n",
      "Median of models: 0.520599250936\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.505617977528\n",
      "Model:  mlp\n",
      "0.512172284644\n",
      "Model:  lr_count_2k_word\n",
      "0.507490636704\n",
      "Model:  lr_count_2k_char\n",
      "0.526217228464\n",
      "Model:  lr_count_5k_word\n",
      "0.503745318352\n",
      "Model:  lr_count_5k_char\n",
      "0.50468164794\n",
      "Model:  lr_clear_count_1k\n",
      "0.5234082397\n",
      "Model:  xgb\n",
      "0.52808988764\n",
      "Model:  lr_tfidf_1k\n",
      "0.50936329588\n",
      "Model:  lr_tfidf_5k\n",
      "0.507490636704\n",
      "Median of models averaged per user:\n",
      "0.520599250936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Median of averaged model per user:\n",
      "0.520599250936\n",
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.495670995671\n",
      "Model:  mlp\n",
      "0.50937950938\n",
      "Model:  lr_count_2k_word\n",
      "0.502886002886\n",
      "Model:  lr_count_2k_char\n",
      "0.510101010101\n",
      "Model:  lr_count_5k_word\n",
      "0.517316017316\n",
      "Model:  lr_count_5k_char\n",
      "0.507936507937\n",
      "Model:  lr_clear_count_1k\n",
      "0.511544011544\n",
      "Model:  xgb\n",
      "0.48556998557\n",
      "Model:  lr_tfidf_1k\n",
      "0.510822510823\n",
      "Model:  lr_tfidf_5k\n",
      "0.510101010101\n",
      "Median of models: 0.512987012987\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.507936507937\n",
      "Model:  mlp\n",
      "0.506493506494\n",
      "Model:  lr_count_2k_word\n",
      "0.507936507937\n",
      "Model:  lr_count_2k_char\n",
      "0.518037518038\n",
      "Model:  lr_count_5k_word\n",
      "0.519480519481\n",
      "Model:  lr_count_5k_char\n",
      "0.503607503608\n",
      "Model:  lr_clear_count_1k\n",
      "0.525252525253\n",
      "Model:  xgb\n",
      "0.496392496392\n",
      "Model:  lr_tfidf_1k\n",
      "0.513708513709\n",
      "Model:  lr_tfidf_5k\n",
      "0.518037518038\n",
      "Median of models averaged per user:\n",
      "0.515151515152\n",
      "Median of averaged model per user:\n",
      "0.52380952381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.514167650531\n",
      "Model:  mlp\n",
      "0.512396694215\n",
      "Model:  lr_count_2k_word\n",
      "0.511806375443\n",
      "Model:  lr_count_2k_char\n",
      "0.513577331759\n",
      "Model:  lr_count_5k_word\n",
      "0.517709563164\n",
      "Model:  lr_count_5k_char\n",
      "0.499409681228\n",
      "Model:  lr_clear_count_1k\n",
      "0.524203069658\n",
      "Model:  xgb\n",
      "0.510625737898\n",
      "Model:  lr_tfidf_1k\n",
      "0.507674144038\n",
      "Model:  lr_tfidf_5k\n",
      "0.514167650531\n",
      "Median of models: 0.512987012987\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.534709193246\n",
      "Model:  mlp\n",
      "0.527204502814\n",
      "Model:  lr_count_2k_word\n",
      "0.544090056285\n",
      "Model:  lr_count_2k_char\n",
      "0.527204502814\n",
      "Model:  lr_count_5k_word\n",
      "0.527204502814\n",
      "Model:  lr_count_5k_char\n",
      "0.512195121951\n",
      "Model:  lr_clear_count_1k\n",
      "0.538461538462\n",
      "Model:  xgb\n",
      "0.519699812383\n",
      "Model:  lr_tfidf_1k\n",
      "0.519699812383\n",
      "Model:  lr_tfidf_5k\n",
      "0.538461538462\n",
      "Median of models averaged per user:\n",
      "0.544090056285\n",
      "Median of averaged model per user:\n",
      "0.53095684803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.510660426417\n",
      "Model:  mlp\n",
      "0.515860634425\n",
      "Model:  lr_count_2k_word\n",
      "0.527301092044\n",
      "Model:  lr_count_2k_char\n",
      "0.519500780031\n",
      "Model:  lr_count_5k_word\n",
      "0.519500780031\n",
      "Model:  lr_count_5k_char\n",
      "0.509100364015\n",
      "Model:  lr_clear_count_1k\n",
      "0.520540821633\n",
      "Model:  xgb\n",
      "0.527301092044\n",
      "Model:  lr_tfidf_1k\n",
      "0.50598023921\n",
      "Model:  lr_tfidf_5k\n",
      "0.515340613625\n",
      "Median of models: 0.525741029641\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.512359550562\n",
      "Model:  mlp\n",
      "0.52808988764\n",
      "Model:  lr_count_2k_word\n",
      "0.54606741573\n",
      "Model:  lr_count_2k_char\n",
      "0.525842696629\n",
      "Model:  lr_count_5k_word\n",
      "0.54606741573\n",
      "Model:  lr_count_5k_char\n",
      "0.516853932584\n",
      "Model:  lr_clear_count_1k\n",
      "0.54606741573\n",
      "Model:  xgb\n",
      "0.539325842697\n",
      "Model:  lr_tfidf_1k\n",
      "0.521348314607\n",
      "Model:  lr_tfidf_5k\n",
      "0.539325842697\n",
      "Median of models averaged per user:\n",
      "0.54606741573\n",
      "Median of averaged model per user:\n",
      "0.539325842697"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.51395572666\n",
      "Model:  mlp\n",
      "0.523580365736\n",
      "Model:  lr_count_2k_word\n",
      "0.52021174206\n",
      "Model:  lr_count_2k_char\n",
      "0.51010587103\n",
      "Model:  lr_count_5k_word\n",
      "0.521174205967\n",
      "Model:  lr_count_5k_char\n",
      "0.507218479307\n",
      "Model:  lr_clear_count_1k\n",
      "0.518768046198\n",
      "Model:  xgb\n",
      "0.523099133782\n",
      "Model:  lr_tfidf_1k\n",
      "0.510587102984\n",
      "Model:  lr_tfidf_5k\n",
      "0.519249278152\n",
      "Median of models: 0.533205004812\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.537662337662\n",
      "Model:  mlp\n",
      "0.532467532468\n",
      "Model:  lr_count_2k_word\n",
      "0.527272727273\n",
      "Model:  lr_count_2k_char\n",
      "0.503896103896\n",
      "Model:  lr_count_5k_word\n",
      "0.548051948052\n",
      "Model:  lr_count_5k_char\n",
      "0.509090909091\n",
      "Model:  lr_clear_count_1k\n",
      "0.535064935065\n",
      "Model:  xgb\n",
      "0.550649350649\n",
      "Model:  lr_tfidf_1k\n",
      "0.501298701299\n",
      "Model:  lr_tfidf_5k\n",
      "0.532467532468\n",
      "Median of models averaged per user:\n",
      "0.537662337662\n",
      "Median of averaged model per user:\n",
      "0.568831168831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.51912568306\n",
      "Model:  mlp\n",
      "0.511839708561\n",
      "Model:  lr_count_2k_word\n",
      "0.516848816029\n",
      "Model:  lr_count_2k_char\n",
      "0.517304189435\n",
      "Model:  lr_count_5k_word\n",
      "0.524590163934\n",
      "Model:  lr_count_5k_char\n",
      "0.508652094718\n",
      "Model:  lr_clear_count_1k\n",
      "0.52276867031\n",
      "Model:  xgb\n",
      "0.509107468124\n",
      "Model:  lr_tfidf_1k\n",
      "0.516848816029\n",
      "Model:  lr_tfidf_5k\n",
      "0.530054644809\n",
      "Median of models: 0.525500910747\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.523668639053\n",
      "Model:  mlp\n",
      "0.479289940828\n",
      "Model:  lr_count_2k_word\n",
      "0.526627218935\n",
      "Model:  lr_count_2k_char\n",
      "0.508875739645\n",
      "Model:  lr_count_5k_word\n",
      "0.529585798817\n",
      "Model:  lr_count_5k_char\n",
      "0.508875739645\n",
      "Model:  lr_clear_count_1k\n",
      "0.511834319527\n",
      "Model:  xgb\n",
      "0.511834319527\n",
      "Model:  lr_tfidf_1k\n",
      "0.5\n",
      "Model:  lr_tfidf_5k\n",
      "0.532544378698\n",
      "Median of models averaged per user:\n",
      "0.529585798817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of averaged model per user:\n",
      "0.532544378698\n",
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.517346053773\n",
      "Model:  mlp\n",
      "0.50607111882\n",
      "Model:  lr_count_2k_word\n",
      "0.514744145707\n",
      "Model:  lr_count_2k_char\n",
      "0.501734605377\n",
      "Model:  lr_count_5k_word\n",
      "0.510407632264\n",
      "Model:  lr_count_5k_char\n",
      "0.508673026886\n",
      "Model:  lr_clear_count_1k\n",
      "0.518213356461\n",
      "Model:  xgb\n",
      "0.510841283608\n",
      "Model:  lr_tfidf_1k\n",
      "0.511274934952\n",
      "Model:  lr_tfidf_5k\n",
      "0.511274934952\n",
      "Median of models: 0.512142237641\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.543046357616\n",
      "Model:  mlp\n",
      "0.5\n",
      "Model:  lr_count_2k_word\n",
      "0.543046357616\n",
      "Model:  lr_count_2k_char\n",
      "0.523178807947\n",
      "Model:  lr_count_5k_word\n",
      "0.513245033113\n",
      "Model:  lr_count_5k_char\n",
      "0.493377483444\n",
      "Model:  lr_clear_count_1k\n",
      "0.513245033113\n",
      "Model:  xgb\n",
      "0.539735099338\n",
      "Model:  lr_tfidf_1k\n",
      "0.513245033113\n",
      "Model:  lr_tfidf_5k\n",
      "0.523178807947\n",
      "Median of models averaged per user:\n",
      "0.53642384106\n",
      "Median of averaged model per user:\n",
      "0.529801324503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.520403870425\n",
      "Model:  mlp\n",
      "0.518300378629\n",
      "Model:  lr_count_2k_word\n",
      "0.525872949095\n",
      "Model:  lr_count_2k_char\n",
      "0.517038283551\n",
      "Model:  lr_count_5k_word\n",
      "0.521245267143\n",
      "Model:  lr_count_5k_char\n",
      "0.528397139251\n",
      "Model:  lr_clear_count_1k\n",
      "0.535128313\n",
      "Model:  xgb\n",
      "0.514093395036\n",
      "Model:  lr_tfidf_1k\n",
      "0.523769457299\n",
      "Model:  lr_tfidf_5k\n",
      "0.519562473706\n",
      "Median of models: 0.533866217922\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.553113553114\n",
      "Model:  mlp\n",
      "0.556776556777\n",
      "Model:  lr_count_2k_word\n",
      "0.534798534799\n",
      "Model:  lr_count_2k_char\n",
      "0.542124542125\n",
      "Model:  lr_count_5k_word\n",
      "0.556776556777\n",
      "Model:  lr_count_5k_char\n",
      "0.531135531136\n",
      "Model:  lr_clear_count_1k\n",
      "0.586080586081\n",
      "Model:  xgb\n",
      "0.520146520147\n",
      "Model:  lr_tfidf_1k\n",
      "0.534798534799\n",
      "Model:  lr_tfidf_5k\n",
      "0.538461538462\n",
      "Median of models averaged per user:\n",
      "0.56043956044\n",
      "Median of averaged model per user:\n",
      "0.564102564103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.534201954397\n",
      "Model:  mlp\n",
      "0.532980456026\n",
      "Model:  lr_count_2k_word\n",
      "0.54845276873\n",
      "Model:  lr_count_2k_char\n",
      "0.53664495114\n",
      "Model:  lr_count_5k_word\n",
      "0.541123778502\n",
      "Model:  lr_count_5k_char\n",
      "0.545195439739\n",
      "Model:  lr_clear_count_1k\n",
      "0.538680781759\n",
      "Model:  xgb\n",
      "0.510586319218\n",
      "Model:  lr_tfidf_1k\n",
      "0.541123778502\n",
      "Model:  lr_tfidf_5k\n",
      "0.53664495114\n",
      "Median of models: 0.550895765472\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.560483870968\n",
      "Model:  mlp\n",
      "0.552419354839\n",
      "Model:  lr_count_2k_word\n",
      "0.620967741935\n",
      "Model:  lr_count_2k_char\n",
      "0.564516129032\n",
      "Model:  lr_count_5k_word\n",
      "0.588709677419\n",
      "Model:  lr_count_5k_char\n",
      "0.58064516129\n",
      "Model:  lr_clear_count_1k\n",
      "0.58064516129\n",
      "Model:  xgb\n",
      "0.495967741935\n",
      "Model:  lr_tfidf_1k\n",
      "0.568548387097\n",
      "Model:  lr_tfidf_5k\n",
      "0.560483870968\n",
      "Median of models averaged per user:\n",
      "0.584677419355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of averaged model per user:\n",
      "0.58064516129\n",
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.522500995619\n",
      "Model:  mlp\n",
      "0.52608522501\n",
      "Model:  lr_count_2k_word\n",
      "0.52528872959\n",
      "Model:  lr_count_2k_char\n",
      "0.539625647153\n",
      "Model:  lr_count_5k_word\n",
      "0.529271206691\n",
      "Model:  lr_count_5k_char\n",
      "0.536041417762\n",
      "Model:  lr_clear_count_1k\n",
      "0.532058940661\n",
      "Model:  xgb\n",
      "0.534050179211\n",
      "Model:  lr_tfidf_1k\n",
      "0.533253683791\n",
      "Model:  lr_tfidf_5k\n",
      "0.543608124253\n",
      "Median of models: 0.544404619673\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.561403508772\n",
      "Model:  mlp\n",
      "0.565789473684\n",
      "Model:  lr_count_2k_word\n",
      "0.570175438596\n",
      "Model:  lr_count_2k_char\n",
      "0.578947368421\n",
      "Model:  lr_count_5k_word\n",
      "0.561403508772\n",
      "Model:  lr_count_5k_char\n",
      "0.583333333333\n",
      "Model:  lr_clear_count_1k\n",
      "0.539473684211\n",
      "Model:  xgb\n",
      "0.539473684211\n",
      "Model:  lr_tfidf_1k\n",
      "0.614035087719\n",
      "Model:  lr_tfidf_5k\n",
      "0.570175438596\n",
      "Median of models averaged per user:\n",
      "0.565789473684\n",
      "Median of averaged model per user:\n",
      "0.561403508772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.511655011655\n",
      "Model:  mlp\n",
      "0.51825951826\n",
      "Model:  lr_count_2k_word\n",
      "0.520590520591\n",
      "Model:  lr_count_2k_char\n",
      "0.532634032634\n",
      "Model:  lr_count_5k_word\n",
      "0.53108003108\n",
      "Model:  lr_count_5k_char\n",
      "0.530303030303\n",
      "Model:  lr_clear_count_1k\n",
      "0.52602952603\n",
      "Model:  xgb\n",
      "0.52602952603\n",
      "Model:  lr_tfidf_1k\n",
      "0.530303030303\n",
      "Model:  lr_tfidf_5k\n",
      "0.538461538462\n",
      "Median of models: 0.533411033411\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.509433962264\n",
      "Model:  mlp\n",
      "0.580188679245\n",
      "Model:  lr_count_2k_word\n",
      "0.556603773585\n",
      "Model:  lr_count_2k_char\n",
      "0.575471698113\n",
      "Model:  lr_count_5k_word\n",
      "0.589622641509\n",
      "Model:  lr_count_5k_char\n",
      "0.561320754717\n",
      "Model:  lr_clear_count_1k\n",
      "0.547169811321\n",
      "Model:  xgb\n",
      "0.556603773585\n",
      "Model:  lr_tfidf_1k\n",
      "0.584905660377\n",
      "Model:  lr_tfidf_5k\n",
      "0.580188679245\n",
      "Median of models averaged per user:\n",
      "0.575471698113\n",
      "Median of averaged model per user:\n",
      "0.580188679245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.506717850288\n",
      "Model:  mlp\n",
      "0.516314779271\n",
      "Model:  lr_count_2k_word\n",
      "0.520537428023\n",
      "Model:  lr_count_2k_char\n",
      "0.528598848369\n",
      "Model:  lr_count_5k_word\n",
      "0.525143953935\n",
      "Model:  lr_count_5k_char\n",
      "0.532821497121\n",
      "Model:  lr_clear_count_1k\n",
      "0.529366602687\n",
      "Model:  xgb\n",
      "0.518618042226\n",
      "Model:  lr_tfidf_1k\n",
      "0.521689059501\n",
      "Model:  lr_tfidf_5k\n",
      "0.52207293666\n",
      "Median of models: 0.523992322457\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.492462311558\n",
      "Model:  mlp\n",
      "0.537688442211\n",
      "Model:  lr_count_2k_word\n",
      "0.547738693467\n",
      "Model:  lr_count_2k_char\n",
      "0.592964824121\n",
      "Model:  lr_count_5k_word\n",
      "0.56783919598\n",
      "Model:  lr_count_5k_char\n",
      "0.587939698492\n",
      "Model:  lr_clear_count_1k\n",
      "0.562814070352\n",
      "Model:  xgb\n",
      "0.562814070352\n",
      "Model:  lr_tfidf_1k\n",
      "0.547738693467\n",
      "Model:  lr_tfidf_5k\n",
      "0.572864321608\n",
      "Median of models averaged per user:\n",
      "0.582914572864\n",
      "Median of averaged model per user:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.552763819095\n",
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.501131221719\n",
      "Model:  mlp\n",
      "0.519230769231\n",
      "Model:  lr_count_2k_word\n",
      "0.510935143288\n",
      "Model:  lr_count_2k_char\n",
      "0.525641025641\n",
      "Model:  lr_count_5k_word\n",
      "0.50754147813\n",
      "Model:  lr_count_5k_char\n",
      "0.522247360483\n",
      "Model:  lr_clear_count_1k\n",
      "0.524509803922\n",
      "Model:  xgb\n",
      "0.505279034691\n",
      "Model:  lr_tfidf_1k\n",
      "0.519230769231\n",
      "Model:  lr_tfidf_5k\n",
      "0.530165912519\n",
      "Median of models: 0.523755656109\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.532608695652\n",
      "Model:  mlp\n",
      "0.548913043478\n",
      "Model:  lr_count_2k_word\n",
      "0.559782608696\n",
      "Model:  lr_count_2k_char\n",
      "0.576086956522\n",
      "Model:  lr_count_5k_word\n",
      "0.5\n",
      "Model:  lr_count_5k_char\n",
      "0.586956521739\n",
      "Model:  lr_clear_count_1k\n",
      "0.570652173913\n",
      "Model:  xgb\n",
      "0.5\n",
      "Model:  lr_tfidf_1k\n",
      "0.538043478261\n",
      "Model:  lr_tfidf_5k\n",
      "0.586956521739\n",
      "Median of models averaged per user:\n",
      "0.565217391304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of averaged model per user:\n",
      "0.559782608696\n",
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.518449496832\n",
      "Model:  mlp\n",
      "0.530003727171\n",
      "Model:  lr_count_2k_word\n",
      "0.52851285874\n",
      "Model:  lr_count_2k_char\n",
      "0.529258292956\n",
      "Model:  lr_count_5k_word\n",
      "0.530376444279\n",
      "Model:  lr_count_5k_char\n",
      "0.525903838986\n",
      "Model:  lr_clear_count_1k\n",
      "0.540439806187\n",
      "Model:  xgb\n",
      "0.519567648155\n",
      "Model:  lr_tfidf_1k\n",
      "0.532985464033\n",
      "Model:  lr_tfidf_5k\n",
      "0.540812523295\n",
      "Median of models: 0.537830786433\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.563218390805\n",
      "Model:  mlp\n",
      "0.586206896552\n",
      "Model:  lr_count_2k_word\n",
      "0.568965517241\n",
      "Model:  lr_count_2k_char\n",
      "0.563218390805\n",
      "Model:  lr_count_5k_word\n",
      "0.591954022989\n",
      "Model:  lr_count_5k_char\n",
      "0.586206896552\n",
      "Model:  lr_clear_count_1k\n",
      "0.620689655172\n",
      "Model:  xgb\n",
      "0.557471264368\n",
      "Model:  lr_tfidf_1k\n",
      "0.591954022989\n",
      "Model:  lr_tfidf_5k\n",
      "0.649425287356\n",
      "Median of models averaged per user:\n",
      "0.609195402299\n",
      "Median of averaged model per user:\n",
      "0.586206896552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.513114148504\n",
      "Model:  mlp\n",
      "0.52124122645\n",
      "Model:  lr_count_2k_word\n",
      "0.516808274843\n",
      "Model:  lr_count_2k_char\n",
      "0.511636497968\n",
      "Model:  lr_count_5k_word\n",
      "0.5108976727\n",
      "Model:  lr_count_5k_char\n",
      "0.508681196897\n",
      "Model:  lr_clear_count_1k\n",
      "0.530476542298\n",
      "Model:  xgb\n",
      "0.530107129664\n",
      "Model:  lr_tfidf_1k\n",
      "0.515700036941\n",
      "Model:  lr_tfidf_5k\n",
      "0.530845954932\n",
      "Median of models: 0.525304765423\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.493902439024\n",
      "Model:  mlp\n",
      "0.55487804878\n",
      "Model:  lr_count_2k_word\n",
      "0.536585365854\n",
      "Model:  lr_count_2k_char\n",
      "0.506097560976\n",
      "Model:  lr_count_5k_word\n",
      "0.512195121951\n",
      "Model:  lr_count_5k_char\n",
      "0.536585365854\n",
      "Model:  lr_clear_count_1k\n",
      "0.59756097561\n",
      "Model:  xgb\n",
      "0.585365853659\n",
      "Model:  lr_tfidf_1k\n",
      "0.524390243902\n",
      "Model:  lr_tfidf_5k\n",
      "0.591463414634\n",
      "Median of models averaged per user:\n",
      "0.548780487805\n",
      "Median of averaged model per user:\n",
      "0.542682926829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.507262164125\n",
      "Model:  mlp\n",
      "0.518518518519\n",
      "Model:  lr_count_2k_word\n",
      "0.515250544662\n",
      "Model:  lr_count_2k_char\n",
      "0.512708787219\n",
      "Model:  lr_count_5k_word\n",
      "0.509077705156\n",
      "Model:  lr_count_5k_char\n",
      "0.5174291939\n",
      "Model:  lr_clear_count_1k\n",
      "0.536310820625\n",
      "Model:  xgb\n",
      "0.5232389252\n",
      "Model:  lr_tfidf_1k\n",
      "0.518881626725\n",
      "Model:  lr_tfidf_5k\n",
      "0.533042846768\n",
      "Median of models: 0.532679738562\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.532467532468\n",
      "Model:  mlp\n",
      "0.551948051948\n",
      "Model:  lr_count_2k_word\n",
      "0.545454545455\n",
      "Model:  lr_count_2k_char\n",
      "0.519480519481\n",
      "Model:  lr_count_5k_word\n",
      "0.525974025974\n",
      "Model:  lr_count_5k_char\n",
      "0.545454545455\n",
      "Model:  lr_clear_count_1k\n",
      "0.597402597403\n",
      "Model:  xgb\n",
      "0.545454545455\n",
      "Model:  lr_tfidf_1k\n",
      "0.551948051948\n",
      "Model:  lr_tfidf_5k\n",
      "0.603896103896\n",
      "Median of models averaged per user:\n",
      "0.564935064935\n",
      "Median of averaged model per user:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.558441558442\n",
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.51570964247\n",
      "Model:  mlp\n",
      "0.534850126399\n",
      "Model:  lr_count_2k_word\n",
      "0.52618273745\n",
      "Model:  lr_count_2k_char\n",
      "0.520765619357\n",
      "Model:  lr_count_5k_word\n",
      "0.534488985193\n",
      "Model:  lr_count_5k_char\n",
      "0.526905019863\n",
      "Model:  lr_clear_count_1k\n",
      "0.547128927411\n",
      "Model:  xgb\n",
      "0.513542795233\n",
      "Model:  lr_tfidf_1k\n",
      "0.5290718671\n",
      "Model:  lr_tfidf_5k\n",
      "0.526905019863\n",
      "Median of models: 0.533044420368\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.493243243243\n",
      "Model:  mlp\n",
      "0.587837837838\n",
      "Model:  lr_count_2k_word\n",
      "0.560810810811\n",
      "Model:  lr_count_2k_char\n",
      "0.533783783784\n",
      "Model:  lr_count_5k_word\n",
      "0.641891891892\n",
      "Model:  lr_count_5k_char\n",
      "0.560810810811\n",
      "Model:  lr_clear_count_1k\n",
      "0.608108108108\n",
      "Model:  xgb\n",
      "0.513513513514\n",
      "Model:  lr_tfidf_1k\n",
      "0.533783783784\n",
      "Model:  lr_tfidf_5k\n",
      "0.587837837838\n",
      "Median of models averaged per user:\n",
      "0.560810810811\n",
      "Median of averaged model per user:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.574324324324\n",
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.515873015873\n",
      "Model:  mlp\n",
      "0.505050505051\n",
      "Model:  lr_count_2k_word\n",
      "0.513347763348\n",
      "Model:  lr_count_2k_char\n",
      "0.506854256854\n",
      "Model:  lr_count_5k_word\n",
      "0.511904761905\n",
      "Model:  lr_count_5k_char\n",
      "0.516955266955\n",
      "Model:  lr_clear_count_1k\n",
      "0.532467532468\n",
      "Model:  xgb\n",
      "0.498917748918\n",
      "Model:  lr_tfidf_1k\n",
      "0.520923520924\n",
      "Model:  lr_tfidf_5k\n",
      "0.521645021645\n",
      "Median of models: 0.522727272727\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.528571428571\n",
      "Model:  mlp\n",
      "0.514285714286\n",
      "Model:  lr_count_2k_word\n",
      "0.514285714286\n",
      "Model:  lr_count_2k_char\n",
      "0.478571428571\n",
      "Model:  lr_count_5k_word\n",
      "0.5\n",
      "Model:  lr_count_5k_char\n",
      "0.542857142857\n",
      "Model:  lr_clear_count_1k\n",
      "0.571428571429\n",
      "Model:  xgb\n",
      "0.507142857143\n",
      "Model:  lr_tfidf_1k\n",
      "0.542857142857\n",
      "Model:  lr_tfidf_5k\n",
      "0.592857142857\n",
      "Median of models averaged per user:\n",
      "0.535714285714\n",
      "Median of averaged model per user:\n",
      "0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.534958766583\n",
      "Model:  mlp\n",
      "0.53101470061\n",
      "Model:  lr_count_2k_word\n",
      "0.525636428828\n",
      "Model:  lr_count_2k_char\n",
      "0.524202223019\n",
      "Model:  lr_count_5k_word\n",
      "0.537110075296\n",
      "Model:  lr_count_5k_char\n",
      "0.53280745787\n",
      "Model:  lr_clear_count_1k\n",
      "0.533166009322\n",
      "Model:  xgb\n",
      "0.502330584439\n",
      "Model:  lr_tfidf_1k\n",
      "0.537110075296\n",
      "Model:  lr_tfidf_5k\n",
      "0.528863391897\n",
      "Median of models: 0.539261384009\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.626865671642\n",
      "Model:  mlp\n",
      "0.544776119403\n",
      "Model:  lr_count_2k_word\n",
      "0.574626865672\n",
      "Model:  lr_count_2k_char\n",
      "0.559701492537\n",
      "Model:  lr_count_5k_word\n",
      "0.65671641791\n",
      "Model:  lr_count_5k_char\n",
      "0.626865671642\n",
      "Model:  lr_clear_count_1k\n",
      "0.611940298507\n",
      "Model:  xgb\n",
      "0.5\n",
      "Model:  lr_tfidf_1k\n",
      "0.582089552239\n",
      "Model:  lr_tfidf_5k\n",
      "0.589552238806\n",
      "Median of models averaged per user:\n",
      "0.60447761194\n",
      "Median of averaged model per user:\n",
      "0.574626865672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)`\n",
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for comment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/miniconda3/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lstm_word\n",
      "0.519285714286\n",
      "Model:  mlp\n",
      "0.526785714286\n",
      "Model:  lr_count_2k_word\n",
      "0.524285714286\n",
      "Model:  lr_count_2k_char\n",
      "0.53\n",
      "Model:  lr_count_5k_word\n",
      "0.531071428571\n",
      "Model:  lr_count_5k_char\n",
      "0.532857142857\n",
      "Model:  lr_clear_count_1k\n",
      "0.530714285714\n",
      "Model:  xgb\n",
      "0.493214285714\n",
      "Model:  lr_tfidf_1k\n",
      "0.529642857143\n",
      "Model:  lr_tfidf_5k\n",
      "0.53\n",
      "Median of models: 0.533571428571\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.546875\n",
      "Model:  mlp\n",
      "0.609375\n",
      "Model:  lr_count_2k_word\n",
      "0.578125\n",
      "Model:  lr_count_2k_char\n",
      "0.5703125\n",
      "Model:  lr_count_5k_word\n",
      "0.6171875\n",
      "Model:  lr_count_5k_char\n",
      "0.5703125\n",
      "Model:  lr_clear_count_1k\n",
      "0.5859375\n",
      "Model:  xgb\n",
      "0.5\n",
      "Model:  lr_tfidf_1k\n",
      "0.609375\n",
      "Model:  lr_tfidf_5k\n",
      "0.546875\n",
      "Median of models averaged per user:\n",
      "0.609375\n",
      "Median of averaged model per user:\n",
      "0.609375\n",
      "CPU times: user 18h 3min 49s, sys: 1h 44min 33s, total: 19h 48min 23s\n",
      "Wall time: 5h 49min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(0)\n",
    "scores = []\n",
    "for i in range(1, 21):\n",
    "    sc = fit_predict_to_n_user(comments,\n",
    "            [\n",
    "                LstmModel('lstm_word', nb_epoch=5),\n",
    "    #             LstmModel('lstm_char', nb_epoch=5, nb_words=100, char_level=True, max_len=100),\n",
    "                MlpModel('mlp'),\n",
    "                LrModelCount('lr_count_2k_word', 2000, ngram_range=(1, 2)),\n",
    "                LrModelCount('lr_count_2k_char', 2000, 'char', (3, 3)),\n",
    "                LrModelCount('lr_count_5k_word', 5000, ngram_range=(1, 2)),\n",
    "                LrModelCount('lr_count_5k_char', 5000, 'char', (3, 3)),\n",
    "\n",
    "                LrModelCountClear('lr_clear_count_1k', 1000),\n",
    "                FeaturesModelXGB('xgb'),\n",
    "                LrModelTfidf('lr_tfidf_1k', 1000),\n",
    "                LrModelTfidf('lr_tfidf_5k', 5000),\n",
    "            ], i, False, with_additional=True, debug=False)\n",
    "    scores.append(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAGCCAYAAAD5b1poAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57ccc7f6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(range(1, 21), [x[1] for x in scores])\n",
    "# plt.plot(range(3, 21), [x[1] for x in scores])\n",
    "# plt.yticks(np.round(np.linspace(0.51, 0.66, 16), 2));\n",
    "# plt.xticks(np.linspace(0, 16, 17));\n",
    "# plt.ylim(0.51, 0.66)\n",
    "# plt.xlim(0, 16)\n",
    "plt.xlabel('–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª-–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤')\n",
    "plt.ylabel('–¢–æ—á–Ω–æ—Å—Ç—å')\n",
    "plt.title('–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ç–æ—á–Ω–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª-–≤–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.savefig('temp1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniq_ids = []\n",
    "for i in range(1, 21):\n",
    "    unique_ids = comments.from_id.value_counts()[comments.from_id.value_counts() >= i].index.values\n",
    "    uniq_ids.append(len(unique_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAGCCAYAAAAMkdHYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfyGknEGsbI5WAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57cc276630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1,21), uniq_ids)\n",
    "# plt.xticks(np.linspace(0, 16, 17));\n",
    "plt.xlabel('–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª-–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤')\n",
    "plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–µ–ª–æ–≤–µ–∫')\n",
    "plt.title('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–µ–ª–æ–≤–µ–∫ –ø—Ä–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª-–≤–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.savefig('temp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
