{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/anaconda3/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/home/digitman/anaconda3/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/home/digitman/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/digitman/anaconda3/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from stop_words import get_stop_words\n",
    "import Stemmer\n",
    "import pymorphy2\n",
    "from segtok import segmenter\n",
    "import re\n",
    "from functools import partial\n",
    "import pickle\n",
    "from gensim import corpora, models\n",
    "from gensim.models import word2vec\n",
    "import xgboost as xgb \n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/comments_vrn.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185612, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    98373\n",
       "1.0    87239\n",
       "Name: is_gum, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_gum.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_gum</th>\n",
       "      <th>hour</th>\n",
       "      <th>likes</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9048238</td>\n",
       "      <td>–í–∂—É—Ö –¥–∞–∂–µ –∑–¥–µ—Å—å</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9048238</td>\n",
       "      <td>–ò –ø–∏—à–∏—Ç–µ –∞–∫–∫—É—Ä–∞—Ç–Ω–µ–µ üòû</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9048238</td>\n",
       "      <td>–≠—Ç–æ #–∏–º–±—Ä–∏–Ω–∞ üòè</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   from_id                   text  is_gum  hour  likes  sex\n",
       "0  9048238        –í–∂—É—Ö –¥–∞–∂–µ –∑–¥–µ—Å—å     0.0    20      1    2\n",
       "1  9048238  –ò –ø–∏—à–∏—Ç–µ –∞–∫–∫—É—Ä–∞—Ç–Ω–µ–µ üòû     0.0    12      3    2\n",
       "2  9048238         –≠—Ç–æ #–∏–º–±—Ä–∏–Ω–∞ üòè     0.0    21      0    2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lenghts_word = np.array([len(m.split()) for m in data.text.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.451069973924099, 7.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenghts_word.mean(), np.median(lenghts_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114275, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = data[(lenghts_word < 50) & (lenghts_word > 4)]\n",
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54% of comments contain links\n"
     ]
    }
   ],
   "source": [
    "links = [m for m in data.text.values if 'http' in m or 'www' in m or '.ru' in m or '.com' in m] \n",
    "print('{:.2f}% of comments contain links'.format(len(links) / len(data) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "without_link = [False if 'http' in c or 'www' in c or '.ru' in c or '.com' in c else True\n",
    "                for c in comments.text.values] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = comments[without_link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113709, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Droping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=1000, ngram_range=(1, 2), analyzer='word', max_df=0.6)\n",
    "X = vectorizer.fit_transform([' '.join(t.split()[:5]) for t in comments.text.values])\n",
    "y = comments.is_gum.values\n",
    "# y = comments.sex.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=1000, ngram_range=(3, 3), analyzer='char')\n",
    "X = vectorizer.fit_transform([' '.join(t.split()[:4]) for t in comments.text.values])\n",
    "y = comments.is_gum.values\n",
    "# y = comments.sex.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = IsolationForest(200, contamination=0.01, n_jobs=-1)\n",
    "forest.fit(X)\n",
    "X_pred = forest.predict(X)\n",
    "comments['len'] = [len(t) for t in comments.text.values]\n",
    "comments['outlier'] = X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ '[id77046083|–í–∏–∫—Ç–æ—Ä], –∫—Å—Ç–∞—Ç–∏, —Ç—É—Ç –Ω–∏–∫–∞–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ—Ç. –°–Ω–∏–∑—É —Å–ª–µ–≤–∞. –ï—Å–ª–∏ —Å–º–æ—Ç—Ä–µ—Ç—å —Å –ó–µ–º–ª–∏.',\n",
       "       '[id254300877|–í–∏–∫—Ç–æ—Ä–∏—è], –∏–º–µ–Ω–Ω–æ! –¢–æ–ª—å–∫–æ –Ω–µ –∑–Ω–∞—é—Ç –æ–± —ç—Ç–æ–º.',\n",
       "       '[id254300877|–í–∏–∫—Ç–æ—Ä–∏—è], –∫–æ—Ç–æ—Ä–æ–≥–æ –±–æ–∂–µ—Å—Ç–≤–∞? –ù–∏–∫—Ç–æ –Ω–µ —Ö–∞–º–∏—Ç –≤ —Å—Ç–æ—Ä–æ–Ω—É –∏—Å—Ç–∏–Ω–Ω–æ–≥–æ –ë–æ–≥–∞, –õ–µ—Ç–∞—é—â–µ–≥–æ –∏ –ú–∞–∫–∞—Ä–æ–Ω–Ω–æ–≥–æ!',\n",
       "       '[id6628178|–°–µ—Ä–≥–µ–π], –æ, –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ. –î–ª—è –ø–ª–∞–Ω–æ–≤–æ–≥–æ —É–Ω–∏—á—Ç–æ–∂–µ–Ω–∏—è –≤–Ω–∞—á–∞–ª–µ –Ω–∞–¥–æ –ø—Ä–æ–≤–µ—Å—Ç–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ. –ù–µ—É–∂—Ç–æ —Ä—É–∫–∏ –¥–æ—à–ª–∏?! –ß–µ—Å—Ç–Ω–æ –≥–æ–≤–æ—Ä—è, —Å–ª–∞–±–æ —Å–µ–±–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é...',\n",
       "       '[id59044595|–ê–ª–µ–∫—Å–µ–π], –∫—Å—Ç–∞—Ç–∏ —Å–∫–∞–∑–∞—Ç—å, —è –¥–∏–∞–º–µ—Ç—Ä–∞–ª—å–Ω–æ –∏–∑–º–µ–Ω–∏–ª —Å–≤–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ –†–ü–¶ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –ª–µ—Ç. –ù–∞—á–Ω–µ–º —Å —Ç–æ–≥–æ, —á—Ç–æ –≤ –ø–µ—Ä–≤–æ–π –ø–æ–ª–æ–≤–∏–Ω–µ 90-—Ö —è –∫—Ä–µ—Å—Ç–∏–ª—Å—è. –¢–µ–ø–µ—Ä—å –∂–µ —è –±—ã —Å —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ–º –≤–∑–æ—Ä–≤–∞–ª —Ö—Ä–∞–º –õ—É–∂–∫–∞ –°—Ç—Ä–æ–∏—Ç–µ–ª—è –µ—â–µ —Ä–∞–∑.',\n",
       "       '[id59044595|–ê–ª–µ–∫—Å–µ–π], –ø—Ä–∞–≤–∏–ª—å–Ω–æ. –í–µ—Ä–Ω–æ. –î–ª—è –º–µ–Ω—è —Å–≤—è—Ç —Ä–∞–∑—É–º. –ü–æ—á–µ–º—É —è –¥–æ–ª–∂–µ–Ω –º–æ–ª—á–∞—Ç—å, –∫–æ–≥–¥–∞ –µ–≥–æ –ø–æ–ø–∏—Ä–∞—é—Ç?',\n",
       "       '[id102189842|–ú–∞—Ä–∏—è], –î–∞ –ø—É—Å—Ç—å –≤—ã—Å–∫–∞–∑—ã–≤–∞—Ç—å—Å—è... –û–Ω –Ω–µ —É–¥–∞—á–Ω–∏–∫ –ø—Ä–æ—Å—Ç–æ –∂–∞–ª—å –µ–≥–æ... –ê —Ç—É—Ç –æ–Ω —Å–µ–±—è –ø—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —á—Ç–æ–± –µ–≥–æ –∑–∞–º–µ—Ç–∏–ª–∏ üòÇüòÇüòÇ–Ω–æ –æ–Ω –Ω–µ —Å—Ç–æ–∏—Ç –≤–∞—à–∏—Ö –Ω–µ—Ä–≤–æ–≤ –∑–∞–±–µ–π—Ç–µ –Ω–∞ –Ω–µ–≥–æ üëçüëçüëç',\n",
       "       '[id16867860|–î–º–∏—Ç—Ä–∏–π], –ù–µ—Ç –Ω–µ –ø–µ—Ä–µ–≤–µ–ª—Å—è —è –∂ –ø–æ—ç—Ç–æ–º—É –≤–∞–º –∏ –ø–∏—à—É —Ç—É—Ç üòÇüòÇüòÇüòÇüëçüëçüëç–Ω–∞ —Ö—Ä–µ–Ω–∞ –º–Ω–µ —ç—Ç–∏ –µ—Å–ª–∏ –µ—Å—Ç—å —Å–≤–æ–∏ –∏–∑–≤—Ä–∞—â–µ–Ω—Ü—ã üòÇüòÇüòÇüòÇ',\n",
       "       '[id16867860|–î–º–∏—Ç—Ä–∏–π], –±–æ—é—Å—å –Ω–µ –¥–æ–≤–µ–∑—É üòÇüòÇüòÇüòÇ',\n",
       "       '[id16867860|–î–º–∏—Ç—Ä–∏–π], —è —Ç–∞–∫ –ø–æ–Ω–∏–º–∞—é —Ç—É—Ç —É–∂–µ –≤—Å–µ —Ö–≤–∞—Å—Ç–∞—é—Ç—Å—è –∫—Ç–æ —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø–æ–º–æ–≥–∞–µ—Ç üòÇüëç'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[comments.outlier == -1].head(10).text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_id</th>\n",
       "      <th>is_gum</th>\n",
       "      <th>hour</th>\n",
       "      <th>likes</th>\n",
       "      <th>sex</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outlier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1.003984e+08</td>\n",
       "      <td>0.494728</td>\n",
       "      <td>11.980668</td>\n",
       "      <td>0.467487</td>\n",
       "      <td>1.660808</td>\n",
       "      <td>108.568541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.166110e+07</td>\n",
       "      <td>0.461940</td>\n",
       "      <td>12.739027</td>\n",
       "      <td>1.073891</td>\n",
       "      <td>1.701993</td>\n",
       "      <td>88.377273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              from_id    is_gum       hour     likes       sex         len\n",
       "outlier                                                                   \n",
       "-1       1.003984e+08  0.494728  11.980668  0.467487  1.660808  108.568541\n",
       " 1       9.166110e+07  0.461940  12.739027  1.073891  1.701993   88.377273"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.groupby('outlier').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_list = comments.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('emoji.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "emojis = [line[0] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_with_emoji(comment):\n",
    "    for em in emojis:\n",
    "        if em in comment:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def with_emoji(comments):\n",
    "    return [is_with_emoji(c) for c in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_emoji(comment, repetition=True):\n",
    "    ems = []\n",
    "    for em in emojis:\n",
    "        if not repetition:\n",
    "            if em in comment:\n",
    "                ems.append(em)\n",
    "        else:\n",
    "            founded = re.findall(em, comment)\n",
    "            if len(founded) > 0:\n",
    "                ems.extend(founded)\n",
    "    return ems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If not done before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113709"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %time emoji_from_comments_rep = list(map(get_emoji, comments_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('emoji_from_comments_rep_vrn.pkl', 'wb') as f:\n",
    "    pickle.dump(emoji_from_comments_rep, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Else load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113709, 113709)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('emoji_from_comments_rep_vrn.pkl', 'rb') as f:\n",
    "    emoji_from_comments_rep = pickle.load(f)\n",
    "emoji_from_comments_no_rep = list(map(lambda com: get_emoji(com, False), comments_list))\n",
    "len(comments_list), len(emoji_from_comments_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_emoji_proportion(comments, emoji_from_coms=None, repetition=True):\n",
    "    emoji_proportion = [] \n",
    "    func = lambda com: get_emoji(com, repetition)\n",
    "    if not emoji_from_coms:\n",
    "        emoji_from_coms = list(map(func, comments))\n",
    "    \n",
    "    for i in range(len(comments)):\n",
    "        com = re.sub(' *', '', comments[i])\n",
    "        emoji_proportion.append(len(emoji_from_coms[i]) / len(com))\n",
    "    return np.array(emoji_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em_proportion_rep = get_emoji_proportion(comments_list, emoji_from_comments_rep)\n",
    "em_proportion_no_rep = get_emoji_proportion(comments_list, emoji_from_comments_no_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['üëçüëçüëçüëçüëçüëç–∫–ª–∞–∞–∞—Å‚ùó‚ùó‚ùó‚ùó —ç—Ç–∞ –µ–ª–∫–∞ –±—É–¥–µ–µ–µ—Ç —Å–∞–º–æ–π –∫—Ä–∞—Å–∏–≤–æ–πüòÇüòÇüòÇüòÇ',\n",
       "       'üòÇüòÇüòÇüòÇüëçüëçüëç–Ω –Ω—É —ç—Ç–æ –∂ –ª—é–¥–∏....\\nüòÇüòÇüòÇ–±–ª–∏–Ω –∞ –∫–æ–≥–¥–∞ –Ω–æ–≤—ã–π –≥–æ–¥???üòÇ',\n",
       "       'üòÇüòÇüòÇüòÇüòÇüòÇ–≤–æ—Ç –±—ã –º–µ–Ω—è –Ω–∞ –∫—É–ø—é—Ä—É –Ω–µ –ø–ª–æ—Ö–æ–æ–æ –±—ã–ª–æ –±üòÇüòÇüòÇ',\n",
       "       '–ò –∑–¥–µ—Å—å —Ö–æ—Ä–æ—à–æ –∏ —Ç–∞–º —Ö–æ—Ä–æ—à–æ....üëçüëçüëçüëçüëçüëçüëçüëçüëç',\n",
       "       '–î–∞ —á—Ç–æ –≤—ã... –ö–æ–º—É —á—Ç–æ –Ω—Ä–∞–≤–∏—Ç—Å—è üòçüòçüòçüòçüëçüëçüëçüëçüëçüëçüëçüëç',\n",
       "       '–ê –º–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –º–æ–∂–Ω–æ –≤–æ–æ–±—â–µ –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å üòÇüòÇüòÇüòÇüòÇüëçüëçüëçüëçüëçüëç',\n",
       "       'üòçüòçüòçüòçüòçüòç–∏ —Ç–∏—à–∏–Ω–∞ –∏ —Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ üëçüëçüëçüëçüëç',\n",
       "       '–ö–æ–º—É –∫–∞–∫ –Ω–æ –í–æ—Ä–æ–Ω–µ–∂ —ç—Ç–æ –≤–æ—Ä–æ–Ω–µ–∂ –ª—é–±–∏–º –∏ –±—É–¥–µ–º –ª—é–±–∏—Ç—å üòçüòçüòçüòçüòçüòçüòçüòçüòçüëçüëçüëçüëçüëçüëçüëç',\n",
       "       '–ê —è –æ—Ç–ø—Ä–∞–≤–ª—é :–æ–¥—É–º–∞–π—Å—è –Ω–µ –≥–ª—É–ø–∏ –∑–∞–º—É–∂ –Ω–µ –≤—ã—Ö–æ–¥–∏ üòÇüòÇüòÇüòÇüòÇüòÇüëçüëçüëçüëç',\n",
       "       '–û–æ–æ–æ –ø–æ–¥—Å–æ–ª–Ω—É—Ö–∏ üëçüëçüëçüëçüòçüòçüòçüòçüòçüòçüëçüåª üåª üåªüåªüåªüåªüåªüåªüåªüåªüåªüåªüåªüåª'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((em_proportion_rep > 0.2).sum())\n",
    "comments_list[em_proportion_rep > 0.2][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['–ì–ª–∞–≤–Ω–æ–µ —á—Ç–æ–± –Ω–µ –ø–æ–∑–¥–Ω–æ üòÇüòÇüòÇüëç', 'üòÇüòÇüòÇ—ç—Ç–æ —è —Å –ü–µ—Ä–º–∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—Å—å üòçüòç',\n",
       "       '–û–æ–æ–æ –ø–æ–¥—Å–æ–ª–Ω—É—Ö–∏ üëçüëçüëçüëçüòçüòçüòçüòçüòçüòçüëçüåª üåª üåªüåªüåªüåªüåªüåªüåªüåªüåªüåªüåªüåª',\n",
       "       'üòÇüòÇüòÇüòÇüòÇ—ç—Ç–æ –µ—â–µ —á—Ç–æ —Ç–∞–∫–æ–µ üòÇüòÇüòÇüòÇüòÇüëçüëçüëç',\n",
       "       'üëçüëçüëçüëçüëçüëçüëçüòçüòçüòçüòçüòçüòç—Å–∞–º—ã–π  –ª—É—á—à–∏–π –∫—Ä–∞—Å–∏–≤—ã–π –≥–æ—Ä–æ–¥ üòõüòõüòõ',\n",
       "       'üòÇüòÇüòÇüòÇüòÇüëçüëçüëçüëçüëç–≤–æ—Ç —Ç–µ –Ω–∞ —Ü–∞—Ä–∏—Ü–∞ –ø—Ä—è–º', 'üòÇüòÇüòÇüòÇüòÇüëçüëçüëçüëç–∞ —è —Ç–∞–∫ —á–∞—Å—Ç–æ –µ–¥—É üòÇüòÇüòÇ',\n",
       "       'üòÇüòÇüòÇüòÇ–∞ —è –Ω–∏—á–µ–≥–æ —Å–µ–±–µ –Ω–µ —Å–∫–∞–∂—É üëçüëçüëç',\n",
       "       '–° –≥–æ—Ä–µ–º –ø–æ–ø–æ–ª–∞–º... ‚ùÑ  ‚ùÑ  ‚ùÑ  ‚ùÑ  ‚ùÑ  üëç',\n",
       "       '[id138651229|–ù–∏–∫–∏—Ç–∞], –ò –ø—Ä—è–º –ø–µ—Ä–µ–¥ –ù–ì! üéÑ üéÑ üçª üçª üç∑ üç∑ ‚ùÑ ‚ùÑ ‚ùÑ ‚ùÑ ‚ùÑ ‚ùÑ'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((em_proportion_no_rep > 0.07).sum())\n",
    "comments_list[em_proportion_no_rep > 0.07][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of alphabetical symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_abc_proportion(comments):\n",
    "    abc_proportion = []     \n",
    "    for i in range(len(comments)):\n",
    "        com = re.sub(' *', '', comments[i])\n",
    "        abc = re.findall('[–∞-—è—ëa-z]', com, flags=re.IGNORECASE)\n",
    "        abc_proportion.append(len(abc) / len(com))\n",
    "    return np.array(abc_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abc_proportion = get_abc_proportion(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "549"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abc_proportion < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['+7 952 104 73 50', '[id33372525|–î–µ–Ω–∏—Å], –∞ –∫—Ç–æ –≤ 14)?',\n",
       "       '–û–æ–æ–æ –ø–æ–¥—Å–æ–ª–Ω—É—Ö–∏ üëçüëçüëçüëçüòçüòçüòçüòçüòçüòçüëçüåª üåª üåªüåªüåªüåªüåªüåªüåªüåªüåªüåªüåªüåª',\n",
       "       '[id366133865|–ê–Ω–¥—Ä–µ–π], —É –º–µ–Ω—è –∫–æ—Ç))) –ø–æ–¥–æ–π–¥–µ—Ç????? üòÇüòÇüòÇüòÇ',\n",
       "       '[id330930820|–õ—è—Å—å–∫–∞], –∞ —É –º–µ–Ω—è —Ç–æ–∂–µ.... üòÇüòÇüëç',\n",
       "       '[id322876931|–ê–Ω–¥—Ä–µ–π], üòÇüòÇüòÇüòÇ –≤–æ—Ç –±–ª–∏–Ω üòÇüòÇüòÇ',\n",
       "       '[id16867860|–î–º–∏—Ç—Ä–∏–π], –Ω–æ —É–∂ –Ω–µ—Ç))) üòÇüòÇüòÇüòÇ',\n",
       "       '[id42740602|–Æ–ª–∏—è], –±—É–¥—É—Ç –¥–≤–µ 1, 22, 29, 38, 55 –∏ 120–ê –≤—Å–µ –ø–ª–∞—Ç–Ω—ã–µ.',\n",
       "       '[id290551639|Vika], –∞ —É –≤–∞—Å —ç',\n",
       "       '[id138651229|–ù–∏–∫–∏—Ç–∞], –ò –ø—Ä—è–º –ø–µ—Ä–µ–¥ –ù–ì! üéÑ üéÑ üçª üçª üç∑ üç∑ ‚ùÑ ‚ùÑ ‚ùÑ ‚ùÑ ‚ùÑ ‚ùÑ'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_list[abc_proportion < 0.5][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments['emojis'] = [' '.join(e) for e in emoji_from_comments_rep]\n",
    "comments['em_proportion_rep'] = em_proportion_rep\n",
    "comments['em_proportion_no_rep'] = em_proportion_no_rep\n",
    "comments['abc_proportion'] = abc_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_gum</th>\n",
       "      <th>hour</th>\n",
       "      <th>likes</th>\n",
       "      <th>sex</th>\n",
       "      <th>len</th>\n",
       "      <th>outlier</th>\n",
       "      <th>emojis</th>\n",
       "      <th>em_proportion_rep</th>\n",
       "      <th>em_proportion_no_rep</th>\n",
       "      <th>abc_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9048238</td>\n",
       "      <td>–Ω—É –ø–ø—Ü, —É–∂–µ –ø—Ä–æ—Å—Ç–æ —Ç–∞–∫ —Ç–µ–ª–µ—Ñ–æ–Ω –Ω–µ –∑–∞—Ä—è–¥–∏—à—å... üòÜ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>üòÜ</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10679122</td>\n",
       "      <td>[id332962766|–ò–≥–æ—Ä—å], –æ–Ω–∏ –∫–∞–≥–±—ç –Ω–∞–º–µ–∫–∞—é—Ç, —á—Ç–æ –Ω...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10679122</td>\n",
       "      <td>[id386347082|Jeg-Hater], –ø—Ä–æ—Å—Ç–æ –≤–æ—é! –ë–ª–∏-–∏-–Ω.....</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.739837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from_id                                               text  is_gum  hour  \\\n",
       "6   9048238    –Ω—É –ø–ø—Ü, —É–∂–µ –ø—Ä–æ—Å—Ç–æ —Ç–∞–∫ —Ç–µ–ª–µ—Ñ–æ–Ω –Ω–µ –∑–∞—Ä—è–¥–∏—à—å... üòÜ     0.0    22   \n",
       "7  10679122  [id332962766|–ò–≥–æ—Ä—å], –æ–Ω–∏ –∫–∞–≥–±—ç –Ω–∞–º–µ–∫–∞—é—Ç, —á—Ç–æ –Ω...     0.0    20   \n",
       "8  10679122  [id386347082|Jeg-Hater], –ø—Ä–æ—Å—Ç–æ –≤–æ—é! –ë–ª–∏-–∏-–Ω.....     0.0    21   \n",
       "\n",
       "   likes  sex  len  outlier emojis  em_proportion_rep  em_proportion_no_rep  \\\n",
       "6      4    2   47        1      üòÜ           0.025641              0.025641   \n",
       "7      0    2  101        1                  0.000000              0.000000   \n",
       "8      0    2  141        1                  0.000000              0.000000   \n",
       "\n",
       "   abc_proportion  \n",
       "6        0.871795  \n",
       "7        0.818182  \n",
       "8        0.739837  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If message repeats more than one time - drop (spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261 different spam comments\n"
     ]
    }
   ],
   "source": [
    "print('{} different spam comments'.format((comments.text.value_counts() > 1).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792 total count of spam comments\n"
     ]
    }
   ],
   "source": [
    "print('{} total count of spam comments'\n",
    "      .format(comments.text.value_counts()[comments.text.value_counts() > 1].values.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_comments = comments.text.value_counts()[comments.text.value_counts() > 1].keys()\n",
    "comments = comments[comments.text.apply(lambda t: t not in spam_comments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_to_del = comments[(comments.em_proportion_rep > 0.15).values | (comments.abc_proportion < 0.5).values | \n",
    "                        (comments.text.value_counts() != 1).values].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(635,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_del.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments.drop(index_to_del, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112282, 12)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_list = comments.text.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_list = []\n",
    "for comment in comments.text.values:\n",
    "    c = comment.split()\n",
    "    if c[0].startswith('[id'):\n",
    "        c[0] = '–∏–º—è'\n",
    "    c_ = []\n",
    "    for w in c:\n",
    "        if w.startswith('id'):\n",
    "            c_.append('–∏–º—è')\n",
    "        else:\n",
    "            c_.append(w)\n",
    "    comments_list.append(' '.join(c))\n",
    "comments_list = np.array(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['–Ω—É –ø–ø—Ü, —É–∂–µ –ø—Ä–æ—Å—Ç–æ —Ç–∞–∫ —Ç–µ–ª–µ—Ñ–æ–Ω –Ω–µ –∑–∞—Ä—è–¥–∏—à—å... üòÜ',\n",
       "       '–∏–º—è –æ–Ω–∏ –∫–∞–≥–±—ç –Ω–∞–º–µ–∫–∞—é—Ç, —á—Ç–æ –Ω–∞–∫—Ä—É—á–∏–≤–∞—é—Ç –ª–µ–≤—ã—Ö –ø–ª–∞—Ç–µ–∂–µ–π –Ω–µ –æ—á–µ–Ω—å –º–Ω–æ–≥–æ. –°—É–∫–∏ –æ–Ω–∏ –≤—Å–µ.',\n",
       "       '–∏–º—è –ø—Ä–æ—Å—Ç–æ –≤–æ—é! –ë–ª–∏-–∏-–Ω... –ê –∑–Ω–∞–µ—à—å, —á—Ç–æ —Ç–∞–∫–æ–µ –±—É–∫–≤–∞ \"–£\" –Ω–∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª—è—Ö :)))) (—Å–∫–æ–ª—å–∫–æ –∂–µ –¥–µ–±–∏–ª–æ–≤ –Ω–∞ —Å–≤–µ—Ç–µ,–∞?)'], \n",
       "      dtype='<U421')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments.text = comments_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clearing comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = comments.is_gum.values\n",
    "adj_proportion = []\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_comments(comments, with_stemmer=False, with_lemmer=True, to_lower=True, without_names=False,\n",
    "                without_stop_words=False, min_word_len=None, with_emoji=False):\n",
    "    global adj_proportion\n",
    "    global errors \n",
    "    adj_proportion = []\n",
    "    errors = []\n",
    "    clear_comments = []\n",
    "    stop_words = set(get_stop_words('ru'))\n",
    "    stemmer = Stemmer.Stemmer('russian')\n",
    "    lemmer = pymorphy2.MorphAnalyzer()\n",
    "    \n",
    "    names_del = 0\n",
    "    i = -1\n",
    "    for comment in comments:\n",
    "        comment_ = comment\n",
    "        i += 1\n",
    "        if to_lower:\n",
    "            comment = comment.lower()\n",
    "        comment = re.sub('[^–∞-—è–ê-–Ø—ë–Åa-zA-Z\\-]', ' ', comment)\n",
    "        comment = comment.split()\n",
    "        if without_stop_words:\n",
    "            comment = [c for c in comment if c not in stop_words]\n",
    "        if with_stemmer:\n",
    "            comment = stemmer.stemWords(comment)\n",
    "            if without_names:\n",
    "                with open('names_from_sent.txt', 'r') as f:\n",
    "                    names = f.readlines()\n",
    "                    names = set([name.strip() for name in names])\n",
    "                before = len(comment)\n",
    "                comment = [c for c in comment if c not in names]\n",
    "                aft = len(comment)\n",
    "                names_del += before - aft\n",
    "        elif with_lemmer:\n",
    "            parsed = [lemmer.parse(c)[0] for c in comment]\n",
    "            comment = [p.normal_form for p in parsed]\n",
    "            adj = sum([1 for p in parsed if 'ADJ' in str(p.tag)])\n",
    "            if len(comment) == 0:\n",
    "                errors.append(comment_)\n",
    "                adj_proportion.append(0)\n",
    "            else:\n",
    "                adj_proportion.append(adj / len(comment))\n",
    "            if without_names:\n",
    "                with open('names.txt', 'r') as f:\n",
    "                    names = f.readlines()\n",
    "                    names = set([name.strip() for name in names])\n",
    "                    before = len(comment)\n",
    "                    comment = [c for c in comment if c not in names]\n",
    "                    aft = len(comment)\n",
    "                    names_del += before - aft\n",
    "        if min_word_len is not None:\n",
    "            comment = [c for c in comment if len(c) >= min_word_len]\n",
    "        if with_emoji:\n",
    "            comment.extend(emoji_from_comments_rep[i])\n",
    "        clear_comments.append(' '.join(comment))\n",
    "    print('names del: {}'.format(names_del))\n",
    "    return clear_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names del: 7797\n",
      "CPU times: user 9min 47s, sys: 5.8 s, total: 9min 53s\n",
      "Wall time: 10min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clear_coms = clear_comments(comments_list, min_word_len=3, with_emoji=True, with_stemmer=False,\n",
    "                            with_lemmer=True, without_names=True, without_stop_words=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–∏–º—è –≤–æ—Ç —ç—Ç–æ –Ω–æ–º–µ—Ä –¥–∞–≤–∞—Ç—å —Å–≤–∞–ª–∏—Ç—å –∫—É–¥–∞-–Ω–∏–±—É–¥—å –Ω–∞—à –¥–æ–º –∏–ª–∏ –±—ã—Ç—å –¥–∞–≤–∞—Ç—å –∏–¥–∏–æ—Ç—Å–∫–∏–π —Å–æ–≤–µ—Ç —ç—Ç–æ –º–æ–π –¥–æ–º –Ω–∏—á—É—Ç—å –º–∞–ª–µ–Ω—å–∫–∏–π —á–µ–º –≤–∞—à –Ω–µ–ø—Ä–∏—è—Ç–Ω–æ –Ω–µ–º–æ–π –≤–∏–¥–µ—Ç—å –∏–Ω—Ç–µ—Ä—å–µ—Ä –≤–µ–∫',\n",
       " '–∏–º—è –ø—Ä–æ —ç—Ç–æ —Ç–æ—Ç –ø–æ–¥–æ–±–Ω—ã–π',\n",
       " '–∏–º—è —á—Ç–æ –≤–µ—Å—å –º–æ–ª–æ–∫–æ –≤–∞—à –≥—Ä—É–ø–ø–∞ –Ω–∞–∑–≤–∞—Ç—å —Å–æ–±–∏—Ä–∞—Ç—å—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –µ—â—ë —Ä–∞–∑ –µ—Å–ª–∏ –ø–æ–Ω—è—Ç—å –º–æ–π –º—ã—Å–ª—å',\n",
       " '–∏–º—è –≤–∞—à –≤–æ–∏–Ω—Å—Ç–≤–æ –∫–æ–º —Å–æ–ª–¥–∞—Ç —ç—Ç–æ —Å–µ—Ä—å—ë–∑–Ω–æ',\n",
       " '–∏–º—è –ø–æ—Ç–æ–º –ø–æ–ø–æ–≤ —Ñ–æ–Ω–∞—Ä—å –≤–µ—à–∞—Ç—å –ø—Ä–∏—á—ë–º —á–µ–∫–∏—Å—Ç –æ—Ç–Ω—é–¥—å –±—ã—Ç—å –º–µ—Ä–∏—Ç—å—Å—è –ø–∏–ø–∏—Å—å–∫–∞']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_coms[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14705882352941177,\n",
       " 0.2857142857142857,\n",
       " 0.14285714285714285,\n",
       " 0.09090909090909091,\n",
       " 0.0]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_proportion[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.77 s, sys: 44 ms, total: 6.81 s\n",
      "Wall time: 6.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = CountVectorizer(max_features=10000, min_df=100, ngram_range=(1, 2), analyzer='word')\n",
    "word_features = vectorizer.fit_transform(clear_coms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['–∑–∞', '–≤—á–µ—Ä–∞', '–±–∞–±–∞', '–∑–≤–æ–Ω–∏—Ç—å', '–≤–æ–∑–∏—Ç—å', '–ø–∞–¥–∞—Ç—å', '–º–∞–ª—å—á–∏–∫',\n",
       "       '–≤—ã–∑–≤–∞—Ç—å', '–∏—Å–∫–∞—Ç—å', '–∫—Ä—ã—à–∞', '–º–µ–Ω—è—Ç—å', '–∏–º—è –±—ã—Ç—å', '–∫—Ä–∞—Å–∏–≤–æ',\n",
       "       '–Ω–æ–≤—ã–π', '–≤–µ—Å–Ω–∞', '–¥–æ—Å—Ç–æ–π–Ω—ã–π', '–∂–∞–ª–∫–æ', '–∏–º—è –∞–≥–∞', '–Ω–∏–∂–µ', '–≤—ã–ø–∏—Ç—å'], \n",
       "      dtype='<U18')"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectorizer.get_feature_names())[np.random.randint(0, 1000, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = lm.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-1cc2881736f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_gum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word_features' is not defined"
     ]
    }
   ],
   "source": [
    "np.mean(cross_val_score(lr, word_features, comments.is_gum, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the first letter of sentence upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_stat(comments):\n",
    "    big_letter = []\n",
    "    sents_count = []\n",
    "    for comment in comments:\n",
    "        sents = list(segmenter.split_single(re.sub('(\\)+|\\.+)', '\\n', comment)))\n",
    "        count = sum([1 for sent in sents if sent and (sent[0].isupper() or '–∏–º—è' in sent\n",
    "                                                      or (len(sent) > 1 and sent[0] == '\"' and sent[1].isupper()))])\n",
    "        total = sum([1 for sent in sents if sent.strip() != ''\n",
    "                     and re.match('.*[a-z–∞-—è—ë].*', sent.strip(), flags=re.IGNORECASE)])\n",
    "        # print(count, total)\n",
    "        if total:\n",
    "            big_letter.append(count // total)\n",
    "        else:\n",
    "            big_letter.append(1)\n",
    "        if total > 3:\n",
    "            total = 4\n",
    "        if total < 1:\n",
    "            total = 1\n",
    "        sents_count.append(total)\n",
    "    return big_letter, sents_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.79 s, sys: 12 ms, total: 4.8 s\n",
      "Wall time: 4.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "big_letter, sents_count = sentence_stat(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    61633\n",
       "2    30433\n",
       "3    11832\n",
       "4     8384\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(sents_count).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    75977\n",
       "0    36305\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(big_letter).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation count in comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def punctuation_counts(comments, pattern='\\(+', partion=False):\n",
    "    if partion:\n",
    "        return [sum(len(p) for p in re.findall(pattern, c)) / len(c) for c in comments]\n",
    "    else:\n",
    "        return [1 if len(re.findall(pattern, c)) > 0 else 0 for c in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "commas = punctuation_counts(comments_list, pattern='[\\.]{2,}', partion=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    93994\n",
       "1    18288\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(commas).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_word_length(comments):\n",
    "    lengths = []\n",
    "    for comment in comments:\n",
    "        comment = comment.lower()\n",
    "        comment = re.sub('[^–∞-—è—ë\\-]', ' ', comment).split()\n",
    "        ls = [len(w) for w in comment]\n",
    "        if len(ls):\n",
    "            lengths.append(sum(ls) / len(ls))\n",
    "        else:\n",
    "            lengths.append(1)\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_length = mean_word_length(comments_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caps WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def caps_words(comments, partion=False):\n",
    "    caps = []\n",
    "    for comment in comments:\n",
    "        count = len(re.findall('[–ê-–Ø–ÅA-Z\\-]{4,}', comment))\n",
    "        total = len(comment.split())\n",
    "        if partion and total != 0:\n",
    "            caps.append(count / total * 100)\n",
    "        else:\n",
    "            caps.append(1 if count > 0 else 0)\n",
    "    return caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caps = caps_words(comments_list, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    108995\n",
       "1      3287\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(caps).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eng_words(comments, partion=False):\n",
    "    engs = []\n",
    "    for comment in comments:\n",
    "        count = len([w for w in re.findall('[a-z\\-]{3,}', comment, flags=re.IGNORECASE) if w != '–∏–º—è'])\n",
    "        total = len(comment.split())\n",
    "        if partion and total != 0:\n",
    "            engs.append(count / total * 100)\n",
    "        else:\n",
    "            engs.append(1 if count > 0 else 0)\n",
    "    return engs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engs = eng_words(comments_list, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    110628\n",
       "1      1654\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(engs).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_words(comments):\n",
    "    return [len(com.split()) if len(com.split()) < 25 else 25 for com in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_count = total_words(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25    13788\n",
       "5     13100\n",
       "6     11924\n",
       "7     10207\n",
       "8      8874\n",
       "9      7538\n",
       "10     6474\n",
       "11     5563\n",
       "12     4982\n",
       "13     4441\n",
       "14     3844\n",
       "15     3470\n",
       "16     2980\n",
       "17     2691\n",
       "18     2438\n",
       "19     2152\n",
       "20     1858\n",
       "21     1763\n",
       "22     1503\n",
       "23     1387\n",
       "24     1305\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(words_count).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_chars(comments):\n",
    "    return [len(com) if len(com) < 100 else 100 for com in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars_count = total_chars(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    28340\n",
       "33      1799\n",
       "35      1767\n",
       "38      1750\n",
       "36      1735\n",
       "34      1727\n",
       "37      1696\n",
       "30      1693\n",
       "31      1682\n",
       "32      1679\n",
       "41      1659\n",
       "39      1641\n",
       "28      1635\n",
       "42      1612\n",
       "40      1584\n",
       "43      1557\n",
       "29      1552\n",
       "44      1515\n",
       "45      1485\n",
       "46      1466\n",
       "27      1414\n",
       "47      1409\n",
       "26      1392\n",
       "48      1361\n",
       "49      1327\n",
       "50      1297\n",
       "52      1296\n",
       "51      1273\n",
       "53      1270\n",
       "25      1226\n",
       "       ...  \n",
       "84       656\n",
       "80       656\n",
       "81       635\n",
       "85       623\n",
       "87       604\n",
       "86       603\n",
       "83       592\n",
       "90       590\n",
       "88       569\n",
       "95       533\n",
       "91       528\n",
       "89       526\n",
       "94       506\n",
       "93       505\n",
       "97       484\n",
       "92       480\n",
       "20       474\n",
       "96       456\n",
       "98       455\n",
       "99       417\n",
       "19       335\n",
       "18       234\n",
       "17       139\n",
       "16        78\n",
       "15        28\n",
       "14        18\n",
       "13         6\n",
       "11         2\n",
       "12         1\n",
       "9          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(chars_count).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All comments features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_comments_features(coms):\n",
    "    features = pd.DataFrame()\n",
    "    features['with_emoji'] = with_emoji(coms)\n",
    "    big_letter, sents_count = sentence_stat(coms)\n",
    "    features['big_letter'] = big_letter\n",
    "    features['sents_count'] = sents_count\n",
    "    features['punct_)'] = punctuation_counts(coms, pattern='\\)+')\n",
    "    features['punct_('] = punctuation_counts(coms, pattern='\\(+')\n",
    "    features['punct_?'] = punctuation_counts(coms, pattern='\\?+')\n",
    "    features['punct_!'] = punctuation_counts(coms, pattern='\\!+')\n",
    "    features['punct_..'] = punctuation_counts(coms, pattern='[\\.]{2,}')\n",
    "    features['punct_1-9'] = punctuation_counts(coms, pattern='[0-9]{1,}')\n",
    "    features['punct_\"'] = punctuation_counts(coms, pattern='\".+\"')\n",
    "    features['eng_words'] = eng_words(coms, True)\n",
    "    features['mean_word_len'] = mean_word_length(coms)\n",
    "    features['caps'] = caps_words(coms)\n",
    "    features['em_proportion_rep'] = comments['em_proportion_rep'].values\n",
    "    features['em_proportion_no_rep'] = comments['em_proportion_no_rep'].values\n",
    "    # features['adj_proportion'] = adj_proportion\n",
    "    features['abc_proportion'] = comments['abc_proportion'].values\n",
    "    features['words_count'] = total_words(coms)\n",
    "    features['chars_count'] = total_chars(coms)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comment_features = get_comments_features(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>with_emoji</th>\n",
       "      <th>big_letter</th>\n",
       "      <th>sents_count</th>\n",
       "      <th>punct_)</th>\n",
       "      <th>punct_(</th>\n",
       "      <th>punct_?</th>\n",
       "      <th>punct_!</th>\n",
       "      <th>punct_..</th>\n",
       "      <th>punct_1-9</th>\n",
       "      <th>punct_\"</th>\n",
       "      <th>eng_words</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>caps</th>\n",
       "      <th>em_proportion_rep</th>\n",
       "      <th>em_proportion_no_rep</th>\n",
       "      <th>abc_proportion</th>\n",
       "      <th>words_count</th>\n",
       "      <th>chars_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.00000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.087530</td>\n",
       "      <td>0.676662</td>\n",
       "      <td>1.705803</td>\n",
       "      <td>0.246495</td>\n",
       "      <td>0.046045</td>\n",
       "      <td>0.199043</td>\n",
       "      <td>0.127696</td>\n",
       "      <td>0.162876</td>\n",
       "      <td>0.127776</td>\n",
       "      <td>0.055236</td>\n",
       "      <td>0.248619</td>\n",
       "      <td>4.651674</td>\n",
       "      <td>0.029275</td>\n",
       "      <td>0.00262</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.837887</td>\n",
       "      <td>12.379651</td>\n",
       "      <td>63.908489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.282611</td>\n",
       "      <td>0.467752</td>\n",
       "      <td>0.930818</td>\n",
       "      <td>0.430972</td>\n",
       "      <td>0.209583</td>\n",
       "      <td>0.399283</td>\n",
       "      <td>0.333753</td>\n",
       "      <td>0.369254</td>\n",
       "      <td>0.333842</td>\n",
       "      <td>0.228441</td>\n",
       "      <td>2.870331</td>\n",
       "      <td>0.910977</td>\n",
       "      <td>0.168576</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.007918</td>\n",
       "      <td>0.111049</td>\n",
       "      <td>6.678896</td>\n",
       "      <td>27.597940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.15000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          with_emoji     big_letter    sents_count        punct_)  \\\n",
       "count  112282.000000  112282.000000  112282.000000  112282.000000   \n",
       "mean        0.087530       0.676662       1.705803       0.246495   \n",
       "std         0.282611       0.467752       0.930818       0.430972   \n",
       "min         0.000000       0.000000       1.000000       0.000000   \n",
       "25%         0.000000       0.000000       1.000000       0.000000   \n",
       "50%         0.000000       1.000000       1.000000       0.000000   \n",
       "75%         0.000000       1.000000       2.000000       0.000000   \n",
       "max         1.000000       1.000000       4.000000       1.000000   \n",
       "\n",
       "             punct_(        punct_?        punct_!       punct_..  \\\n",
       "count  112282.000000  112282.000000  112282.000000  112282.000000   \n",
       "mean        0.046045       0.199043       0.127696       0.162876   \n",
       "std         0.209583       0.399283       0.333753       0.369254   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "           punct_1-9        punct_\"      eng_words  mean_word_len  \\\n",
       "count  112282.000000  112282.000000  112282.000000  112282.000000   \n",
       "mean        0.127776       0.055236       0.248619       4.651674   \n",
       "std         0.333842       0.228441       2.870331       0.910977   \n",
       "min         0.000000       0.000000       0.000000       1.000000   \n",
       "25%         0.000000       0.000000       0.000000       4.058824   \n",
       "50%         0.000000       0.000000       0.000000       4.600000   \n",
       "75%         0.000000       0.000000       0.000000       5.181818   \n",
       "max         1.000000       1.000000     110.000000      19.200000   \n",
       "\n",
       "                caps  em_proportion_rep  em_proportion_no_rep  abc_proportion  \\\n",
       "count  112282.000000       112282.00000         112282.000000   112282.000000   \n",
       "mean        0.029275            0.00262              0.002025        0.837887   \n",
       "std         0.168576            0.01114              0.007918        0.111049   \n",
       "min         0.000000            0.00000              0.000000        0.500000   \n",
       "25%         0.000000            0.00000              0.000000        0.756410   \n",
       "50%         0.000000            0.00000              0.000000        0.857143   \n",
       "75%         0.000000            0.00000              0.000000        0.933333   \n",
       "max         1.000000            0.15000              0.150000        1.000000   \n",
       "\n",
       "         words_count    chars_count  \n",
       "count  112282.000000  112282.000000  \n",
       "mean       12.379651      63.908489  \n",
       "std         6.678896      27.597940  \n",
       "min         5.000000       9.000000  \n",
       "25%         7.000000      39.000000  \n",
       "50%        10.000000      60.000000  \n",
       "75%        17.000000     100.000000  \n",
       "max        25.000000     100.000000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = comment_features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112282, 18)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = lm.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498646295473 0.0128116633448\n"
     ]
    }
   ],
   "source": [
    "baseline_scores = cross_val_score(lr, X, y, cv=5)\n",
    "print(baseline_scores.mean(), baseline_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.48975866,  0.47844674,  0.51126648,  0.51603135,  0.51937121])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression, mutual_info_regression, RFE, SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel = SelectKBest(f_regression, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel = SelectKBest(mutual_info_regression, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel = RFE(lr, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel = SelectFromModel(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel = lm.RandomizedLasso(sample_fraction=0.5, scaling=0.01, n_resampling=500, selection_threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6c4bb05d6144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sel' is not defined"
     ]
    }
   ],
   "source": [
    "sel.fit(X[:30000], y[:30000])\n",
    "X_ = sel.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ = sel.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112282, 7)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['punct_1-9', 'punct_\"', 'mean_word_len', 'caps', 'abc_proportion',\n",
       "       'words_count', 'chars_count'], dtype=object)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_features.columns.values[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sents_count', 'punct_!', 'punct_1-9', 'punct_\"', 'mean_word_len',\n",
       "       'caps', 'words_count'], dtype=object)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_features.columns.values[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.524082684622 0.0156796052383\n"
     ]
    }
   ],
   "source": [
    "baseline_scores = cross_val_score(lr, X_, y, cv=5)\n",
    "print(baseline_scores.mean(), baseline_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537005297114 0.0122820381343\n"
     ]
    }
   ],
   "source": [
    "baseline_scores = cross_val_score(lr, X_, y, cv=5)\n",
    "print(baseline_scores.mean(), baseline_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=[0.1, 1, 10, 100], class_weight=None, cv=None,\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1.0,\n",
       "           max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2',\n",
       "           random_state=None, refit=True, scoring=None, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09238615, -0.00393661, -0.10605297, -0.03285124,  0.00487407]])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cross validation method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_df_balanced(df, by_col):\n",
    "    \"\"\"Make df balanced by binary columns named - by_col. Using oversampling\"\"\"\n",
    "    big_class = 0\n",
    "    small_class = 1\n",
    "    if df[by_col].value_counts()[0] < df[by_col].value_counts()[1]:\n",
    "        big_class = 1\n",
    "        small_class = 0\n",
    "    \n",
    "    delta = df[by_col].value_counts()[big_class] - df[by_col].value_counts()[small_class]\n",
    "    only_ing = df[df[by_col] == small_class]\n",
    "    to_add_indexes = np.random.randint(0, len(only_ing) - 1, delta)\n",
    "    df = pd.concat((df, only_ing.iloc[to_add_indexes]))\n",
    "\n",
    "    # shuffle after adding\n",
    "    df = df.iloc[np.random.permutation(df.shape[0])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_predict_to_n_user(comments, models, n=10, use_cache=True, debug=True, debug_score=True):\n",
    "    unique_ids = None\n",
    "    if use_cache:\n",
    "        with open('unique_ids_{}.pkl'.format(n), 'rb') as f:\n",
    "            unique_ids = pickle.load(f)\n",
    "    else:\n",
    "        unique_ids = comments.from_id.value_counts()[comments.from_id.value_counts() >= n].index.values\n",
    "        with open('unique_ids_{}.pkl'.format(n), 'wb') as f:\n",
    "            pickle.dump(unique_ids, f)\n",
    "    \n",
    "    if debug:\n",
    "        print('{} - uniq peoples'.format(len(unique_ids)))\n",
    "    \n",
    "    train_idxs = unique_ids[:len(unique_ids) * 0.8]\n",
    "    test_idxs = unique_ids[len(unique_ids) * 0.8:]\n",
    "\n",
    "    train_comments = comments[[i in train_idxs for i in comments.from_id]]\n",
    "    test_comments = comments[[i in test_idxs for i in comments.from_id]]\n",
    "\n",
    "    if debug:\n",
    "        print('Before sampling:')\n",
    "        print(train_comments.is_gum.value_counts())\n",
    "    \n",
    "    train_comments = make_df_balanced(train_comments, 'is_gum')\n",
    "    \n",
    "    X_train, X_test = train_comments.text.values, test_comments.text.values\n",
    "    y_train, y_test = train_comments.is_gum.values, test_comments.is_gum.values\n",
    "    \n",
    "    # models\n",
    "    prediction_df = pd.DataFrame()\n",
    "    if debug_score:\n",
    "        print('Accuracy for comment:')\n",
    "    \n",
    "    cols = []\n",
    "    for model in models:\n",
    "        cols.append(model.name)\n",
    "        model.fit(X_train, y_train)\n",
    "        prediction = model.predict(X_test)\n",
    "        prediction_df[model.name] = prediction\n",
    "        \n",
    "        if debug_score:\n",
    "            print('Model: ', model.name)\n",
    "            print(accuracy_score(y_test, prediction))\n",
    "    \n",
    "    prediction_df['prediction'] = prediction_df.median(axis=1)\n",
    "    if debug_score:\n",
    "        print('Median of models:', accuracy_score(y_test, prediction_df['prediction'].values.astype(int)))\n",
    "    # print(test_comments.shape, prediction_df.shape)\n",
    "    test_comments = pd.concat((test_comments.reset_index(drop=True), prediction_df.reset_index(drop=True)), axis=1)\n",
    "    # print(test_comments.shape)\n",
    "    # test_comments['prediction'] = prediction\n",
    "    # y_true = test_comments.groupby('from_id').agg(np.median)['is_gum'].values\n",
    "    # return test_comments\n",
    "    grouped_median_test = test_comments.groupby('from_id').agg(np.median)\n",
    "    # return test_comments.groupby('from_id')[cols].agg(np.median)\n",
    "    y_true = grouped_median_test['is_gum'].values\n",
    "    # print(y_true[:3])\n",
    "    if debug_score:\n",
    "        print('Accuracy for user:')\n",
    "\n",
    "    for model in models:\n",
    "        y_pred = grouped_median_test[model.name].values.astype(int)\n",
    "        # print(y_pred[:3])\n",
    "        # y_pred = np.floor(test_comments.groupby('from_id').agg(np.median)['prediction'].values)\n",
    "        if debug_score:\n",
    "            print('Model: ', model.name)\n",
    "            print(accuracy_score(y_true, y_pred))\n",
    "    if debug_score:\n",
    "        y_pred = np.floor(grouped_median_test[cols].median(axis=1).values).astype(int)\n",
    "        print('Median of models averaged per user:')\n",
    "        print(accuracy_score(y_true, y_pred))\n",
    "    \n",
    "    if debug_score:\n",
    "        y_pred = np.floor(grouped_median_test['prediction'].values).astype(int)\n",
    "        print('Median of averaged model per user:')\n",
    "        print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, name='-'):\n",
    "        self.name = name\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        raise NotImplemented()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LrModelCount(Model):\n",
    "    def __init__(self, name='-', max_features=1000):\n",
    "        super().__init__(name)\n",
    "        self.vectorizer = CountVectorizer(max_features=max_features)\n",
    "        self.model = lm.LogisticRegression()\n",
    "        self._fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = self.vectorizer.fit_transform(X)\n",
    "        self.model.fit(X, y)\n",
    "        self._fitted = True\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = self.vectorizer.transform(X)\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LrModelTfidf(Model):\n",
    "    def __init__(self, name='-', max_features=1000):\n",
    "        super().__init__(name)\n",
    "        self.vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "        self.model = lm.LogisticRegression()\n",
    "        self._fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = self.vectorizer.fit_transform(X)\n",
    "        self.model.fit(X, y)\n",
    "        self._fitted = True\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = self.vectorizer.transform(X)\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "import keras.preprocessing.text\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MlpModel(Model):\n",
    "    def __init__(self, name='-', max_features=1000, neurons=500):\n",
    "        super().__init__(name)\n",
    "        self.vectorizer = CountVectorizer(max_features=max_features)\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(neurons, input_shape=(max_features,)))\n",
    "        self.model.add(Activation(PReLU()))\n",
    "        self.model.add(Dropout(0.3))\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.add(Activation('sigmoid'))\n",
    "\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        self._fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = self.vectorizer.fit_transform(X)\n",
    "        self.model.fit(X.toarray(), y,\n",
    "                    nb_epoch=3, batch_size=512,\n",
    "                    verbose=0) # , validation_split=0.1)\n",
    "        self._fitted = True\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = self.vectorizer.transform(X)\n",
    "        return self.model.predict_classes(X.toarray(), batch_size=512, verbose=0).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LstmModel(Model):\n",
    "    def __init__(self, name='-', nb_words=10000, embedding_vector_length=64, char_level=False, max_len=40,\n",
    "                 nb_epoch=3):\n",
    "        super().__init__(name)\n",
    "        self.nb_words = nb_words\n",
    "        self.embedding_vector_length = embedding_vector_length\n",
    "        self.char_level = char_level\n",
    "        self.max_len = max_len\n",
    "        self.nb_epoch = nb_epoch\n",
    "        \n",
    "        self.vectorizer = keras.preprocessing.text.Tokenizer(nb_words=nb_words, lower=True, split=\" \",\n",
    "                                                             char_level=char_level)\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Embedding(nb_words, embedding_vector_length)) #, input_length=max_comment_length))\n",
    "        self.model.add(Dropout(0.4))\n",
    "        self.model.add(LSTM(64, return_sequences=True, dropout_W=0.2, dropout_U=0.2))  # returns a sequence of vectors of dimension 32\n",
    "        self.model.add(Dropout(0.3))\n",
    "        self.model.add(LSTM(64, return_sequences=False, dropout_W=0.3, dropout_U=0.3))  # returns a sequence of vectors of dimension 32\n",
    "        self.model.add(Dropout(0.3))\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        self._fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.vectorizer.fit_on_texts(X) # clear_coms\n",
    "        X = self.vectorizer.texts_to_sequences(X)\n",
    "        X = sequence.pad_sequences(X, maxlen=self.max_len, padding='pre')\n",
    "        \n",
    "        self.model.fit(X, y, nb_epoch=self.nb_epoch, batch_size=512, verbose=0)\n",
    "        self._fitted = True\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = self.vectorizer.texts_to_sequences(X)\n",
    "        X = sequence.pad_sequences(X, maxlen=self.max_len, padding='pre')\n",
    "        return self.model.predict_classes(X, batch_size=512, verbose=0).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1361 - uniq peoples\n",
      "Before sampling:\n",
      "0.0    53398\n",
      "1.0    44588\n",
      "Name: is_gum, dtype: int64\n",
      "Accuracy for comment:\n",
      "Model:  lstm_word\n",
      "0.540983606557\n",
      "Model:  lstm_char\n",
      "0.540983606557\n",
      "Median of models: 0.54\n",
      "Accuracy for user:\n",
      "Model:  lstm_word\n",
      "0.648351648352\n",
      "Model:  lstm_char\n",
      "0.589743589744\n",
      "Median of models averaged per user:\n",
      "0.626373626374\n",
      "Median of averaged model per user:\n",
      "0.545787545788\n",
      "CPU times: user 3h 16min 11s, sys: 11min 24s, total: 3h 27min 35s\n",
      "Wall time: 1h 49min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit_predict_to_n_user(comments, [\n",
    "              LstmModel('lstm_word', nb_epoch=4),\n",
    "              LstmModel('lstm_char', nb_epoch=4, nb_words=100, char_level=True, max_len=100)\n",
    "\n",
    "#             MlpModel('mlp')\n",
    "#             LrModelCount('lr_count_1k', 1000),\n",
    "#             LrModelCount('lr_count_5k', 5000),\n",
    "#             LrModelTfidf('lr_tfidf_1k', 1000),\n",
    "#             LrModelTfidf('lr_tfidf_5k', 5000),\n",
    "        ],\n",
    "                      5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_ids = comments.from_id.value_counts()[comments.from_id.value_counts() >= 10].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1361"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('unique_ids.pkl', 'wb') as f:\n",
    "    pickle.dump(unique_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('unique_ids_10.pkl', 'rb') as f:\n",
    "    unique_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_ids = pd.Series(unique_ids).sample(frac=1, random_state=3).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    45254\n",
       "1.0    37810\n",
       "Name: is_gum, dtype: int64"
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique_ids = pd.Series(unique_ids).sample(frac=1, random_state=3).values\n",
    "train_idxs = unique_ids[:len(unique_ids) * 0.8]\n",
    "test_idxs = unique_ids[len(unique_ids) * 0.8:]\n",
    "\n",
    "train_comments = comments[[i in train_idxs for i in comments.from_id]]\n",
    "test_comments = comments[[i in test_idxs for i in comments.from_id]]\n",
    "\n",
    "train_comments.is_gum.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    9671\n",
      "1.0    8301\n",
      "Name: is_gum, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_comments.is_gum.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1088, 273)"
      ]
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idxs), len(test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    9671\n",
       "1.0    8301\n",
       "Name: is_gum, dtype: int64"
      ]
     },
     "execution_count": 932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comments.is_gum.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    45254\n",
       "0.0    45254\n",
       "Name: is_gum, dtype: int64"
      ]
     },
     "execution_count": 916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comments.is_gum.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90508, 10), (17972, 10))"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comments.shape, test_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(train_comments.text.values)\n",
    "X_test = vectorizer.transform(test_comments.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[7],\n",
       "        [1],\n",
       "        [6],\n",
       "        ..., \n",
       "        [7],\n",
       "        [2],\n",
       "        [4]])"
      ]
     },
     "execution_count": 919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = lm.LogisticRegression() # class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, train_comments.is_gum.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52203427553972848"
      ]
     },
     "execution_count": 922,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, test_comments.is_gum.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitman/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "test_comments['prediction'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true = test_comments.groupby('from_id').agg(np.median)['is_gum'].values\n",
    "y_pred = np.floor(test_comments.groupby('from_id').agg(np.median)['prediction'].values)\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58608058608058611"
      ]
     },
     "execution_count": 927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4e194c8588>"
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg8AAAFoCAYAAADQPBjdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAGUlJREFUeJzt3XuQ5XV55/F3XwBHpHXsoRg3y4TCwofARoVxMNHVLcGU\nJevENRorAc0iIWQLFCbrIlLZ1JhUSuKChFLCZcHlJk4kJbXcUiEpNGbJZl3GCWEc5DEGZ5mVEEZm\npAdoGKan94/fmbW3l5np5/S5dff7VTU15/wu5/ecp8/p/vT39/2dHpqenkaSJGmuhvtdgCRJWlgM\nD5IkqcTwIEmSSgwPkiSpxPAgSZJKDA+SJKnE8CBJkkoMD5IkqcTwIEmSSgwPkiSpZLS6Q0SsAq4E\n3gm8BPwZsA54M/AN4IXWpkPANPDRzPxaa98LgPOAlcDDwLrM3DTP5yBJknqoHB6Au4EHgaOB5cB/\nBS4DbgO2ZuaxL7dTRKwF1gPvATYDFwL3RMTrM3OyjTokSVIflE5bRMSraYLDJZk5mZlPADfTjEIc\nzLnAjZm5MTNfpAkc08DaYs2SJKmPSiMPmfkMcM6sxauAH7Zuj0XEHcA7aE5fXJGZf9hatxrYMOOx\npiPiIWANcHsbtUuSpD6Y14TJiHgLcD7w+8AEzTyGK4DXAWcD6yPirNbm48DOWQ+xA1gxnxokSVJv\ntTPnAYCIeDtwF3BxZn6jtfjUGZv8RURcC3wMuKm1bKjd4wFMT09PDw3N6yEkSVqqOvYDtK3w0Jr8\neCtwfmbedoBNtwIfbN3eTjP6MNM4zeTJORkaGmJiYpKpqb2FapeukZFhxsaW2bMi+1Znz9pj3+rs\nWXv29a1T2rlU8200IwkfzMz7Zyz/ELAiM6+dsfkJwGOt2xtp5j3c2tp+GDgZuKFy/KmpvezZ4wum\nwp61x77V2bP22Lc6e9ZfpfAQESPA9TSnKu6ftXo3cHlEfB/4S+BdwFnAR1vrrwE2RMQGmrkRF9FM\nqry33eIlSVLvVUcefh44HvhCRHyR5lLLfR8GFTQfFnUVzWdAPAlckJl3AmTmfRFxCc2VFUfSXPJ5\neuuyTUmStEAMTU9P97uGiumdO59zqGqORkeHWb78cOxZjX2rs2ftsW919qw9rb51bMKkf9tCkiSV\nGB4kSVKJ4UGSJJUYHiRJUonhQZIklRgeJElSieFBkiSVGB4kSVKJ4UGSJJUYHiRJUonhQZIklRge\nJElSSfWvakqSVLJ79262bNnckccaGRlmbGwZExOTTE117g9jnXjiz3LooYd27PEWO8ODJKmrtmzZ\nzKeuuIMjxlf1u5SXtevpx/lP/x5OOml1v0tZMAwPkqSuO2J8Fa9ZeVy/y1CHOOdBkiSVGB4kSVKJ\n4UGSJJUYHiRJUonhQZIklRgeJElSieFBkiSVGB4kSVKJ4UGSJJUYHiRJUonhQZIklRgeJElSieFB\nkiSVGB4kSVKJ4UGSJJUYHiRJUonhQZIklRgeJElSieFBkiSVGB4kSVKJ4UGSJJUYHiRJUonhQZIk\nlRgeJElSieFBkiSVGB4kSVKJ4UGSJJUYHiRJUonhQZIklRgeJElSieFBkiSVGB4kSVKJ4UGSJJUY\nHiRJUonhQZIklRgeJElSyWh1h4hYBVwJvBN4Cfgz4MLMnIiIU4FLgeOBx4FLM/MrM/a9ADgPWAk8\nDKzLzE3zfhaSJKln2hl5uBvYARwNrAZOBC6PiJXAncDVwJHAOuD6iDgZICLWAuuBjwBHAfcA90TE\nsvk+CUmS1Dul8BARrwYeBC7JzMnMfAK4mWYU4kwgM/PmzNydmfcDdwHntHY/F7gxMzdm5ovAZcA0\nsLZDz0WSJPVAKTxk5jOZeU5mbp+x+GjghzSjELNPQWwC1rRu/z/rM3MaeGjGekmStACU5zzMFBFv\nAT4O/CJwMbBt1iY7gBWt2+PAzgOsn5OREed4ztW+XtmzGvtWZ8/as1T6thCe38jIMKOjg19nuzr9\nNWg7PETE22lOS1ycmV+PiIuBoYPsdrD1BzU25hSJKnvWHvtWZ8/as9j7thCe39jYMpYvP7zfZSwY\nbYWH1uTHW4HzM/O21uLtNKMLM40DTx1k/ebKsScmJpma2lsreIkaGRlmbGyZPSuyb3X2rD1LpW8T\nE5P9LuGgJiYm2bnzuX6X0TX7Xmud0s6lmm8DbgI+2JoUuc9G4KxZm68BvjVj/Wqa0EFEDAMnAzdU\njj81tZc9exbvm6wb7Fl77FudPWvPYu/bQghGi/1r0Gml8BARI8D1NKcq7p+1+jbgMxFxduv2acB7\ngbe21l8DbIiIDTSf8XAR8AJwb/vlS5KkXquOPPw8zQdAfSEivkhzqeVQ6/8A3gd8EfgjYCtwZmZu\nAcjM+yLiEuB2ms+BeBA4vXXZpiRJWiBK4SEzHwBGDrDJNuCkA+x/HXBd5ZiSJGmwLN7rUiRJUlcY\nHiRJUonhQZIklRgeJElSieFBkiSVGB4kSVKJ4UGSJJUYHiRJUonhQZIklRgeJElSieFBkiSVGB4k\nSVKJ4UGSJJUYHiRJUonhQZIklRgeJElSieFBkiSVGB4kSVKJ4UGSJJUYHiRJUonhQZIklRgeJElS\nieFBkiSVGB4kSVKJ4UGSJJUYHiRJUonhQZIklRgeJElSieFBkiSVGB4kSVKJ4UGSJJUYHiRJUonh\nQZIklRgeJElSieFBkiSVGB4kSVKJ4UGSJJUYHiRJUonhQZIklRgeJElSieFBkiSVGB4kSVKJ4UGS\nJJUYHiRJUonhQZIklRgeJElSieFBkiSVGB4kSVKJ4UGSJJUYHiRJUonhQZIklYxWd4iI9wA3A1/P\nzDNmLP9XwDeAF1qLhoBp4KOZ+bXWNhcA5wErgYeBdZm5aV7PQJIk9VQpPETERcDZwPf2s8nWzDx2\nP/uuBdYD7wE2AxcC90TE6zNzslKHJEnqn+ppi0ngFOAf2jjWucCNmbkxM18ELqMZmVjbxmNJkqQ+\nKYWHzLwqM3cdYJOxiLgjIrZHxLaI+K0Z61YD//cURWZOAw8Ba0oVS5KkvirPeTiACZp5DFcAHwbe\nBfxJROzMzJuAcWDnrH12ACsqBxkZcY7nXO3rlT2rsW919qw9S6VvC+H5jYwMMzo6+HW2q9Nfg46F\nh8z8W+DUGYv+IiKuBT4G3NRaNjTf44yNLZvvQyw59qw99q3OnrVnsfdtITy/sbFlLF9+eL/LWDA6\nOfLwcrYCH2zd3k4z+jDTOM3kyTmbmJhkamrv/CtbAkZGhhkbW2bPiuxbnT1rz1Lp28TE4M+Jn5iY\nZOfO5/pdRtfse611SsfCQ0R8CFiRmdfOWHwC8Fjr9kaaeQ+3trYfBk4GbqgcZ2pqL3v2LN43WTfY\ns/bYtzp71p7F3reFEIwW+9eg0zo58rAbuDwivg/8Jc2ch7OAj7bWXwNsiIgNNHMjLqL5TIh7O1iD\nJEnqsurnPEzSXF55SOv+B4DpzHxlZt4VEeuAq4CjgSeBCzLzToDMvC8iLgFuB44EHgROb122KUmS\nFohSeMjMA54wycwbOMBpiMy8DriuckxJkjRYFu91KZIkqSsMD5IkqcTwIEmSSgwPkiSpxPAgSZJK\nDA+SJKnE8CBJkkoMD5IkqcTwIEmSSgwPkiSpxPAgSZJKDA+SJKnE8CBJkkoMD5IkqcTwIEmSSgwP\nkiSpxPAgSZJKDA+SJKnE8CBJkkoMD5IkqcTwIEmSSgwPkiSpxPAgSZJKDA+SJKnE8CBJkkoMD5Ik\nqcTwIEmSSgwPkiSpxPAgSZJKDA+SJKnE8CBJkkoMD5IkqcTwIEmSSgwPkiSpxPAgSZJKDA+SJKnE\n8CBJkkoMD5IkqcTwIEmSSgwPkiSpxPAgSZJKDA+SJKnE8CBJkkoMD5IkqcTwIEmSSgwPkiSpxPAg\nSZJKDA+SJKnE8CBJkkoMD5IkqcTwIEmSSkarO0TEe4Cbga9n5hmz1p0KXAocDzwOXJqZX5mx/gLg\nPGAl8DCwLjM3tV++JEnqtdLIQ0RcBFwJfO9l1q0E7gSuBo4E1gHXR8TJrfVrgfXAR4CjgHuAeyJi\n2XyegCRJ6q3qaYtJ4BTgH15m3ZlAZubNmbk7M+8H7gLOaa0/F7gxMzdm5ovAZcA0sLa90iVJUj+U\nwkNmXpWZu/azejUw+xTEJmDNy63PzGngoRnrJUnSAlCe83AA48C2Wct2ACtmrN95gPVzMjLiHM+5\n2tcre1Zj3+rsWXuWSt8WwvMbGRlmdHTw62xXp78GnQwPAEPzXH9QY2NOkaiyZ+2xb3X2rD2LvW8L\n4fmNjS1j+fLD+13GgtHJ8LCdZnRhpnHgqYOs31w5yMTEJFNTe9sqcKkZGRlmbGyZPSuyb3X2rD1L\npW8TE5P9LuGgJiYm2bnzuX6X0TX7Xmud0snwsBE4a9ayNcC3ZqxfDdwKEBHDwMnADZWDTE3tZc+e\nxfsm6wZ71h77VmfP2rPY+7YQgtFi/xp0WifDw23AZyLi7Nbt04D3Am9trb8G2BARG2g+4+Ei4AXg\n3g7WIEmSuqz6OQ+TEfE8zWc1/PKM+2TmduB9wCeAHwOfB87MzC2t9fcBlwC3A0/ThIvTW5dtSpKk\nBaI08pCZBzxhkpkPACcdYP11wHWVY0qSpMGyeK9LkSRJXWF4kCRJJYYHSZJUYniQJEklhgdJklRi\neJAkSSWGB0mSVGJ4kCRJJYYHSZJUYniQJEklhgdJklRieJAkSSWGB0mSVGJ4kCRJJYYHSZJUYniQ\nJEklhgdJklRieJAkSSWGB0mSVGJ4kCRJJYYHSZJUYniQJEklhgdJklRieJAkSSWGB0mSVGJ4kCRJ\nJYYHSZJUYniQJEklhgdJklRieJAkSSWGB0mSVGJ4kCRJJYYHSZJUYniQJEklhgdJklRieJAkSSWG\nB0mSVGJ4kCRJJYYHSZJUYniQJEklhgdJklRieJAkSSWGB0mSVGJ4kCRJJYYHSZJUYniQJEklhgdJ\nklRieJAkSSWGB0mSVGJ4kCRJJYYHSZJUMtrJB4uIvcCLwDQw1Pr/+sy8MCJOBS4FjgceBy7NzK90\n8viSJKn7OhoeaMLCGzJz28yFEbESuBP4OLABeAdwV0Q8mpmbOlyDJEnqok6Hh6HWv9nOBDIzb27d\nvz8i7gLOAc7rcA2SJKmLOh0eAD4XEW8DxoCvAp8EVgOzRxg2AR/uwvElSVIXdTo8/A3w58CvAcfS\nhIergXFg26xtdwArqgcYGXGO51zt65U9q7FvdfasPUulbwvh+Y2MDDM6Ovh1tqvTX4OOhofMfPvM\nuxHxaeBu4K94+dMZZWNjyzrxMEuKPWuPfauzZ+1Z7H1bCM9vbGwZy5cf3u8yFoxunLaYaSswAuyl\nGX2YaRx4qvqAExOTTE3tnX9lS8DIyDBjY8vsWZF9q7Nn7VkqfZuYmOx3CQc1MTHJzp3P9buMrtn3\nWuuUjoWHiHgz8JHM/A8zFp8AvAD8KXDWrF3WAN+qHmdqai979izeN1k32LP22Lc6e9aexd63hRCM\nFvvXoNM6OfLwFHBuRDwFXAkcA/wecB3wZWB9RJwN3AacBrwXeGsHjy9JknqgYzMoMvMJ4HTg/cCP\ngAdoRhwuzsztwPuATwA/Bj4PnJmZWzp1fEmS1BudnjD5APD2A6w7qZPHkyRJvbd4r0uRJEldYXiQ\nJEklhgdJklRieJAkSSWGB0mSVGJ4kCRJJYYHSZJUYniQJEklhgdJklRieJAkSSWGB0mSVGJ4kCRJ\nJYYHSZJUYniQJEklhgdJklRieJAkSSWGB0mSVGJ4kCRJJYYHSZJUYniQJEklhgdJklRieJAkSSWG\nB0mSVDLa7wIkSe3bvXs3W7Zs7ncZB5T5aL9LUIcZHiRpAduyZTOfuuIOjhhf1e9S9uufHnuQo45d\n0+8y1EGGB0la4I4YX8VrVh7X7zL2a9fT2/pdgjrMOQ+SJKnE8CBJkkoMD5IkqcTwIEmSSgwPkiSp\nxPAgSZJKDA+SJKnE8CBJkkoMD5IkqcTwIEmSSgwPkiSpxPAgSZJKDA+SJKnE8CBJkkoMD5IkqcTw\nIEmSSgwPkiSpxPAgSZJKDA+SJKnE8CBJkkoMD5IkqWS03wVI0qDavXs3W7Zs7trjj4wMMza2jImJ\nSaam9rb1GJmPdrgq6eAMD5K0H1u2bOZTV9zBEeOr+l3Kfv3TYw9y1LFr+l2GlhjDgyQdwBHjq3jN\nyuP6XcZ+7Xp6W79L0BLknAdJklTS05GHiFgFXA38HLAL+GpmfrqXNUiSpPnp9cjDHcA24Bjg3cAH\nImJdj2uQJEnz0LORh4h4C/BG4NTMfBZ4NiKuAC4ErpzLY/zuZz/PC5MvsXd6uouVtu+wQw/h/N/8\nDYaHPRuk/ur2VQKztXvVwIkn/iyHHnpoFyuT1A29PG1xMrA1MydmLNsEREQcnpnPHewB7v/uMGNH\nRtcKnK9dj/wV5770Eocddli/S9EStxCuEnhm+w/4jbWPEnF8v0vZLy+DlF5eL8PDOLBz1rIdrf9X\nAAcND0NDwwwNDe5v9UNDw3znOw9xyCGD8ZvU8PAQr3rVK3j22RfYu3cwR2sG0WLo29//ffa7hIN6\nYdePuPKW+3jl2N/2u5T92vGPyZGr3tjvMg7o+WeeBAb7dTroNe56+nFGRk5hdHRwf77M18hIZ59b\nry/VHJrPzt+85cJ57d997+93ARIAp532Ts4/v99VSFqsehmzttOMPsw0ThNHt/ewDkmSNA+9DA8b\ngVUR8doZy04BHsnM53tYhyRJmoeh6R5euRAR/x34DvBJ4KeAe4HLMvPanhUhSZLmpdezQz5EExqe\nBL4O3GRwkCRpYenpyIMkSVr4Fu91KZIkqSsMD5IkqcTwIEmSSgwPkiSpxPAgSZJKDA+SJKmk13/b\n4oAiYhVwNfBzwC7gq5n56f1sewFwHrASeBhYl5mbelXroCj27HDgOuAM4PjM/F7PCh0wxb79O2Ad\n8M+A7wOfycy7elXroCj2bD3wMeC1wP8CPpeZX+5VrYOk0rcZ+/wU8F3g8sz8ve5XOVjm2rPW6+x3\ngN2tRUM0f/LgpzNzyf3Zg+J7NIBraT7p+UfAH2bmlXM91qCNPNwBbAOOAd4NfCAi1s3eKCLWAuuB\njwBHAfcA90TEst6VOjDm2rPXAd8GXmKQ/7xd78y1b78EfBY4C1gOXAXcHhHH9KrQATLXnl1I8958\nN/Bq4DPATRHxpp5VOljm1LdZvgDs6XJdg6zSs1sy85Wtf8ta/y+54NAy1/foK4D7gLtpAv4vAWdH\nxBvmeqCBGXmIiLcAbwROzcxngWcj4grgQmB2GjoXuDEzN7b2vay13Vrg9t5V3V/Fnh0JXEQzSvNv\ne1rogCn2bRlwSWb+j9b9/xIRn6NJ9lt7VHLfFXv2EHBGZn6/df9rEfEMcALwd72qeRAU+7Zvn9OB\n42l+KVpy2umZyn37MPDjzLyidf/brX3nbJBGHk4GtmbmxIxlm2hGVw6fte3q1joAMnOa5hvWmq5X\nOVjm3LPMfDgz7+5pdYOr0rfbMvO6ffcj4jXAEcAPe1Lp4Kj07JuZ+SDNyldExMdpfou+v2fVDo7K\n97V9vxF+keaU7FRvShw4pZ4Bb4qIv46IZyJic0T8Qm/KHDiVvv1L4DsR8aWI2BkRj0TEGZWDDVJ4\nGAd2zlq2o/X/ijluO3u7xa7SM/3EfPp2PfA3mfnfOl7VYCv3LCL+M/Ac8FvAv8nMp7pX3sCq9m09\n8NeZ+c2uVjXYKj373zTzkPadwv4SzSns47pa4WCq9O2fA+8H/hx4HfAHwC2VU4sDc9qiZahL2y5m\n9qE9pb5FxChwM/AzwLu6UtHgK/UsM8+NiE8AvwrcGxHvyswlddqiZU59i4gTgLOBf9HdchaEOfUs\nM79EExj2uTIifoUmTKzvRmEDbq7v0SHg25n51db9W1oTw3+ZOZ5aHKSRh+00yWmmcZrJfbMnv+xv\n26X2m02lZ/qJUt9aQ8l/ChwNvGOJTsZq67WWmS9m5k3A/wR+vWvVDa5K366muZJnKb6+Zprv97Wt\nNFdGLTWVvj0J/HjWsq00Vy/OySCFh43Aqoh47YxlpwCPZObzL7Pt6n13ImKY5nzPt7pe5WCp9Gym\npX61RbVvfwy8AJyWmbOHBZeKOfcsIu6KiPNm7b+X5kqfpWZOfWtdYvcO4HcjYntEbAd+Bbg4Ijb2\ntOL+q7zWfjsiZo8E/gzwWJdrHESV72uP8P9PkDyG5rLqORmY8JCZDwEPAn8QEUdExPE050qvBoiI\nRyPiba3NrwF+LSLe2ro88z/SfHO/tw+l980cevbdGT3bZ4glfqqj8lqLiDOBE4EPZ+ZS/OEHlN+f\nD9D80HtzRIy0Lq0+DVhyn41R6Ns2mpGtNwNvav27i+Z73en9qL1fiq+1ceCPIuINEXFYRHwSeD3N\nKcYlpdi3LwMrIuKS1qTmX6X5BXzOn8UyaHMePkQzIe1J4Bngmsy8trXuOOBVAJl5X0RcQnNZ5pE0\nDTs9M1/sfcl9d6CevYFWzyLit2lCFjQjD38XEdPA72fmZ3tb8kA42Gtt3+zkjwE/DeyICPjJh9Dc\nmpm/2dOK+29O70/gcuAQmjD/auAHwK8v4UmAB+1b64qxJ2buFBHPAxNLdKLpXF9rn6Z5P95P83kF\nW2guVXyCpWmuP0P/MSL+Nc3nifwO8Djwi5n5g7keaGh6eqmPYEuSpIqBOW0hSZIWBsODJEkqMTxI\nkqQSw4MkSSoxPEiSpBLDgyRJKjE8SJKkEsODJEkqMTxIkqQSw4MkSSoxPEiSpJL/A0sRl0A4PDkg\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e172e16a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_comments.groupby('from_id').agg(np.std)['prediction'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4e171b7390>"
      ]
     },
     "execution_count": 905,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg8AAAFoCAYAAADQPBjdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nem6jP8NdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e1949a978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_comments.groupby('from_id').agg(np.median)['prediction'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
