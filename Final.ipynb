{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from stop_words import get_stop_words\n",
    "import Stemmer\n",
    "import pymorphy2\n",
    "from segtok import segmenter\n",
    "import re\n",
    "from functools import partial\n",
    "import pickle\n",
    "from gensim import corpora, models\n",
    "from gensim.models import word2vec\n",
    "import xgboost as xgb \n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/comments_vrn.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185612, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    98373\n",
       "1.0    87239\n",
       "Name: is_gum, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_gum.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_gum</th>\n",
       "      <th>hour</th>\n",
       "      <th>likes</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9048238</td>\n",
       "      <td>–í–∂—É—Ö –¥–∞–∂–µ –∑–¥–µ—Å—å</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9048238</td>\n",
       "      <td>–ò –ø–∏—à–∏—Ç–µ –∞–∫–∫—É—Ä–∞—Ç–Ω–µ–µ üòû</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9048238</td>\n",
       "      <td>–≠—Ç–æ #–∏–º–±—Ä–∏–Ω–∞ üòè</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   from_id                   text  is_gum  hour  likes  sex\n",
       "0  9048238        –í–∂—É—Ö –¥–∞–∂–µ –∑–¥–µ—Å—å     0.0    20      1    2\n",
       "1  9048238  –ò –ø–∏—à–∏—Ç–µ –∞–∫–∫—É—Ä–∞—Ç–Ω–µ–µ üòû     0.0    12      3    2\n",
       "2  9048238         –≠—Ç–æ #–∏–º–±—Ä–∏–Ω–∞ üòè     0.0    21      0    2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lenghts_word = np.array([len(m.split()) for m in data.text.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.451069973924099, 7.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenghts_word.mean(), np.median(lenghts_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114275, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = data[(lenghts_word < 50) & (lenghts_word > 4)]\n",
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54% of comments contain links\n"
     ]
    }
   ],
   "source": [
    "links = [m for m in data.text.values if 'http' in m or 'www' in m or '.ru' in m or '.com' in m] \n",
    "print('{:.2f}% of comments contain links'.format(len(links) / len(data) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "without_link = [False if 'http' in c or 'www' in c or '.ru' in c or '.com' in c else True\n",
    "                for c in comments.text.values] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = comments[without_link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113709, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Droping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=1000, ngram_range=(1, 2), analyzer='word', max_df=0.6)\n",
    "X = vectorizer.fit_transform([' '.join(t.split()[:5]) for t in comments.text.values])\n",
    "y = comments.is_gum.values\n",
    "# y = comments.sex.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=1000, ngram_range=(3, 3), analyzer='char')\n",
    "X = vectorizer.fit_transform([' '.join(t.split()[:4]) for t in comments.text.values])\n",
    "y = comments.is_gum.values\n",
    "# y = comments.sex.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = IsolationForest(200, contamination=0.01, n_jobs=-1)\n",
    "forest.fit(X)\n",
    "X_pred = forest.predict(X)\n",
    "comments['len'] = [len(t) for t in comments.text.values]\n",
    "comments['outlier'] = X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ '–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ, –∞ –∫–∞–∫ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è –ø–µ—à–µ—Ö–æ–¥–∞–º –ø—Ä–æ—Ö–æ–¥–∏—Ç—å, –ø–æ –º–Ω–µ–Ω–∏—é –∞–≤—Ç–æ—Ä–∞? –û—Å–æ–±–µ–Ω–Ω–æ –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –Ω–µ–ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –ø–∞—Ä–∫–æ–≤–∫–∏? –¢—Ä–æ—Ç—É–∞—Ä–∞ —Ç–∞–º –Ω–µ –±—ã–ª–æ –∏ –Ω–µ—Ç.',\n",
       "       '–∏–º—è —ç—Ç–æ –∂–∏–∑–Ω—å...–≤—Å—è–∫–æ–µ –±—ã–≤–∞–µ—Ç...–≥–ª–∞–≤–Ω–æ–µ —Å–∞–º–æ–º—É –Ω–µ –±—ã—Ç—å —Ç–∞–∫–∏–º —Ç–æ–≥–¥–∞ –≤—Å–µ –±—É–¥–µ—Ç —á–∏–∫–∏ —á–∏–∫–∏üëçüëçüëçüëçüòâ',\n",
       "       'üòÇüòÇüòÇüòÇüòÇüòÇ—á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤–æ –≥–∏–±–Ω–µ—Ç –±–µ–∑ –≤–æ–¥—ã... –ê –Ω–∞–º –≥–æ—Ä—è—á—É—é –ø–æ–¥–∞–≤–∞–π... –ö—É–ø–∞–π—Ç–µ—Å—å –≤ —Ö–æ–ª–æ–¥–Ω–æ–π',\n",
       "       '–ì–∏–±–Ω–µ—Ç –æ–±—â–µ—Å—Ç–≤–æ –º–æ—Ä–∞–ª—å —Ä–∞—Å—Ç–æ–ø—Ç–∞–Ω–∞... –ß—Ç–æ –∂ –≤—ã —Ç–≤–æ—Ä–∏—Ç–µ –º–æ–ª–æ–¥–µ–∂—å))))??? –û—Ç–≤–µ—á–∞—é –≤–∞–º –Ω–∞—à–∏ —Å—Ç–∞—Ä–µ–Ω—å–∫–∏–µ))) -–ú—ã –∂–∏–≤–µ–º –º—ã –≤—ã–∂–∏–≤–∞–µ–º –∫–∞–∫ –º–æ–∂–µ–º üòÉüòÉüòÉüòÉüòÉ–∏ –æ—Å—É–∂–¥–∞—Ç—å –Ω–µ –Ω–∞–¥–æ))))',\n",
       "       '–ö–æ–Ω–µ—á–Ω–æ, –Ω–∞—Å–æ—Å–∞–ª–∞ –Ω–∞ –ø—Ä–∞–≤–∞ –∏ —Å–≤–æ–π –º–∞—Ç–∏–∑, –∞ –Ω–∞ –µ–∑–¥–∏—Ç—å –Ω–µ —É—Å–ø–µ–ª–∞ –Ω–∞—Å–æ—Å–∞—Ç—å, —Ç–µ–ø–µ—Ä—å –µ–π –¥–æ—Ä–æ–≥–∏ –±–æ–ª—å—à–µ –Ω–∞–¥–æ, —Ö–æ—Ç—è —Ç–∞–º –Ω–∞ –∫–∞–º–∞–∑–µ –ø—Ä–æ–µ–¥–µ—à—å.',\n",
       "       '–ü–æ—á—Ç–∏ –≤—Å–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è —É–∂–µ –ø–æ —Ä–∞–∑—É –≤—ã–ø–æ–ª–Ω–µ–Ω—ã))',\n",
       "       '–ù–µ –∑–∞–±—ã–≤–∞–µ–º —Å–µ–≥–æ–¥–Ω—è –∫–∞–Ω–∞–ª –ü—è—Ç–Ω–∏—Ü–∞ 12:30 –†–µ–≤–∏–∑–æ—Ä—Ä–æ. –í–æ—Ä–æ–Ω–µ–∂. Full',\n",
       "       '–¢–∞–∫–æ–µ –∂–µ –ø—Ä–æ–¥–µ–ª—ã–≤–∞–ª –æ–¥–∏–Ω —Ä–∞–∑ –Ω–∞ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ –∫–∏–≤–∏. –¢–æ–ª—å–∫–æ –≤ —Ç–æ—Ç —Ä–∞–∑ —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª –Ω–µ –±—ã–ª –∞–∫—Ç–∏–≤–Ω—ã–º –ø—Ä–∏—à–ª–æ—Å—å –ø–æ–ø–æ—Ç–µ—Ç—å –ø–æ–∫–∞ –Ω–∞—Ç—ã–∫–∞–ª –∫–Ω–æ–ø–∫—É –ø—É—Å–∫ –≤—Å–ª–µ–ø—É—é –∏ –¥–∞–ª—å—à–µ –≤—Å–µ –∑–∞–∫–æ–Ω—á–∏–ª–æ—Å—å —Ç–µ–º –∂–µ —á—Ç–æ –≤ –¥–∞–Ω–Ω–æ–º –ø–æ—Å—Ç–µ!',\n",
       "       '–≥–ª–∞–≤–Ω–æ–µ-–≤–µ—Ä–∏—Ç—å...—á—É–¥–µ—Å–∞ —Å–ª—É—á–∞—é—Ç—Å—è –ø–æ–¥ –Ω–æ–≤—ã–π –≥–æ–¥..—Ö–æ—Ç—è —ç—Ç–æ —è–≤–Ω–æ –Ω–µ —Ç–æ—Ç —Å–ª—É—á–∞–π –∞—Ö–∞—Ö)',\n",
       "       '–∏–º—è –∫–∞–∫–æ–π –ø—Ä–æ–≤–æ–¥ –ø–µ—Ä–µ—Ä–µ–∑–∞—Ç—å?–∫—Ä–∞—Å–Ω—ã–π –∏–ª–∏ –∑–µ–ª–µ–Ω—ã–π?üòÑ'], dtype=object)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[comments.outlier == -1].head(10).text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_id</th>\n",
       "      <th>is_gum</th>\n",
       "      <th>hour</th>\n",
       "      <th>likes</th>\n",
       "      <th>sex</th>\n",
       "      <th>em_proportion_rep</th>\n",
       "      <th>em_proportion_no_rep</th>\n",
       "      <th>abc_proportion</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outlier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>8.772633e+07</td>\n",
       "      <td>0.467498</td>\n",
       "      <td>13.575245</td>\n",
       "      <td>2.008905</td>\n",
       "      <td>1.688335</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.911466</td>\n",
       "      <td>94.389136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.125301e+07</td>\n",
       "      <td>0.461195</td>\n",
       "      <td>12.719312</td>\n",
       "      <td>1.065852</td>\n",
       "      <td>1.703227</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.837144</td>\n",
       "      <td>79.340107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              from_id    is_gum       hour     likes       sex  \\\n",
       "outlier                                                          \n",
       "-1       8.772633e+07  0.467498  13.575245  2.008905  1.688335   \n",
       " 1       9.125301e+07  0.461195  12.719312  1.065852  1.703227   \n",
       "\n",
       "         em_proportion_rep  em_proportion_no_rep  abc_proportion        len  \n",
       "outlier                                                                      \n",
       "-1                0.001838              0.001357        0.911466  94.389136  \n",
       " 1                0.002628              0.002032        0.837144  79.340107  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.groupby('outlier').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_list = comments.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('emoji.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "emojis = [line[0] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_with_emoji(comment):\n",
    "    for em in emojis:\n",
    "        if em in comment:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def with_emoji(comments):\n",
    "    return [is_with_emoji(c) for c in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_emoji(comment, repetition=True):\n",
    "    ems = []\n",
    "    for em in emojis:\n",
    "        if not repetition:\n",
    "            if em in comment:\n",
    "                ems.append(em)\n",
    "        else:\n",
    "            founded = re.findall(em, comment)\n",
    "            if len(founded) > 0:\n",
    "                ems.extend(founded)\n",
    "    return ems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If not done before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113709"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %time emoji_from_comments_rep = list(map(get_emoji, comments_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('emoji_from_comments_rep_vrn.pkl', 'wb') as f:\n",
    "    pickle.dump(emoji_from_comments_rep, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Else load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113709, 113709)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('emoji_from_comments_rep_vrn.pkl', 'rb') as f:\n",
    "    emoji_from_comments_rep = pickle.load(f)\n",
    "emoji_from_comments_no_rep = list(map(lambda com: get_emoji(com, False), comments_list))\n",
    "len(comments_list), len(emoji_from_comments_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_emoji_proportion(comments, emoji_from_coms=None, repetition=True):\n",
    "    emoji_proportion = [] \n",
    "    func = lambda com: get_emoji(com, repetition)\n",
    "    if not emoji_from_coms:\n",
    "        emoji_from_coms = list(map(func, comments))\n",
    "    \n",
    "    for i in range(len(comments)):\n",
    "        com = re.sub(' *', '', comments[i])\n",
    "        emoji_proportion.append(len(emoji_from_coms[i]) / len(com))\n",
    "    return np.array(emoji_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em_proportion_rep = get_emoji_proportion(comments_list, emoji_from_comments_rep)\n",
    "em_proportion_no_rep = get_emoji_proportion(comments_list, emoji_from_comments_no_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['üëçüëçüëçüëçüëçüëç–∫–ª–∞–∞–∞—Å‚ùó‚ùó‚ùó‚ùó —ç—Ç–∞ –µ–ª–∫–∞ –±—É–¥–µ–µ–µ—Ç —Å–∞–º–æ–π –∫—Ä–∞—Å–∏–≤–æ–πüòÇüòÇüòÇüòÇ',\n",
       "       'üòÇüòÇüòÇüòÇüëçüëçüëç–Ω –Ω—É —ç—Ç–æ –∂ –ª—é–¥–∏....\\nüòÇüòÇüòÇ–±–ª–∏–Ω –∞ –∫–æ–≥–¥–∞ –Ω–æ–≤—ã–π –≥–æ–¥???üòÇ',\n",
       "       'üòÇüòÇüòÇüòÇüòÇüòÇ–≤–æ—Ç –±—ã –º–µ–Ω—è –Ω–∞ –∫—É–ø—é—Ä—É –Ω–µ –ø–ª–æ—Ö–æ–æ–æ –±—ã–ª–æ –±üòÇüòÇüòÇ',\n",
       "       '–ò –∑–¥–µ—Å—å —Ö–æ—Ä–æ—à–æ –∏ —Ç–∞–º —Ö–æ—Ä–æ—à–æ....üëçüëçüëçüëçüëçüëçüëçüëçüëç',\n",
       "       '–î–∞ —á—Ç–æ –≤—ã... –ö–æ–º—É —á—Ç–æ –Ω—Ä–∞–≤–∏—Ç—Å—è üòçüòçüòçüòçüëçüëçüëçüëçüëçüëçüëçüëç',\n",
       "       '–ê –º–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –º–æ–∂–Ω–æ –≤–æ–æ–±—â–µ –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å üòÇüòÇüòÇüòÇüòÇüëçüëçüëçüëçüëçüëç',\n",
       "       'üòçüòçüòçüòçüòçüòç–∏ —Ç–∏—à–∏–Ω–∞ –∏ —Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ üëçüëçüëçüëçüëç',\n",
       "       '–ö–æ–º—É –∫–∞–∫ –Ω–æ –í–æ—Ä–æ–Ω–µ–∂ —ç—Ç–æ –≤–æ—Ä–æ–Ω–µ–∂ –ª—é–±–∏–º –∏ –±—É–¥–µ–º –ª—é–±–∏—Ç—å üòçüòçüòçüòçüòçüòçüòçüòçüòçüëçüëçüëçüëçüëçüëçüëç',\n",
       "       '–ê —è –æ—Ç–ø—Ä–∞–≤–ª—é :–æ–¥—É–º–∞–π—Å—è –Ω–µ –≥–ª—É–ø–∏ –∑–∞–º—É–∂ –Ω–µ –≤—ã—Ö–æ–¥–∏ üòÇüòÇüòÇüòÇüòÇüòÇüëçüëçüëçüëç',\n",
       "       '–û–æ–æ–æ –ø–æ–¥—Å–æ–ª–Ω—É—Ö–∏ üëçüëçüëçüëçüòçüòçüòçüòçüòçüòçüëçüåª üåª üåªüåªüåªüåªüåªüåªüåªüåªüåªüåªüåªüåª'], dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((em_proportion_rep > 0.2).sum())\n",
    "comments_list[em_proportion_rep > 0.2][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['–ì–ª–∞–≤–Ω–æ–µ —á—Ç–æ–± –Ω–µ –ø–æ–∑–¥–Ω–æ üòÇüòÇüòÇüëç', 'üòÇüòÇüòÇ—ç—Ç–æ —è —Å –ü–µ—Ä–º–∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—Å—å üòçüòç',\n",
       "       '–û–æ–æ–æ –ø–æ–¥—Å–æ–ª–Ω—É—Ö–∏ üëçüëçüëçüëçüòçüòçüòçüòçüòçüòçüëçüåª üåª üåªüåªüåªüåªüåªüåªüåªüåªüåªüåªüåªüåª',\n",
       "       'üòÇüòÇüòÇüòÇüòÇ—ç—Ç–æ –µ—â–µ —á—Ç–æ —Ç–∞–∫–æ–µ üòÇüòÇüòÇüòÇüòÇüëçüëçüëç',\n",
       "       'üëçüëçüëçüëçüëçüëçüëçüòçüòçüòçüòçüòçüòç—Å–∞–º—ã–π  –ª—É—á—à–∏–π –∫—Ä–∞—Å–∏–≤—ã–π –≥–æ—Ä–æ–¥ üòõüòõüòõ',\n",
       "       'üòÇüòÇüòÇüòÇüòÇüëçüëçüëçüëçüëç–≤–æ—Ç —Ç–µ –Ω–∞ —Ü–∞—Ä–∏—Ü–∞ –ø—Ä—è–º', 'üòÇüòÇüòÇüòÇüòÇüëçüëçüëçüëç–∞ —è —Ç–∞–∫ —á–∞—Å—Ç–æ –µ–¥—É üòÇüòÇüòÇ',\n",
       "       'üòÇüòÇüòÇüòÇ–∞ —è –Ω–∏—á–µ–≥–æ —Å–µ–±–µ –Ω–µ —Å–∫–∞–∂—É üëçüëçüëç',\n",
       "       '–° –≥–æ—Ä–µ–º –ø–æ–ø–æ–ª–∞–º... ‚ùÑ  ‚ùÑ  ‚ùÑ  ‚ùÑ  ‚ùÑ  üëç',\n",
       "       '[id138651229|–ù–∏–∫–∏—Ç–∞], –ò –ø—Ä—è–º –ø–µ—Ä–µ–¥ –ù–ì! üéÑ üéÑ üçª üçª üç∑ üç∑ ‚ùÑ ‚ùÑ ‚ùÑ ‚ùÑ ‚ùÑ ‚ùÑ'], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((em_proportion_no_rep > 0.07).sum())\n",
    "comments_list[em_proportion_no_rep > 0.07][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of alphabetical symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_abc_proportion(comments):\n",
    "    abc_proportion = []     \n",
    "    for i in range(len(comments)):\n",
    "        com = re.sub(' *', '', comments[i])\n",
    "        abc = re.findall('[–∞-—è—ëa-z]', com, flags=re.IGNORECASE)\n",
    "        abc_proportion.append(len(abc) / len(com))\n",
    "    return np.array(abc_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abc_proportion = get_abc_proportion(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "549"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abc_proportion < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['+7 952 104 73 50', '[id33372525|–î–µ–Ω–∏—Å], –∞ –∫—Ç–æ –≤ 14)?',\n",
       "       '–û–æ–æ–æ –ø–æ–¥—Å–æ–ª–Ω—É—Ö–∏ üëçüëçüëçüëçüòçüòçüòçüòçüòçüòçüëçüåª üåª üåªüåªüåªüåªüåªüåªüåªüåªüåªüåªüåªüåª',\n",
       "       '[id366133865|–ê–Ω–¥—Ä–µ–π], —É –º–µ–Ω—è –∫–æ—Ç))) –ø–æ–¥–æ–π–¥–µ—Ç????? üòÇüòÇüòÇüòÇ',\n",
       "       '[id330930820|–õ—è—Å—å–∫–∞], –∞ —É –º–µ–Ω—è —Ç–æ–∂–µ.... üòÇüòÇüëç',\n",
       "       '[id322876931|–ê–Ω–¥—Ä–µ–π], üòÇüòÇüòÇüòÇ –≤–æ—Ç –±–ª–∏–Ω üòÇüòÇüòÇ',\n",
       "       '[id16867860|–î–º–∏—Ç—Ä–∏–π], –Ω–æ —É–∂ –Ω–µ—Ç))) üòÇüòÇüòÇüòÇ',\n",
       "       '[id42740602|–Æ–ª–∏—è], –±—É–¥—É—Ç –¥–≤–µ 1, 22, 29, 38, 55 –∏ 120–ê –≤—Å–µ –ø–ª–∞—Ç–Ω—ã–µ.',\n",
       "       '[id290551639|Vika], –∞ —É –≤–∞—Å —ç',\n",
       "       '[id138651229|–ù–∏–∫–∏—Ç–∞], –ò –ø—Ä—è–º –ø–µ—Ä–µ–¥ –ù–ì! üéÑ üéÑ üçª üçª üç∑ üç∑ ‚ùÑ ‚ùÑ ‚ùÑ ‚ùÑ ‚ùÑ ‚ùÑ'], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_list[abc_proportion < 0.5][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments['emojis'] = [' '.join(e) for e in emoji_from_comments_rep]\n",
    "comments['em_proportion_rep'] = em_proportion_rep\n",
    "comments['em_proportion_no_rep'] = em_proportion_no_rep\n",
    "comments['abc_proportion'] = abc_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_gum</th>\n",
       "      <th>hour</th>\n",
       "      <th>likes</th>\n",
       "      <th>sex</th>\n",
       "      <th>outlier</th>\n",
       "      <th>emojis</th>\n",
       "      <th>em_proportion_rep</th>\n",
       "      <th>em_proportion_no_rep</th>\n",
       "      <th>abc_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9048238</td>\n",
       "      <td>–Ω—É –ø–ø—Ü, —É–∂–µ –ø—Ä–æ—Å—Ç–æ —Ç–∞–∫ —Ç–µ–ª–µ—Ñ–æ–Ω –Ω–µ –∑–∞—Ä—è–¥–∏—à—å... üòÜ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>üòÜ</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10679122</td>\n",
       "      <td>[id332962766|–ò–≥–æ—Ä—å], –æ–Ω–∏ –∫–∞–≥–±—ç –Ω–∞–º–µ–∫–∞—é—Ç, —á—Ç–æ –Ω...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10679122</td>\n",
       "      <td>[id386347082|Jeg-Hater], –ø—Ä–æ—Å—Ç–æ –≤–æ—é! –ë–ª–∏-–∏-–Ω.....</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.739837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from_id                                               text  is_gum  hour  \\\n",
       "6   9048238    –Ω—É –ø–ø—Ü, —É–∂–µ –ø—Ä–æ—Å—Ç–æ —Ç–∞–∫ —Ç–µ–ª–µ—Ñ–æ–Ω –Ω–µ –∑–∞—Ä—è–¥–∏—à—å... üòÜ     0.0    22   \n",
       "7  10679122  [id332962766|–ò–≥–æ—Ä—å], –æ–Ω–∏ –∫–∞–≥–±—ç –Ω–∞–º–µ–∫–∞—é—Ç, —á—Ç–æ –Ω...     0.0    20   \n",
       "8  10679122  [id386347082|Jeg-Hater], –ø—Ä–æ—Å—Ç–æ –≤–æ—é! –ë–ª–∏-–∏-–Ω.....     0.0    21   \n",
       "\n",
       "   likes  sex  outlier emojis  em_proportion_rep  em_proportion_no_rep  \\\n",
       "6      4    2        1      üòÜ           0.025641              0.025641   \n",
       "7      0    2        1                  0.000000              0.000000   \n",
       "8      0    2        1                  0.000000              0.000000   \n",
       "\n",
       "   abc_proportion  \n",
       "6        0.871795  \n",
       "7        0.818182  \n",
       "8        0.739837  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If message repeats more than one time - drop (spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261 different spam comments\n"
     ]
    }
   ],
   "source": [
    "print('{} different spam comments'.format((comments.text.value_counts() > 1).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792 total count of spam comments\n"
     ]
    }
   ],
   "source": [
    "print('{} total count of spam comments'\n",
    "      .format(comments.text.value_counts()[comments.text.value_counts() > 1].values.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_comments = comments.text.value_counts()[comments.text.value_counts() > 1].keys()\n",
    "comments = comments[comments.text.apply(lambda t: t not in spam_comments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_to_del = comments[(comments.em_proportion_rep > 0.15).values | (comments.abc_proportion < 0.5).values | \n",
    "                        (comments.text.value_counts() != 1).values].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(635,)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_del.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments.drop(index_to_del, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112282, 11)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_list = comments.text.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_list = []\n",
    "for comment in comments.text.values:\n",
    "    c = comment.split()\n",
    "    if c[0].startswith('[id'):\n",
    "        c[0] = '–∏–º—è'\n",
    "    c_ = []\n",
    "    for w in c:\n",
    "        if w.startswith('id'):\n",
    "            c_.append('–∏–º—è')\n",
    "        else:\n",
    "            c_.append(w)\n",
    "    comments_list.append(' '.join(c))\n",
    "comments_list = np.array(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['–Ω—É –ø–ø—Ü, —É–∂–µ –ø—Ä–æ—Å—Ç–æ —Ç–∞–∫ —Ç–µ–ª–µ—Ñ–æ–Ω –Ω–µ –∑–∞—Ä—è–¥–∏—à—å... üòÜ',\n",
       "       '–∏–º—è –æ–Ω–∏ –∫–∞–≥–±—ç –Ω–∞–º–µ–∫–∞—é—Ç, —á—Ç–æ –Ω–∞–∫—Ä—É—á–∏–≤–∞—é—Ç –ª–µ–≤—ã—Ö –ø–ª–∞—Ç–µ–∂–µ–π –Ω–µ –æ—á–µ–Ω—å –º–Ω–æ–≥–æ. –°—É–∫–∏ –æ–Ω–∏ –≤—Å–µ.',\n",
       "       '–∏–º—è –ø—Ä–æ—Å—Ç–æ –≤–æ—é! –ë–ª–∏-–∏-–Ω... –ê –∑–Ω–∞–µ—à—å, —á—Ç–æ —Ç–∞–∫–æ–µ –±—É–∫–≤–∞ \"–£\" –Ω–∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª—è—Ö :)))) (—Å–∫–æ–ª—å–∫–æ –∂–µ –¥–µ–±–∏–ª–æ–≤ –Ω–∞ —Å–≤–µ—Ç–µ,–∞?)'], \n",
       "      dtype='<U421')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments.text = comments_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clearing comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = comments.is_gum.values\n",
    "adj_proportion = []\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_comments(comments, with_stemmer=False, with_lemmer=True, to_lower=True, without_names=False,\n",
    "                without_stop_words=False, min_word_len=None, with_emoji=False):\n",
    "    global adj_proportion\n",
    "    global errors \n",
    "    adj_proportion = []\n",
    "    errors = []\n",
    "    clear_comments = []\n",
    "    stop_words = set(get_stop_words('ru'))\n",
    "    stemmer = Stemmer.Stemmer('russian')\n",
    "    lemmer = pymorphy2.MorphAnalyzer()\n",
    "    \n",
    "    names_del = 0\n",
    "    i = -1\n",
    "    for comment in comments:\n",
    "        comment_ = comment\n",
    "        i += 1\n",
    "        if to_lower:\n",
    "            comment = comment.lower()\n",
    "        comment = re.sub('[^–∞-—è–ê-–Ø—ë–Åa-zA-Z\\-]', ' ', comment)\n",
    "        comment = comment.split()\n",
    "        if without_stop_words:\n",
    "            comment = [c for c in comment if c not in stop_words]\n",
    "        if with_stemmer:\n",
    "            comment = stemmer.stemWords(comment)\n",
    "            if without_names:\n",
    "                with open('names_from_sent.txt', 'r') as f:\n",
    "                    names = f.readlines()\n",
    "                    names = set([name.strip() for name in names])\n",
    "                before = len(comment)\n",
    "                comment = [c for c in comment if c not in names]\n",
    "                aft = len(comment)\n",
    "                names_del += before - aft\n",
    "        elif with_lemmer:\n",
    "            parsed = [lemmer.parse(c)[0] for c in comment]\n",
    "            comment = [p.normal_form for p in parsed]\n",
    "            adj = sum([1 for p in parsed if 'ADJ' in str(p.tag)])\n",
    "            if len(comment) == 0:\n",
    "                errors.append(comment_)\n",
    "                adj_proportion.append(0)\n",
    "            else:\n",
    "                adj_proportion.append(adj / len(comment))\n",
    "            if without_names:\n",
    "                with open('names.txt', 'r') as f:\n",
    "                    names = f.readlines()\n",
    "                    names = set([name.strip() for name in names])\n",
    "                    before = len(comment)\n",
    "                    comment = [c for c in comment if c not in names]\n",
    "                    aft = len(comment)\n",
    "                    names_del += before - aft\n",
    "        if min_word_len is not None:\n",
    "            comment = [c for c in comment if len(c) >= min_word_len]\n",
    "        if with_emoji:\n",
    "            comment.extend(emoji_from_comments_rep[i])\n",
    "        clear_comments.append(' '.join(comment))\n",
    "    print('names del: {}'.format(names_del))\n",
    "    return clear_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names del: 7797\n",
      "CPU times: user 9min 47s, sys: 5.8 s, total: 9min 53s\n",
      "Wall time: 10min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clear_coms = clear_comments(comments_list, min_word_len=3, with_emoji=True, with_stemmer=False,\n",
    "                            with_lemmer=True, without_names=True, without_stop_words=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–∏–º—è –≤–æ—Ç —ç—Ç–æ –Ω–æ–º–µ—Ä –¥–∞–≤–∞—Ç—å —Å–≤–∞–ª–∏—Ç—å –∫—É–¥–∞-–Ω–∏–±—É–¥—å –Ω–∞—à –¥–æ–º –∏–ª–∏ –±—ã—Ç—å –¥–∞–≤–∞—Ç—å –∏–¥–∏–æ—Ç—Å–∫–∏–π —Å–æ–≤–µ—Ç —ç—Ç–æ –º–æ–π –¥–æ–º –Ω–∏—á—É—Ç—å –º–∞–ª–µ–Ω—å–∫–∏–π —á–µ–º –≤–∞—à –Ω–µ–ø—Ä–∏—è—Ç–Ω–æ –Ω–µ–º–æ–π –≤–∏–¥–µ—Ç—å –∏–Ω—Ç–µ—Ä—å–µ—Ä –≤–µ–∫',\n",
       " '–∏–º—è –ø—Ä–æ —ç—Ç–æ —Ç–æ—Ç –ø–æ–¥–æ–±–Ω—ã–π',\n",
       " '–∏–º—è —á—Ç–æ –≤–µ—Å—å –º–æ–ª–æ–∫–æ –≤–∞—à –≥—Ä—É–ø–ø–∞ –Ω–∞–∑–≤–∞—Ç—å —Å–æ–±–∏—Ä–∞—Ç—å—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –µ—â—ë —Ä–∞–∑ –µ—Å–ª–∏ –ø–æ–Ω—è—Ç—å –º–æ–π –º—ã—Å–ª—å',\n",
       " '–∏–º—è –≤–∞—à –≤–æ–∏–Ω—Å—Ç–≤–æ –∫–æ–º —Å–æ–ª–¥–∞—Ç —ç—Ç–æ —Å–µ—Ä—å—ë–∑–Ω–æ',\n",
       " '–∏–º—è –ø–æ—Ç–æ–º –ø–æ–ø–æ–≤ —Ñ–æ–Ω–∞—Ä—å –≤–µ—à–∞—Ç—å –ø—Ä–∏—á—ë–º —á–µ–∫–∏—Å—Ç –æ—Ç–Ω—é–¥—å –±—ã—Ç—å –º–µ—Ä–∏—Ç—å—Å—è –ø–∏–ø–∏—Å—å–∫–∞']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_coms[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14705882352941177,\n",
       " 0.2857142857142857,\n",
       " 0.14285714285714285,\n",
       " 0.09090909090909091,\n",
       " 0.0]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_proportion[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.77 s, sys: 44 ms, total: 6.81 s\n",
      "Wall time: 6.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = CountVectorizer(max_features=10000, min_df=100, ngram_range=(1, 2), analyzer='word')\n",
    "word_features = vectorizer.fit_transform(clear_coms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['–∑–∞', '–≤—á–µ—Ä–∞', '–±–∞–±–∞', '–∑–≤–æ–Ω–∏—Ç—å', '–≤–æ–∑–∏—Ç—å', '–ø–∞–¥–∞—Ç—å', '–º–∞–ª—å—á–∏–∫',\n",
       "       '–≤—ã–∑–≤–∞—Ç—å', '–∏—Å–∫–∞—Ç—å', '–∫—Ä—ã—à–∞', '–º–µ–Ω—è—Ç—å', '–∏–º—è –±—ã—Ç—å', '–∫—Ä–∞—Å–∏–≤–æ',\n",
       "       '–Ω–æ–≤—ã–π', '–≤–µ—Å–Ω–∞', '–¥–æ—Å—Ç–æ–π–Ω—ã–π', '–∂–∞–ª–∫–æ', '–∏–º—è –∞–≥–∞', '–Ω–∏–∂–µ', '–≤—ã–ø–∏—Ç—å'], \n",
       "      dtype='<U18')"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectorizer.get_feature_names())[np.random.randint(0, 1000, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = lm.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52304956426916749"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(lr, word_features, comments.is_gum, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the first letter of sentence upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_stat(comments):\n",
    "    big_letter = []\n",
    "    sents_count = []\n",
    "    for comment in comments:\n",
    "        sents = list(segmenter.split_single(re.sub('(\\)+|\\.+)', '\\n', comment)))\n",
    "        count = sum([1 for sent in sents if sent and (sent[0].isupper() or '–∏–º—è' in sent\n",
    "                                                      or (len(sent) > 1 and sent[0] == '\"' and sent[1].isupper()))])\n",
    "        total = sum([1 for sent in sents if sent.strip() != ''\n",
    "                     and re.match('.*[a-z–∞-—è—ë].*', sent.strip(), flags=re.IGNORECASE)])\n",
    "        # print(count, total)\n",
    "        if total:\n",
    "            big_letter.append(count // total)\n",
    "        else:\n",
    "            big_letter.append(1)\n",
    "        if total > 3:\n",
    "            total = 4\n",
    "        if total < 1:\n",
    "            total = 1\n",
    "        sents_count.append(total)\n",
    "    return big_letter, sents_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.32 s, sys: 0 ns, total: 4.32 s\n",
      "Wall time: 4.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "big_letter, sents_count = sentence_stat(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    61633\n",
       "2    30433\n",
       "3    11832\n",
       "4     8384\n",
       "dtype: int64"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(sents_count).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    75977\n",
       "0    36305\n",
       "dtype: int64"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(big_letter).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation count in comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def punctuation_counts(comments, pattern='\\(+', partion=False):\n",
    "    if partion:\n",
    "        return [sum(len(p) for p in re.findall(pattern, c)) / len(c) for c in comments]\n",
    "    else:\n",
    "        return [1 if len(re.findall(pattern, c)) > 0 else 0 for c in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "commas = punctuation_counts(comments_list, pattern='[\\.]{2,}', partion=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    93994\n",
       "1    18288\n",
       "dtype: int64"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(commas).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_word_length(comments):\n",
    "    lengths = []\n",
    "    for comment in comments:\n",
    "        comment = comment.lower()\n",
    "        comment = re.sub('[^–∞-—è—ë\\-]', ' ', comment).split()\n",
    "        ls = [len(w) for w in comment]\n",
    "        if len(ls):\n",
    "            lengths.append(sum(ls) / len(ls))\n",
    "        else:\n",
    "            lengths.append(1)\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_length = mean_word_length(comments_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caps WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def caps_words(comments, partion=False):\n",
    "    caps = []\n",
    "    for comment in comments:\n",
    "        count = len(re.findall('[–ê-–Ø–ÅA-Z\\-]{4,}', comment))\n",
    "        total = len(comment.split())\n",
    "        if partion and total != 0:\n",
    "            caps.append(count / total * 100)\n",
    "        else:\n",
    "            caps.append(1 if count > 0 else 0)\n",
    "    return caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caps = caps_words(comments_list, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    108995\n",
       "1      3287\n",
       "dtype: int64"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(caps).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eng_words(comments, partion=False):\n",
    "    engs = []\n",
    "    for comment in comments:\n",
    "        count = len([w for w in re.findall('[a-z\\-]{3,}', comment, flags=re.IGNORECASE) if w != '–∏–º—è'])\n",
    "        total = len(comment.split())\n",
    "        if partion and total != 0:\n",
    "            engs.append(count / total * 100)\n",
    "        else:\n",
    "            engs.append(1 if count > 0 else 0)\n",
    "    return engs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engs = eng_words(comments_list, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    110628\n",
       "1      1654\n",
       "dtype: int64"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(engs).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_words(comments):\n",
    "    return [len(com.split()) if len(com.split()) < 25 else 25 for com in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_count = total_words(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25    13788\n",
       "5     13100\n",
       "6     11924\n",
       "7     10207\n",
       "8      8874\n",
       "9      7538\n",
       "10     6474\n",
       "11     5563\n",
       "12     4982\n",
       "13     4441\n",
       "14     3844\n",
       "15     3470\n",
       "16     2980\n",
       "17     2691\n",
       "18     2438\n",
       "19     2152\n",
       "20     1858\n",
       "21     1763\n",
       "22     1503\n",
       "23     1387\n",
       "24     1305\n",
       "dtype: int64"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(words_count).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_chars(comments):\n",
    "    return [len(com) if len(com) < 100 else 100 for com in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars_count = total_chars(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    28340\n",
       "33      1799\n",
       "35      1767\n",
       "38      1750\n",
       "36      1735\n",
       "34      1727\n",
       "37      1696\n",
       "30      1693\n",
       "31      1682\n",
       "32      1679\n",
       "41      1659\n",
       "39      1641\n",
       "28      1635\n",
       "42      1612\n",
       "40      1584\n",
       "43      1557\n",
       "29      1552\n",
       "44      1515\n",
       "45      1485\n",
       "46      1466\n",
       "27      1414\n",
       "47      1409\n",
       "26      1392\n",
       "48      1361\n",
       "49      1327\n",
       "50      1297\n",
       "52      1296\n",
       "51      1273\n",
       "53      1270\n",
       "25      1226\n",
       "       ...  \n",
       "84       656\n",
       "80       656\n",
       "81       635\n",
       "85       623\n",
       "87       604\n",
       "86       603\n",
       "83       592\n",
       "90       590\n",
       "88       569\n",
       "95       533\n",
       "91       528\n",
       "89       526\n",
       "94       506\n",
       "93       505\n",
       "97       484\n",
       "92       480\n",
       "20       474\n",
       "96       456\n",
       "98       455\n",
       "99       417\n",
       "19       335\n",
       "18       234\n",
       "17       139\n",
       "16        78\n",
       "15        28\n",
       "14        18\n",
       "13         6\n",
       "11         2\n",
       "12         1\n",
       "9          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(chars_count).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All comments features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_comments_features(coms):\n",
    "    features = pd.DataFrame()\n",
    "    features['with_emoji'] = with_emoji(coms)\n",
    "    big_letter, sents_count = sentence_stat(coms)\n",
    "    features['big_letter'] = big_letter\n",
    "    features['sents_count'] = sents_count\n",
    "    features['punct_)'] = punctuation_counts(coms, pattern='\\)+')\n",
    "    features['punct_('] = punctuation_counts(coms, pattern='\\(+')\n",
    "    features['punct_?'] = punctuation_counts(coms, pattern='\\?+')\n",
    "    features['punct_!'] = punctuation_counts(coms, pattern='\\!+')\n",
    "    features['punct_..'] = punctuation_counts(coms, pattern='[\\.]{2,}')\n",
    "    features['punct_1-9'] = punctuation_counts(coms, pattern='[0-9]{1,}')\n",
    "    features['punct_\"'] = punctuation_counts(coms, pattern='\".+\"')\n",
    "    features['eng_words'] = eng_words(coms, True)\n",
    "    features['mean_word_len'] = mean_word_length(coms)\n",
    "    features['caps'] = caps_words(coms)\n",
    "    features['em_proportion_rep'] = comments['em_proportion_rep'].values\n",
    "    features['em_proportion_no_rep'] = comments['em_proportion_no_rep'].values\n",
    "    features['adj_proportion'] = adj_proportion\n",
    "    features['abc_proportion'] = comments['abc_proportion'].values\n",
    "    features['words_count'] = total_words(coms)\n",
    "    features['chars_count'] = total_chars(coms)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comment_features = get_comments_features(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>with_emoji</th>\n",
       "      <th>big_letter</th>\n",
       "      <th>sents_count</th>\n",
       "      <th>punct_)</th>\n",
       "      <th>punct_(</th>\n",
       "      <th>punct_?</th>\n",
       "      <th>punct_!</th>\n",
       "      <th>punct_..</th>\n",
       "      <th>punct_1-9</th>\n",
       "      <th>punct_\"</th>\n",
       "      <th>eng_words</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>caps</th>\n",
       "      <th>em_proportion_rep</th>\n",
       "      <th>em_proportion_no_rep</th>\n",
       "      <th>adj_proportion</th>\n",
       "      <th>abc_proportion</th>\n",
       "      <th>words_count</th>\n",
       "      <th>chars_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.00000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "      <td>112282.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.087530</td>\n",
       "      <td>0.676662</td>\n",
       "      <td>1.705803</td>\n",
       "      <td>0.246495</td>\n",
       "      <td>0.046045</td>\n",
       "      <td>0.199043</td>\n",
       "      <td>0.127696</td>\n",
       "      <td>0.162876</td>\n",
       "      <td>0.127776</td>\n",
       "      <td>0.055236</td>\n",
       "      <td>0.248619</td>\n",
       "      <td>4.651674</td>\n",
       "      <td>0.029275</td>\n",
       "      <td>0.00262</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.095670</td>\n",
       "      <td>0.837887</td>\n",
       "      <td>12.379651</td>\n",
       "      <td>63.908489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.282611</td>\n",
       "      <td>0.467752</td>\n",
       "      <td>0.930818</td>\n",
       "      <td>0.430972</td>\n",
       "      <td>0.209583</td>\n",
       "      <td>0.399283</td>\n",
       "      <td>0.333753</td>\n",
       "      <td>0.369254</td>\n",
       "      <td>0.333842</td>\n",
       "      <td>0.228441</td>\n",
       "      <td>2.870331</td>\n",
       "      <td>0.910977</td>\n",
       "      <td>0.168576</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.007918</td>\n",
       "      <td>0.096873</td>\n",
       "      <td>0.111049</td>\n",
       "      <td>6.678896</td>\n",
       "      <td>27.597940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.15000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          with_emoji     big_letter    sents_count        punct_)  \\\n",
       "count  112282.000000  112282.000000  112282.000000  112282.000000   \n",
       "mean        0.087530       0.676662       1.705803       0.246495   \n",
       "std         0.282611       0.467752       0.930818       0.430972   \n",
       "min         0.000000       0.000000       1.000000       0.000000   \n",
       "25%         0.000000       0.000000       1.000000       0.000000   \n",
       "50%         0.000000       1.000000       1.000000       0.000000   \n",
       "75%         0.000000       1.000000       2.000000       0.000000   \n",
       "max         1.000000       1.000000       4.000000       1.000000   \n",
       "\n",
       "             punct_(        punct_?        punct_!       punct_..  \\\n",
       "count  112282.000000  112282.000000  112282.000000  112282.000000   \n",
       "mean        0.046045       0.199043       0.127696       0.162876   \n",
       "std         0.209583       0.399283       0.333753       0.369254   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "           punct_1-9        punct_\"      eng_words  mean_word_len  \\\n",
       "count  112282.000000  112282.000000  112282.000000  112282.000000   \n",
       "mean        0.127776       0.055236       0.248619       4.651674   \n",
       "std         0.333842       0.228441       2.870331       0.910977   \n",
       "min         0.000000       0.000000       0.000000       1.000000   \n",
       "25%         0.000000       0.000000       0.000000       4.058824   \n",
       "50%         0.000000       0.000000       0.000000       4.600000   \n",
       "75%         0.000000       0.000000       0.000000       5.181818   \n",
       "max         1.000000       1.000000     110.000000      19.200000   \n",
       "\n",
       "                caps  em_proportion_rep  em_proportion_no_rep  adj_proportion  \\\n",
       "count  112282.000000       112282.00000         112282.000000   112282.000000   \n",
       "mean        0.029275            0.00262              0.002025        0.095670   \n",
       "std         0.168576            0.01114              0.007918        0.096873   \n",
       "min         0.000000            0.00000              0.000000        0.000000   \n",
       "25%         0.000000            0.00000              0.000000        0.000000   \n",
       "50%         0.000000            0.00000              0.000000        0.085714   \n",
       "75%         0.000000            0.00000              0.000000        0.153846   \n",
       "max         1.000000            0.15000              0.150000        1.000000   \n",
       "\n",
       "       abc_proportion    words_count    chars_count  \n",
       "count   112282.000000  112282.000000  112282.000000  \n",
       "mean         0.837887      12.379651      63.908489  \n",
       "std          0.111049       6.678896      27.597940  \n",
       "min          0.500000       5.000000       9.000000  \n",
       "25%          0.756410       7.000000      39.000000  \n",
       "50%          0.857143      10.000000      60.000000  \n",
       "75%          0.933333      17.000000     100.000000  \n",
       "max          1.000000      25.000000     100.000000  "
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = comment_features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.501309096063 0.0132788987626\n"
     ]
    }
   ],
   "source": [
    "baseline_scores = cross_val_score(lr, X, y, cv=5)\n",
    "print(baseline_scores.mean(), baseline_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.48975866,  0.47844674,  0.51126648,  0.51603135,  0.51937121])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sents_count', 'eng_words', 'mean_word_len', 'words_count',\n",
       "       'chars_count'], dtype=object)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_features.columns.values[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112282, 5)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.539596989232 0.0110092089374\n"
     ]
    }
   ],
   "source": [
    "baseline_scores = cross_val_score(lr, X_, y, cv=5)\n",
    "print(baseline_scores.mean(), baseline_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=[0.1, 1, 10, 100], class_weight=None, cv=None,\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1.0,\n",
       "           max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2',\n",
       "           random_state=None, refit=True, scoring=None, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09238615, -0.00393661, -0.10605297, -0.03285124,  0.00487407]])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
