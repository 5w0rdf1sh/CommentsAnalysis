{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/comments_vrn.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193539, 6)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193539, 6)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_likes = 4\n",
    "max_len = 150\n",
    "min_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_data = data[(data.likes >= min_likes) & (data.text.str.len() < max_len)\\\n",
    "                 & (data.text.str.len() > min_len)][['text']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158.0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.str.len().quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10867, 1)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–§–æ—Ç–∫–∞ –≤ –ø–æ—Å—Ç–µ –ø—Ä–æ—Å—Ç–æ –æ–≥–æ–Ω—åüî•üî•üî•üî•\n"
     ]
    }
   ],
   "source": [
    "print(best_data.text.sample().values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10867 entries, 0 to 10866\n",
      "Data columns (total 1 columns):\n",
      "text    10867 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 85.0+ KB\n"
     ]
    }
   ],
   "source": [
    "best_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data_for_app/best_comments.pkl', 'wb') as f:\n",
    "    pickle.dump(best_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 0 ns, total: 16 ms\n",
      "Wall time: 16.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('data_for_app/best_comments.pkl', 'rb') as f:\n",
    "    b = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149563, 6)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenghts_word = np.array([len(m.split()) for m in data.text.values])\n",
    "comments = data[(lenghts_word <= 20) & (lenghts_word > 1)]\n",
    "comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145819, 3)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "without_link = [False if 'http' in c or 'www' in c or '.ru' in c or '.com' in c else True\n",
    "                for c in comments.text.values] \n",
    "comments = comments[without_link]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_comments = comments.text.value_counts()[comments.text.value_counts() > 1].keys()\n",
    "comments = comments[comments.text.apply(lambda t: t not in spam_comments)]\n",
    "comments_list = comments.text.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_id(df):\n",
    "    comments_list = []\n",
    "    for comment in df.text.values:\n",
    "        c = comment.split()\n",
    "        if c[0].startswith('[id'):\n",
    "            c[0] = ''\n",
    "        c_ = []\n",
    "        for w in c:\n",
    "            if w.startswith('id'):\n",
    "                c_.append('')\n",
    "            else:\n",
    "                c_.append(w)\n",
    "        comments_list.append(' '.join(c))\n",
    "    comments_list = np.array(comments_list)\n",
    "    df.text = comments_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_id(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cross validation method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_df_balanced(df, by_col):\n",
    "    \"\"\"Make df balanced by binary columns named - by_col. Using oversampling\"\"\"\n",
    "    big_class = 0\n",
    "    small_class = 1\n",
    "    if df[by_col].value_counts()[0] < df[by_col].value_counts()[1]:\n",
    "        big_class = 1\n",
    "        small_class = 0\n",
    "    \n",
    "    delta = df[by_col].value_counts()[big_class] - df[by_col].value_counts()[small_class]\n",
    "    only_ing = df[df[by_col] == small_class]\n",
    "    to_add_indexes = np.random.randint(0, len(only_ing) - 1, delta)\n",
    "    df = pd.concat((df, only_ing.iloc[to_add_indexes]))\n",
    "\n",
    "    # shuffle after adding\n",
    "    df = df.iloc[np.random.permutation(df.shape[0])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, name='-'):\n",
    "        self.name = name\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        raise NotImplemented()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        raise NotImplemented()\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LrModelCount(Model):\n",
    "    def __init__(self, name='-', max_features=1000, analyzer='word', ngram_range=(1, 1), penalty='l2', C=1):\n",
    "        super().__init__(name)\n",
    "        self.vectorizer = CountVectorizer(max_features=max_features, analyzer=analyzer, ngram_range=ngram_range)\n",
    "        self.model = lm.LogisticRegression(penalty=penalty, C=C)\n",
    "        self._fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = self.vectorizer.fit_transform(X.text.values)\n",
    "        self.model.fit(X, y)\n",
    "        self._fitted = True\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = self.vectorizer.transform(X.text.values)\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = self.vectorizer.transform(X.text.values)\n",
    "        return self.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LrModelTfidf(Model):\n",
    "    def __init__(self, name='-', max_features=1000, penalty='l2', C=1):\n",
    "        super().__init__(name)\n",
    "        self.vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "        self.model = lm.LogisticRegression(penalty=penalty, C=C)\n",
    "        self._fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = self.vectorizer.fit_transform(X.text.values)\n",
    "        self.model.fit(X, y)\n",
    "        self._fitted = True\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = self.vectorizer.transform(X.text.values)\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        X = self.vectorizer.transform(X.text.values)\n",
    "        return self.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AverageModel():\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        self._fitted = False\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for m in self.models:\n",
    "            m.fit(X, y)\n",
    "        self._fitted = True\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        \n",
    "        predictions = np.hstack([np.expand_dims(m.predict(X), -1) for m in self.models])\n",
    "        predictions = (np.median(predictions, axis=1) > 0.5).astype(int)\n",
    "        return predictions\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if not self._fitted:\n",
    "            raise Exception('Not fitted yet')\n",
    "        \n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            prediction = model.predict_proba(X)\n",
    "            if prediction.shape[1] > 1:\n",
    "                prediction = prediction[:, 1]\n",
    "            else:\n",
    "                prediction = prediction.ravel()\n",
    "            predictions.append(prediction)\n",
    "                \n",
    "        predictions = np.hstack([np.expand_dims(p, -1) for p in predictions])\n",
    "        predictions = np.mean(predictions, axis=1)\n",
    "        return predictions\n",
    "    \n",
    "    def save(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.models, f)\n",
    "\n",
    "    def load(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.models = pickle.load(f)\n",
    "        self._fitted = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "av_model = AverageModel([\n",
    "    LrModelTfidf('lr_tfidf_5k', 5000, penalty='l2', C=0.05),\n",
    "\n",
    "    LrModelCount('lr_count_5k_word_12', 5000, ngram_range=(1, 2), penalty='l2', C=0.05),\n",
    "    LrModelCount('lr_count_10k_word_13', 10000, ngram_range=(1, 3), penalty='l2', C=0.05),\n",
    "\n",
    "    LrModelCount('lr_count_5k_char_23', 5000, 'char', (2, 3), penalty='l2', C=0.05),\n",
    "    LrModelCount('lr_count_2k_char_23', 2000, 'char', (2, 3), penalty='l2', C=0.05),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_coms = 11\n",
    "\n",
    "unique_ids = comments.from_id.value_counts()[comments.from_id.value_counts() >= n_coms].index.values\n",
    "additional_ids = comments.from_id.value_counts()[comments.from_id.value_counts() < n_coms].index.values\n",
    "\n",
    "train_idxs = unique_ids[:int(len(unique_ids) * 0.8)]\n",
    "test_idxs = unique_ids[int(len(unique_ids) * 0.8):]\n",
    "\n",
    "train_comments = comments[[i in train_idxs for i in comments.from_id]]\n",
    "additional_comments = comments[[i in additional_ids for i in comments.from_id]]\n",
    "train_comments = pd.concat((train_comments.reset_index(drop=True), additional_comments.reset_index(drop=True)))\n",
    "\n",
    "test_comments = comments[[i in test_idxs for i in comments.from_id]]\n",
    "\n",
    "train_comments = make_df_balanced(train_comments, 'is_gum')\n",
    "\n",
    "X_train, X_test = train_comments, test_comments\n",
    "y_train, y_test = train_comments.is_gum.values, test_comments.is_gum.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Ç–µ–π, –∞ –Ω–µ –≤—ã–±–æ—Ä —Å–∞–º–æ–≥–æ —á–∞—Å—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, —Ç.–∫ –≤—Ç–æ—Ä–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç, –Ω–∞ —Å–∫–æ–ª—å–∫–æ –∫–∞–∂–¥–∞—è –º–æ–¥–µ–ª—å —É–≤–µ—Ä–µ–Ω–∞ –≤ —Å–≤–æ–µ–º –æ—Ç–≤–µ—Ç–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2158\n",
       "1.0    1718\n",
       "Name: is_gum, dtype: int64"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comments.is_gum.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 0.493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 1.2 s, total: 1min 46s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "av_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr = av_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53689370485036114"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pr > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_model.save('data_for_app/av_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_model = AverageModel([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 92 ms, total: 1.31 s\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "another_model.load('data_for_app/av_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.8 s, sys: 80 ms, total: 1.88 s\n",
      "Wall time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "another_model.load('data_for_app/av_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr = another_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53689370485036114"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pr > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['–û—Ö –Ω—ã—Ç–∏–∫–∏, –æ–ø—è—Ç—å –≤–∞–º –Ω–µ —Ç–∞–∫'], dtype=object)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.sample(1).text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_coms = ['–∫—É–ø–∏ –ø—Ä–∞–≤–∞',\n",
    "           '–∞–≤—Ç–æ–º–æ–±–∏–ª—å –≤ —Å—Ç—É–¥–∏—é',\n",
    "           '–∞ —Ç—ã —Å—Ñ–æ—Ç–∫–∞–π –ø–æ–±–æ–ª—å—à–µ –º–µ—Å—Ç)',\n",
    "           '–°–æ–±—á–∞–∫ –≤ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç—ãüòÇ',\n",
    "           '–ø–æ—ç—Ç–æ–º—É –±–µ—Ä–∏ –∫–æ–ø–µ–π–∫—Éüëç',\n",
    "           '–≤ —Ç–≤–æ–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ',\n",
    "           '–Ω—É –µ—Å–ª–∏ —Ç—ã –∫—É–ø–∏–ª –¥–∏–ø–ª–æ–º',\n",
    "           '—Ç–∞–Ω–∂?',\n",
    "           '–∞ —Ç—ã –≤—ã–≥–ª—è–¥–∏—à—å –∫–∞–∫ –æ–ª–µ–Ω—å',\n",
    "           '–Ω–æ –µ—Å–ª–∏ —É —Ç–µ–±—è –º–æ–∑–≥–∞, —Ç–µ–±–µ –Ω–µ—á–µ–º –¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã',\n",
    "           '–±–ª—è–¥—å',\n",
    "           '–±**–¥—å',\n",
    "           ' –¥—É—Ä–∞'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_coms_df = pd.DataFrame(my_coms, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47520671,  0.41391705,  0.52521049,  0.48708607,  0.46064265,\n",
       "        0.51721634,  0.44965737,  0.47391301,  0.48048024,  0.49664874,\n",
       "        0.47562766,  0.46891131,  0.49851683])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_model.predict_proba(my_coms_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False, False,  True, False, False, False,\n",
       "        True, False, False,  True], dtype=bool)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_model.predict_proba(my_coms_df) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prob = av_model.predict_proba(my_coms_df).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob = np.median(av_model.predict_proba(my_coms_df) > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–∞—à–∞ –æ—Ü–µ–Ω–∫–∞: 0.00\n"
     ]
    }
   ],
   "source": [
    "print('–í–∞—à–∞ –æ—Ü–µ–Ω–∫–∞: {:.2f}'.format(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
